Neuroscience is the study of the nervous system, the collection of nerve cells that interpret all sorts of information which allows the body to coordinate activity in response to the environment.

The study of neuroscience has taught us that the brain is a complicated organ with several connection routes, both between different bodily organs and within itself. Some of those connections communicate information down towards the body, such as signals that allow us to control the movements of our muscles or to change the activity of our internal organs. Other connections ascend into the brain, conveying all sorts of information from the world around us into a representation of our surroundings. Still, other routes communicate between brain areas, such as when the sudden detection of a threat passes through our visual system and turns into a “get ready” signal that then prepares the rest of our body for conflict. Because of this complex system of communication, the nervous system can be thought of as a series of highways and roads that connect different cities (organs).

The nervous system conveys all of these different types of information using a combination of electrical and chemical signals. The main active cellular units of the nervous system, the neurons, are highly sensitive to changes in their environment. A wide variety of chemicals called neurotransmitters are responsible for passing information between neurons.
Realistically, our modern understanding of “neuroscience” is a combination of several academic disciplines, all using their strengths to understand some aspect of the nervous system. Because of this integrative nature, it is possible to study neuroscience from many different perspectives, each of them more fitting for answering different types of questions. These “angles” of analysis are described below.
At the root of the study is biology. Whenever you are studying living processes, such as learning, visual perception, or consciousness, you dip into the realm of biology. The broad field of biology can be subdivided into smaller, more precise categories. Molecular neurobiologists study proteins and gene regulation, cellular neurobiologists examine how networks of neurons communicate with one another, and cognitive neuroscientists study the underlying causes of behaviors. Understanding neuroscience involves genetics, such as the autosomal dominant neurodegenerative condition Huntington’s disease. Other biological sub-disciplines, such as ecology and evolution, are also considered in neuroscience as well, such as the parasite Toxoplasma, which changes an animal’s response to fearful stimuli, allowing the organism to reproduce as it moves through different species in the food web.
Psychology provided the earliest explanations about the brain and ideas about the origin of the mind. Some questions in this field branched off from philosophy as people began thinking about the “mind–body problem”, the discussion that centered around the question of whether a function as complex as consciousness could result from the activity of a clump of cells. Psychologists also wondered whether parts of the brain in isolation have different properties than when those parts are working together. This property, called emergence, is the idea that the whole is greater than the sum of its parts. Psychologists examine neuroscience from a top-down view, aiming questions at understanding the whole organism before looking at smaller components of the organism (compare this with biological approaches, often a bottom-up view that starts at the level of cells or molecules).
Chemistry is a strong influencer of nervous system function—just ask anyone who forgot their morning cup of coffee! We use a variety of endogenous (originating from within the body) chemicals that act as signaling molecules, allowing communication between cells. These chemicals exist in many different structures, which determine their function; some are acidic while others are basic, some are polar, others are fat-soluble, and some are even gases. The nervous system is also highly sensitive to influence by exogenous chemicals (meaning they originate from outside the body), such as caffeine and cocaine.
Many principles of physics can be observed through the functioning of neurons. For example, neurons maintain a negative electrical charge, usually measured on the scale of tens of millivolts (a millivolt is a thousandth of a volt.) The main way for neurons to send signals depends on a temporary change in this voltage; this signal is called an action potential. This change in voltage is brought on by the movement of charged ions across the cell membrane, and they closely follow the rules of magnetism: opposite charges attract while like charges repel.
The field of computational neuroscience has grown from the use of mathematical modeling to describe or predict some aspect of the nervous system. If our current estimates are correct, we have around 86 billion neurons in the brain, a number so large that it is difficult to conceptualize. It would be nearly impossible to understand that many components of a system without taking advantage of the sheer mathematical strength of a computer.
Healthcare providers, like neurologists and psychiatrists, work from a different angle. They coordinate closely with researchers to apply scientific knowledge from the field or laboratory to treat patients, thus using biological principles as therapies. For example, neurologist Dr. Oliver Sacks used his knowledge of the dopamine neurotransmitter system to treat patients with a paralysis-like condition in the 1960s, leading to the development of levadopa treatment for Parkinson’s disease. Other healthcare providers use imaging strategies like a CT scan to assess the extent of a head injury or the location of a brain tumor, while an EEG can be helpful for the diagnosis of epilepsy.
Engineers help develop the tools needed to understand questions in neuroscience, such as the patch clamp rig or electron microscope, highly specialized pieces of lab equipment. They also work closely with healthcare providers to translate science into therapy, such as the deep brain stimulator devices for the treatment of conditions such as Parkinson’s disease. Collectively, all the people who participate in neuroscience in some way are united by their interest in the workings of the body. Because of the overwhelming complexity of the nervous system, there are many questions still unanswered. The continual appearance of new questions in neuroscience keeps us wondering, inspires curiosity, and promises a multitude of fascinating career paths for centuries to come.
The gold standard in science is the use of experimental design. In an experiment, the scientist uses a stepwise process of developing a research question and hypothesis, then answering that question by performing tests. The main goal of an experiment is to establish a causal relationship between one factor that is being changed, the independent variable, and the factor that is influenced, the dependent variable. A well-designed experiment has variables that are carefully controlled, which minimizes the influence of extraneous variables, often called confounding variables. The influence of confounding variables can be eliminated by comparing the experimental group with a control group, a group that is as similar as possible in every way except for the manipulation of the independent variable. Importantly, subjects or patients are generally assigned to the experimental or control group at random.
Another strategy is the case study, a highly detailed description of a single patient and their condition. A case study documents the details regarding a specific deficit or enhancement and is an opportunity to examine individuals with very rare conditions, which are useful for informing about the functions of different brain structures. Like a quasi-experimental study, case studies only show correlation, not causation. It is difficult to generalize the findings from a case study to the population at large.

Perhaps the most famous case study in all of neuroscience is the 1848 story of the railroad worker Phineas Gage. Gage was a construction foreman working on the railroad when an unfortunate explosive workplace accident caused a iron rod to be driven through his left frontal lobe, largely destroying it.  Remarkably, Gage survived this accident and lived another 12 years. However, Gage’s acquaintances described subsequent changes in his personality, teaching us that one of the functions of this area of the brain is regulating our inhibitions.
Case studies can be helpful for the development of hypotheses that can later be tested experimentally. For example, consider another famous case study of Patient HM, the man who had his left and right hippocampus surgically removed and couldn’t create certain types of memory. A research question based on this case study might be: “Is the hippocampus needed for the creation of navigational memory?” Then, an experimental study could be performed in rodents, where we surgically remove the hippocampus (experimental group) or a different part of the brain (control group) and see how well the rodents perform on a memory task.
Though there are many ways that we can directly study humans through experimentation or case studies,  it is often impossible to test every question in humans. Instead of always studying humans, scientists often use nonhuman model organisms, the most common organisms being the worm C. elegans, fruit flies (Drosophila melanogaster), zebrafish (Danio rerio), song birds, mice, rats, and macaque monkeys.
The closer we move towards the human, the more similarities the model organism shares with us. Of the commonly used model organisms, macaque monkeys are the non-humans that are most similar to humans. We share 93% of our genetic material with macaques, but we still have different metabolic and physiological processes, and our behaviors are much different from theirs. Ethical constraints prevent us from performing experiments that may cause physical or psychological harm if performed in humans. We would never conduct a test on humans to assess what concentration of neurotoxin leads to brain damage (these experiments aren’t done very frequently in nonhumans anyway). Invertebrates, such as worms and fruit flies are not as heavily regulated by ethics oversight committees, allowing scientists to conduct a wider set of experiments on these animals.

Our moral responsibilities toward animal subjects are that:

Animals should only be used in worthwhile experiments.
All steps are taken to minimize pain and distress.
All possible alternatives to animal research are considered.
Research facilities at colleges and universities are monitored by an Institutional Care and Use Committee (IACUC). The IACUC consists of fulltime veterinarians, scientists, and community members. They must follow federal laws when approving animal research.
Performing an experiment in an intact, living organism, whether human or nonhuman, is described as an in vivo (Latin meaning “within life”) preparation. The main strength of this strategy is that the data collected here are more predictive of the human condition, which is one of the main goals of biomedical research. However, the in vivo preparation has challenges, because thousands of variables within a living system are uncontrolled or still unknown. There are also very strict ethical limitations on the nature of experiments that can be done in vivo.

On the other hand, an in vitro (Latin meaning “within glass”) preparation is an experiment performed on cultured cells or isolated molecules of DNA, RNA, or protein. These preparations have the opposite strengths and weaknesses of in vivo preparations. They allow for extremely good control over variables, but the results are less reliable in translating to a therapy. The regulations on these experiments are much more lax compared to in vivo experiments; most of the regulatory guidelines are to protect the experimenter rather than the patient or the experimental subject.

Falling in between these two preparations is an ex vivo experiment. In this kind of experiment, a section of the living organism is taken, such as a slice of brain, a tissue biopsy, or a detached frog leg. The strengths and limitations of these experiments are somewhere in between that of the other two preparations.
As complex as the brain is, naturally misconceptions make their way into popular culture. It’s valuable to address these myths about neuroscience and explain the evidence that refutes these statements.

This wildly inaccurate statistic has been the foundation for several fictional movies, TV shows, and books. The truth is that we use every part of the brain, and most of our brain is active most of the time—just not at the same time. Neurologist V.S. Ramachandran uses a great analogy to describe the fallacy of this myth: does a traffic light only use 33% of its lights? A properly functioning traffic light will use all three lights at very precise times. The activity of the brain is closely regulated by multiple mechanisms which prevent unusual electrical activity. In fact, if too many cells were active at the wrong times, just like a traffic light showing both green and red, chaos ensues—one cause of seizures is excessive neural activity.
Another misconception is the idea that each new cell in our brain represents a new memory. While we are far from understanding the process of exactly how memories are formed in the brain, we do have a few clues. Most likely, memories are stored at the sites of close contact between neurons, called synapses. Changes in ways neurons connect and communicate with one another is likely the mechanism behind how memories are formed and stored, rather than the creation of new neurons. Even though the process of cell reproduction is halted in the majority of adult neurons, we are still capable of new neuronal growth, a process called neurogenesis. A few brain areas in particular, like the hippocampus (used in learning and memory functions and the olfactory epithelium (used for smelling), do exhibit frequent birth and death of new neurons.

Myth 3: “The brain cannot repair itself.”
If neurons aren’t being replaced in adulthood, then how do people spontaneously recover from neurological injuries like a stroke? One of the most amazing features of the brain is the phenomenon of plasticity, the ability to change over time. Even if critical brain areas are damaged, it is theorized that the brain learns how to “rewire itself”, essentially figuring out how to carry out these functions without using the damaged connections. Unfortunately, there are some conditions that are neurodegenerative, meaning that their symptoms get progressively worse over time. Many of these disorders, like Parkinson’s disease and Alzheimer’s disease, currently do not have any simple cures or treatments that don’t carry risks and side effects. For people with these conditions, there is not strong evidence that the brain can recover from the destruction caused by these diseases.

Myth 4: “If you are analytical, you are left brain dominant, but if you are creative, you are right brain dominant.”
A common misconception is that the two hemispheres of the brain are responsible for wildly different functions. The truth is that nearly every function that the left half of the brain can do, the right half can do just as well, and vice versa. Sensory information, voluntary control of the muscles, memories, and many other behaviors can be performed equally well by both the left and right halves of the brain. A major exception to the “left vs. right” component is the processing and production of language. For some reason unknown to scientists, these functions are heavily lateralized in the left hemisphere for most people.

Fascinatingly, we do have one strange quirk about signaling between the brain and the rest of the body: signaling pathways from the left brain crosses over to communicate with the right half of the body, and vice versa. This contralateral organization is an unintended consequence of evolution, and is one of the major distinguishing features of the vertebrate brain.
One of the most exciting and satisfying aspects of modern science is the rapidity of new discoveries in the field. New findings are often communicated by publishing academic studies in scientific journals. More neuroscience studies were published between 2015 and 2020 than in the previous seventy years! But, advancements in neuroscience haven’t always moved so quickly.

Trepanation was a surgical intervention that involved drilling a hole into an individual’s skull. It is believed to be one of the oldest surgical procedures according to archaeological evidence. Interestingly, skulls that show evidence of trepanation have been dated to 6500 BCE and show evidence of healing, indicating that the patient survived the surgery.

For hundreds of years, physicians attempted to correlate behaviors with changes in the brain. In the mid 1800s, the physician Paul Broca contributed to localization theory by concluding that specific areas of the brain were responsible for carrying out specific functions. This idea was supported by ablation studies that demonstrated that when different brain structures were ablated, or lesioned, there were specific associated functional losses. Further, electrically exciting specific brain structures resulted in eliciting specific behaviors.

Most likely, some behaviors are more localized than others, but still rely on signals from across many other brain areas. As with most fields of biology, absolutes are rare in neuroscience.

The real strength of our brain is its flexibility: brains are capable of changing and adapting to a wide variety of circumstances. Blind people use their visual areas of the brain while echolocating, stroke survivors can regain lost motor functions using the unaffected brain circuits, and babies can effortlessly learn two languages simultaneously in a bilingual household.

Plasticity is based on the idea that not only is the brain capable change, but that our experiences change the structure and function of our nervous system.

There are 2 major cell types within the nervous system: Neurons and Neuroglia. Neurons are cells that transmit electrical information. Neuroglia are supporting cells of the nervous system.

Neurons are the basic units of the brain. Their main function is to send electrical signals over short and long distances in the body, and they are electrically and chemically excitable. The function of the neuron is dependent on the structure of the neuron. The typical neuron consists of the dendrites, cell body, axon (including the axon hillock), and presynaptic terminal.
Although neurons do have a variety of adaptations that make them unique from other types of cells in the body, they are still cells. Therefore, they contain all of the basic features of a typical mammalian cell.

For example, they are made up of an aqueous cytoplasm bounded by a cell membrane. This cell membrane, also called a plasma membrane or lipid membrane, consists of a sheet of several individual molecules called phospholipids, which consist of two hydrophobic (water-fearing) tails and a hydrophilic (water-loving) end. These phospholipids arrange themselves into a bilayer, with the hydrophobic tails touching each other and the hydrophilic sides facing the cytoplasm and the extracellular space, which are both mostly water. Because of the chemical properties of the cell membrane, it is very effective at keeping ions and charged molecules separated, while allowing small molecules like water and oxygen across the cell.

Neurons also have all the organelles that you would see in other cell types, like a nucleus and mitochondria. The number of neurons in the adult human brain, according to our current best estimate, is close to 86 billion. This number was calculated using a revolutionary technique, the isotropic fractionator or “brain soup”, developed by Brazilian neuroanatomist Suzana Herculano-Houzel. To put this number in context, we have about 37 trillion cells in the whole body, so neurons in the brain make up about 0.2% of all cells in the body. Below are some unique characteristics that neurons have in common.

1. Neurons are electroactive, which means that they are charged cells that can change their charge.

2. Neurons are specialized for rapid communication.

Many cells are capable of sending and receiving chemical signals across long distances and time scales, but neurons are able to communicate with a combination of electrical and chemical signals in a matter of milliseconds. Additionally, the shape of neurons and the organization of the neurons on a microscopic level make them effective for sending signals in a very specific direction.

3. Neurons are “forever” cells.

We are constantly replacing non-neuronal cells. For example, the cells in our bones replace themselves frequently at a rate of about 10% each year. Our body makes new skin cells to replace the dying skin cells on the surface so that we have a “new” skin every month. The cells along the inside of our stomachs, exposed to very harsh acidic conditions, get replaced about every week. About 100 million new red blood cells are created every minute! On the other hand, the mature nervous system generally does not undergo much neurogenesis: the creation of new neurons.

The neurons that we have after development are the ones that we will keep until we die and this permanence of neuronal count makes them different from almost every other cell of the body. However, the idea of adult neurogenesis is a topic of debate among neuroscientists since some areas, like the olfactory system and the hippocampus, display new nerve cell production.

4. …But, neurons can change.

Even though new neurons are not created in most areas of the brain, neurons still have the capability to change in their structure and function. Some of these changes, such as physical changes to the structures of the input sites of the neurons, are believed to last for a lifetime.

We use the word plasticity to describe the ability for the brain to alter its morphology. This term is derived from the Greek plastikos, meaning “capable of being shaped or molded”—think of plastic surgery, where a person changes their physical appearance.

Also, neurons do have the capacity to repair themselves to some extent. Neurons of the Peripheral Nervous System may get injured or completely destroyed as a result of trauma to the body. Afterwards, those injured neurons can regrow to connect once again with their original partner. This regrowth seems to depend on a few chemical signals that the body produces, such as nerve growth factor and brain derived neurotrophic factor. However, this process is often very slow, and does not always successfully restore the nervous system to the way it was pre-injury.
The main function of neurons is to use changes in electrical properties in order to communicate with connected cells. This communication usually moves in one direction, and we will use this pathway as an outline for discussing the anatomical structures of the neurons.

Dendrites, shown here in green, are processes that branch out in a tree-like fashion from the cell body. They are the main target for incoming signals received from other cells. The number of inputs a neuron receives depends on the complexity of the dendritic branching. Dendrites may also have small protrusions along the branches known as spines. Spines (illustrated in the inset box) are the sites of some synaptic contacts. Spines increase the surface area of the dendritic arbor, which may be an important factor in receiving communication.

We believe that spines are one of the most important sites where the nervous system is able to change. For example, neurons change shape after exposure to various environmental conditions, such as stress or exposure to drugs. Tiny changes to the surface of the neuron at the level of dendritic spines is an example of plasticity.

Dendritic plasticity is thought to underlie the reason that we can learn new facts or maintain memories about our childhood over long periods of time. Some set of tiny, submicroscopic changes to the morphology of dendritic spines may represent a single complex memory that you form. A neuron does not need spines for receiving information or for plasticity to take place. Many cells lack spines but are still capable of permanently changing. The input site may be anywhere along the dendrite, or even at the cell body—the “center” of the neuron.
Information that arrives through the many dendrites of a neuron eventually filters into the cell body, or the soma, of the neuron. The cell body (shown below in green) contains the nucleus and cellular organelles, including the endoplasmic reticulum, Golgi apparatus, mitochondria, ribosomes, and secretory vesicles. The nucleus houses the DNA of the cell, which is the template for all proteins synthesized in the cell. The organelles (illustrated in the inset box) in the soma are responsible for cellular mechanisms like protein synthesis, packaging of molecules, and cellular respiration.

The cell body is responsible for deciding whether to pass a signal onto the next cell. The cell membrane of the soma performs a complex set of “cellular arithmetic” that weighs all of the incoming signals: excitatory, inhibitory, and modulatory signals. After all of the calculations have been performed, the membrane decides to send a signal, either a “yes” or “no” output, which travels down the axon.
The axon is the main output extension of the neuron. The axon (highlighted in green) is usually a long, single process that begins at the axon hillock and extends out from the cell body. The axon hillock is located where the cell body transitions into the axon. Axons can branch in order to communicate with more than one target cell.

Several axons can bundle and travel together; these are nerves. Axons can be very long; the longest axon in the human body is part of the sciatic nerve that runs from the posterior end of the spinal cord down the leg to control the muscles of the big toe.
The axon transmits an electrical signal—called an action potential—from the axon hillock to the presynaptic terminal, where the electrical signal will result in a release of chemical neurotransmitters to communicate with the next cell. The action potential is a very brief change in the electrical potential, which is the difference in charge between the inside and outside of the cell. During the action potential, the electrical potential across the membrane moves from a negative value to a positive value and back.
Many axons are also covered by a myelin sheath, a fatty substance that wraps around portions of the axon and increases action potential speed. There are breaks between the myelin segments called Nodes of Ranvier, and this uncovered region of the membrane regenerates the action potential as it propagates down the axon in a process called saltatory conduction. There is a high concentration of voltage-gated ion channels, which are necessary for the action potential to occur, in the Nodes of Ranvier.
The length of an axon is variable depending on the location of the neuron and its function. The axon of a sensory neuron in your big toe needs to travel from your foot up to your spinal cord, whereas an interneuron in your spinal cord may only be a few hundred micrometers in length.
Axon diameter is also variable and can be used to differentiate different types of neurons. The diameter affects the speed at which the action potential will propagate. The larger the diameter, the faster the signal can travel. Additionally, larger diameter axons tend to have thicker myelin.
Axoplasmic transport refers to the movement of material within the axon. Organelles, vesicles, and proteins can be moved from the cell body to the terminal via anterograde transport or from the terminal to the cell body via retrograde transport. Anterograde transport can be either fast or slow.

Microtubules run the length of the axon and provide the cytoskeleton tracks necessary for the transportation of materials. Proteins aid in axoplasmic transport. Kinesin is a motor protein that uses ATP and is used in anterograde transport of materials. Dynein is another motor protein that also uses ATP, but is used in retrograde transport of materials.
The synapse is the physical distance that separates two neurons.
Electrical synapses physically share cytoplasm. An electrical synapse may be less than 5 nanometers apart. Cells connected by electrical synapses share cytoplasm, but have two separate cell membranes.
Chemical synapses use neurotransmitters to communicate. Chemical synapses can vary depending on the nature of the synapse.  A chemical synapse is a larger distance, about 15–40 nm across. Adjacent neurons connected by chemical synapses do not share cytoplasm.
The axon terminates at the presynaptic terminal or terminal bouton. The terminal of the presynaptic cell forms a synapse with another neuron or cell, known as the postsynaptic cell. When the action potential reaches the presynaptic terminal, the neuron releases neurotransmitters into the synapse. The neurotransmitters act on the postsynaptic cell. Therefore, neuronal communication requires both an electrical signal (the action potential) and a chemical signal (the neurotransmitter). Most commonly, presynaptic terminals contact dendrites, but terminals can also communicate with cell bodies or even axons. Neurons can also synapse on non-neuronal cells such as muscle cells or glands.
The terms presynaptic and postsynaptic are in reference to which neuron is releasing neurotransmitters and which is receiving them. Presynaptic cells release neurotransmitters into the synapse and those neurotransmitters act on the postsynaptic cell.
Although these typical structural components can be seen in all neurons, the overall structure can vary drastically depending on the location and function of the neuron. Some neurons, called unipolar, have only one branch from the cell body, and the dendrites and axon terminals project from it. Others, called bipolar, have one axonal branch and one dendritic branch. Multipolar neurons can have many processes branching from the cell body. Additionally, each of the projections can take many forms, with different branching characteristics. The common features of cell body, dendrites, and axon, though, are common among all neurons.
Although most of neuroscience is concerned with understanding the functions of neurons, there are other cells in the nervous system that are just as interesting. These cells are grouped together under the umbrella classification of glia. Historically, when these non-neuronal cells were visualized under the microscope, the histologists and anatomists had no idea about their function. They were seen all around the neurons, so the assumption was that these cells were structural elements, a sort of living glue, that held the nervous system together. Today, we know that these glia serve a variety of functions; unfortunately, the misnomer “glia”—derived from the Latin word for “glue”—is still used to describe these non-neuronal components of the nervous system.
Astrocytes are named for their characteristic star-shaped morphology. One of the main functions of astrocytes in the brain is to help maintain the blood-brain barrier. At the end of the extensions of the astrocyte are protrusions called “endfeet”. These endfeet are often wrapped around the endothelial cells that surround the blood vessels. The endfeet release important biological compounds that allow the endothelial cells to remain healthy as they function in maintaining the blood-brain barrier. Astrocytes are also very closely associated with synapses.

Astrocytes also synthesize and produce a variety of trophic factors, which are helper molecular signals that serve several different functions. For one, trophic factors signal to neurons that the neuron should continue to live, or that specific synapses should be maintained. They help guide the neurons as they reach out, forming synapses where appropriate.
The main function of the oligodendrocytes is to add a layer of myelin around the axons of nearby neurons in the central nervous system. A single oligodendrocyte is able to myelinate up to 50 segments of axons. As cells that produce myelin, they are responsible for increasing the conduction speed of nearby neurons as they send signals. Oligodendrocytes only exist in the central nervous system.
Schwann cells can only be found in the peripheral nervous system. The main action of Schwann cells is to provide a section of myelin sheath for peripheral nervous system neurons, and in this way, they function similarly to the oligodendrocytes. Schwann cells produce only a single section of myelin, compared to oligodendrocytes, which myelinate multiple sections. Schwann cells also function in the regeneration of injured axons. When nerves in the peripheral nervous system are damaged after trauma, Schwann cells rapidly mobilize to the site of injury.
Microglia are a bit different from the other glial cell populations. For one, microglia are more immune cells rather than neural. They act as cellular scavengers that travel throughout the brain and spinal cord. It is estimated that microglia make up 10-15% of all cells in the brain.

As immune cells, microglia identify and destroy clumps of proteins, dead/dying cells, or foreign pathogens that enter into the brain. After an injury to the central nervous system, like a traumatic blow to the head, microglia rapidly react to the area of the insult.
Along the inside of the ventricles are a lining of glia called ependymal cells. These ependymal cells are columnar with small fingerlike extensions called cilia that extend into the ventricles and into the central canal that runs down the inside of the spinal cord. The cilia have motor properties that allow for them to rhythmically beat to create a current in the surrounding fluid.
Ependymal cells produce cerebral spinal fluid (CSF). In total, the body can make about half a liter of CSF each day (a little more than two cups.) The ependymal cells are part of a structure called the choroid plexus, the network of blood vessels and cells that form a boundary between the blood and the CSF.
For the majority of human history, the only way we were able to study the structure of the brain was with crude, butcher-like methods. Wait for a person to die, saw a giant hole in the top of the skull, take the brain out, and slice it into pieces to see if there was some correlation between the way the brain looks and the way they died. With these methods, only major changes in gross anatomy could be observed, such as those resulting from severe birth defects or trauma.

Brain analysis methods were enhanced by the scientific adoption of light microscopy. Naturalists in the mid 1600s such as Antonie van Leeuwenhoek, Jan Swammerdam, and Robert Hooke began looking at biological substances up close, and the brain proved to be a complex and interesting sample of tissue.
Staining is an imaging method that is often used in conjunction with microscopy. Thin slices of brain tissue are exposed to various chemical processes. The chemicals that are used for staining have different affinities for parts of cells.

For staining to work, the tissue needs to be subjected to a series of chemical processes. First, the tissue needs to be fixed. Fixation is a chemical process that is accomplished by exposing the tissue to a chemical like paraformaldehyde. The most effective way to expose every part of the body to fixative is to “hijack” the endogenous circulatory system by flushing fixative through the arteries, a process called perfusion. Chemically, fixatives cause adjacent proteins to become covalently bonded (crosslinked), a process which causes the proteins to become unchangeable; they become “fixed” in time. These fixatives are very harsh chemicals, and usually kill microorganisms and inactivate the endogenous enzymes that normally degrade biological tissue. (As a side note, fixatives are particularly nasty carcinogens that can permeate easily through latex gloves.)

After fixation, devices such as a microtome or cryostat are used to slice the brain into sections as thin as 10 microns. Stains do not always reliably pass all the way through thick sections of tissue, such as an intact brain. With thin slices, chemical stains are able to permeate through the depth of the tissue.

Next, stains are used to color the cells of the nervous system. This process is used because it is good for identifying the location of specific proteins at a subcellular level.
A stain is needed to distinguish individual cells in nervous tissue.

Nissl stain (Cresyl Violet Stain) was discovered by Franz Nissl. It stains nucleic acids such as RNA and DNA. Thus, the stain is only localized to neuronal cell bodies, where RNA and DNA are found. This staining method is useful for studying neuronal arrangement and how densely neurons are packed in specific brain structures.
A major advancement in the study of neuronal morphology came about in the late 1800s. The Italian anatomist and biologist Camillo Golgi identified a shortcoming with the cellular analysis techniques of the time: structures in the central nervous sytem were impossible to distinguish from one another. The cells in the brain were so densely packed together, that it became difficult to identify which cellular material belonged to which cell.
Golgi came up with a new technique using a silver compound that caused the silver to precipitate inside the cell membranes. However, not every cell took up the silver. Instead, only a small fraction of neurons, maybe 1% or even less, were completely stained in black, which stood out remarkably well against the light yellow background of the surrounding tissue. This reaction, initially called the “black reaction”, is now known as a “Golgi stain”. (Despite being more than a hundred years old, we currently don’t know the mechanism by which the silver stain is taken up into the neurons, or what determines why certain cells take the stain and others don’t.)

Because of the great contrast between cell and background, every single part of the neuron was completely filled, allowing Golgi to do drawings of the morphology of this nervous tissue. Based on his staining results, Golgi supported the idea that the parts of the nervous system are all one very large, physically connected network. This idea was known as the Reticular Theory.
About 10 years later, the Spanish neuroanatomist Santiago Ramon y Cajal repeated some of Golgi’s staining experiments with other sections of nervous tissue. Looking at similar darkly-filled neurons, Cajal arrived at a different conclusion: the nervous system is not a giant net, but rather a series of individual units that are separated from one another physically. This idea came to be known as the Neuron Doctrine.
Both Golgi and Cajal were awarded the shared Nobel Prize in Physiology or Medicine in 1906 for their accomplishments in helping to understand “the structure of the nervous system”. Even though Cajal’s Neuron Doctrine was adopted widely by scientists, the elucidation of this organization would not have been made possible without Golgi’s development of the silver stain. The sharing of this prestigious award was ironic because of the many disagreements between the two scientists.

Cajal’s Neuron Doctrine was eventually given more support with the aid of modern techniques, like electron microscopy, that are capable of physically seeing the distance between two neurons. The Neuron Doctrine represents our current understanding of how the nervous system is organized.
Ion flow into and out of the neuron is a critical component of neuron function. Ions move in predictable ways, and the control of ion movement affects the cell at rest and while sending and receiving information from other neurons.
The cell membrane that separates the inside of the cell from the outside is a very effective boundary. It is described as being selectively permeable, which means that some molecules are able to travel across the membrane easily, other molecules have an intermediate ability to cross, and other molecules are completely incapable of passing. Generally, gases and molecules of water are able to pass through the cell membrane easily. Large molecules like glucose, and charged molecules like ions or amino acids, are unable to pass across the membrane.

The neuronal membrane is composed of lipid molecules that form two layers. The hydrophilic heads of the molecules align on the outside of the membrane, interacting with the intra- and extracellular solution of the cell, whereas the hydrophobic tails are arranged in the middle, forming a barrier to water and water-soluble molecules like ions. This barrier is critical to neuron function.
Most cells of the body, including neurons, have specialized transmembrane proteins embedded in the cell membrane. These transmembrane proteins are huge protein complexes that span the entirety of the membrane, with an outer side and an inner side. In the middle of the protein is a pore, which is essentially a “tunnel” that allows molecules and ions to pass across the cell membrane. These proteins are called ion channels. These channels are passive since they do not use any cellular energy to move ions. Rather, they simply provide easy passage for ions. It may be useful to think of an ion channel as a “cellular door”. Ion channels are embedded throughout the neuronal membrane.

Channels can be opened and closed in a number of different ways. We can categorize ion channels into four major classes based on their opening and closing conditions.

Leak channels are persistently open. You can think of these leak channels as revolving doors that are never locked. Neurons usually have several leak channels.
Voltage-gated ion channels open in response to a change in membrane potential.
Ligand-gated ion channels open in response to chemical (ligand) binding, such as neurotransmitters.
The fourth class of ion channels is a catch-all category that includes a wide variety of channels that are used by the sensory systems. They open and close in response to unique stimuli depending on what they are able to sense. For example, some open and close depending when they are moved physically, such as a distortion or stretch (mechanoreceptors). We have these in the hair cells of our ears, in our skin, and in our muscles. Photoreceptors in our eyes have ion channels that close in response to being hit by photons of light, and this activity is necessary for us to be able to see in both brightly and dimly lit environments.
One important feature of ion channels is their ability to distinguish ions based on their chemical properties. For example, some channels are selective for Na+, while preventing the passage of all other ions. Each ion channel has special molecular characteristics that allow certain types of ions to pass through the pore while excluding other ions. Channels can be specific to one ion or allow the flow of multiple ions.
Ion channels control ion movement across the cell membrane because the phospholipid bilayer is impermeable to the charged atoms. When the channels are closed, no ions can move into or out of the cell. When ion channels open, however, then ions can move across the cell membrane.
Ions move in predictable ways. Concentration (chemical) and electrical gradients drive ion movement. The chemical gradient refers to the natural process by which a high concentration of a substance, given enough time, will eventually diffuse to a lower concentration and settle evenly over the space. Ions will diffuse from regions of high concentration to regions of low concentration. Diffusion is a passive process, meaning it does not require energy. As long as a pathway exists (like through open ion channels), the ions will move down the concentration gradient.

In addition to concentration gradients, electrical gradients can also drive ion movement. The electrical gradient refers to the electrical forces acting on charged molecules, “pulling” opposite charges together while also “pushing” like charges away from one another—just like the polarity of magnets. Ions are attracted to, and will move toward, regions of opposite charge. Positive ions will move toward regions of negative charge, and vice versa.

For discussion of ion movement in this text, the combination of these two gradients will be referred to as the electrochemical gradient. Sometimes the concentration and electrical gradients driving ion movement can be in the same direction; sometimes the direction is opposite. The electrochemical gradient is the summation of the two individual gradients and provides a single direction for ion movement.
When the concentration and electrical gradients for a given ion balance—meaning they are equal in strength, but in different directions—that ion will be at equilibrium. Ions still move across the membrane through open channels when at equilibrium, but there is no net movement in either direction, meaning there is an equal number of ions moving into the cell as there are moving out of the cell.
Sodium, potassium, and chloride ions are found in different concentrations across the neuron cell membrane. The location of these ions across the cell membrane and their concentration gradients are important for the function of the neuron. Sodium (Na+) ions are more concentrated in the extracellular fluid and less concentrated within the intracellular fluid. Whereas potassium (K+) ions are more concentrated within the intracellular fluid and less concentrated in the extracellular fluid.
The membrane potential is the difference in electrical charge between the inside and the outside of the neuron. This is measured using two electrodes. A reference electrode (also called the ground electrode) is placed in the extracellular solution. The recording electrode is inserted into the cell body of the neuron.
There is more than one way to describe a change in membrane potential. The membrane potential is measured as the difference in charge between the outside of the cell and the inside of the cell. If the membrane potential moves toward zero, that is a depolarization, because the membrane is becoming less polarized—meaning there is a smaller difference between the charge on the inside of the cell compared to the outside. This is also referred to as a decrease in membrane potential. This means that when a neuron’s membrane potential moves from rest, which is typically around -65 mV, toward 0 mV and becomes more positive, this is a decrease in membrane potential. Since the membrane potential is the difference in electrical charge between the inside and outside of the cell, that difference decreases as the cell’s membrane potential moves toward 0 mV.

If the membrane potential moves away from zero, or gets more negative than it was at rest, that is a hyperpolarization because the membrane is becoming more polarized. This is also referred to as an increase in membrane potential.
At rest, ions are not equally distributed across the membrane. This distribution of ions and other charged molecules leads to the inside of the cell having a more negative charge compared to the outside of the cell.
A closer look shows that sodium, calcium, and chloride are concentrated outside of the cell membrane in the extracellular solution, whereas potassium and negatively-charged molecules like amino acids and proteins are concentrated inside in the intracellular solution.
These concentration differences lead to varying degrees of electrochemical gradients in different directions depending on the ion in question. For example, the electrochemical gradients will drive potassium out of the cell, but will drive sodium into the cell.
The neuron’s membrane potential at which the electrical and concentration gradients for a given ion balance out is called the ion’s equilibrium potential. Let’s look at sodium in more detail:
When sodium channels open, the neuron’s membrane becomes permeable to sodium, and sodium will begin to flow across the membrane. The direction is dependent upon the electrochemical gradients. The concentration of sodium in the extracellular solution is about 10 times higher than the intracellular solution, so there is a concentration gradient driving sodium into the cell. Additionally, at rest, the inside of the neuron is more negative than the outside, so there is also an electrical gradient driving sodium into the cell.

As sodium moves into the cell, though, these gradients change in driving strength. As the neuron’s membrane potential become positive, the electrical gradient no longer works to drive sodium into the cell. Eventually, the concentration gradient driving sodium into the neuron and the electrical gradient driving sodium out of the neuron balance with equal and opposite strengths, and sodium is at equilibrium. The membrane potential of the neuron at which equilibrium occurs is called the equilibrium potential of an ion, which is approximately +60 mV for sodium.

It is possible to predict which way an ion will move by comparing the ion’s equilibrium potential to the neuron’s membrane potential. Let’s assume we have a cell with a resting membrane potential of -70 mV. Sodium’s equilibrium potential is +60 mV. Therefore, to reach equilibrium, sodium will need to enter the cell, bringing in positive charge. On the other hand, chloride’s equilibrium potential is -65 mV. Since chloride is a negative ion, it will need to leave the cell in order to make the cell’s membrane potential more positive to move from -70 mV to -65 mV.
As covered in the previous chapter, at rest there is an uneven distribution of ions on either side of the membrane. The inside of the neuron is more negatively charged than the outside. The resting membrane potential of a typical neuron is around -65mV to -70mV, though it can vary.
How the ions are distributed across the membrane plays an important role in the generation of the resting membrane potential. When the cell is at rest, some non-gated, or leak, ion channels are actually open. Significantly more potassium channels are open than sodium channels, and this makes the membrane at rest more permeable to potassium than sodium.
Since the membrane is permeable to potassium at rest due to the open non-gated channels, potassium will be able to flow across the membrane. The electrochemical gradients at work will cause potassium to flow out of the cell in order to move the cell’s membrane potential toward potassium’s equilibrium potential of -80 mV.
The resting membrane potential of a neuron is typically around -65mV to -70mV (but can vary quite a bit). You might ask, though, if the cell has these open non-gated ion channels, and ions are moving at rest, won’t the cell eventually reach potassium’s equilibrium potential if the membrane is only permeable to potassium?

If the open non-gated potassium channels were the only structural ion flow element present in the cell membrane, the membrane potential would eventually reach potassium’s equilibrium potential. However, the membrane has other open non-gated ion channels as well. Although, there are fewer of these channels compared to the potassium channels. The permeability of chloride is about half that of potassium and the permeability of sodium is about 25 to 40 times less than that of potassium. This leads to enough chloride and sodium ion movement to keep the neuron at a resting membrane potential that is slightly more positive than potassium’s equilibrium potential.
There are negatively charged anions trapped within the cell that contribute to the negative intracellular charge when compared to the extracellular charge.
It is critical the ion gradients that exist across the membrane be maintained for proper neuronal function.

As ions move across the membrane, both at rest and when the neuron is active, the concentrations of ions inside and outside of the cell would change. This would lead to changes in the electrochemical gradients that are driving ion movement. What, then, maintains the concentration and electrical gradients critical for the ion flow that allows the neuron to function properly?

The sodium-potassium pump is the key. The pump uses energy in the form of ATP to move three sodium ions out of the cell and two potassium ions in. This moves the ions against their electrochemical gradients, which is why it requires energy. The pump functions to keep the ionic concentrations at proper levels inside and outside the cell. The pump is removing three positively charged ions from inside the cell and adding two positively charged ions. This leaves the inside of the cell always more negative than the outside of the cell.
Importantly, membrane potential is affected by all of the ions that exist around the membrane. It is possible to calculate the membrane potential of a cell if the concentrations and relative permeabilities of the ions are known.

Recall from the last chapter, the Nernst equation is used to calculate one ion’s equilibrium potential. Knowing the equilibrium potential can help you predict which way one ion will move, and it also calculates the membrane potential value that the cell would reach if the membrane were only permeable to one ion. However, at rest, the membrane is permeable to potassium, chloride, and sodium. To calculate the membrane potential, the Goldman equation is needed.
Clearly, potassium levels must be tightly regulated due to the permeability of potassium for the neuronal membrane. Due to the importance of maintaining appropriate potassium levels, the brain has a specialized structure called the Blood Brain Barrier that helps to maintain proper extracellular potassium in the brain by limiting the amount of potassium that can move from capillaries into the brain. Without the blood brain barrier, eating foods that are high in potassium, like a banana, could completely halt the function of your brain!

Typically, capillaries are very leaky vessels, allowing a variety of different nutrients and waste products to pass between the capillaries and the body tissues. The capillaries in the brain, however, are surrounded by astrocytes (a type of glia that we learned about in Chapter 3). The addition of the astrocytes makes it more difficult for substances to pass between the blood and the brain tissue.

In addition to blocking the movement of potassium from the blood to the brain tissue, astrocytes also have potassium pumps in the astrocyte membranes that actively pump potassium out of the extracellular fluid and into the astrocytes to help regulate extracellular potassium levels. This is called potassium buffering.
The membrane potential will always fall into one of the following categories:

Resting membrane potential
Graded Potentials (postsynaptic potentials)
Action potentials
When the neuron is at rest, there is a baseline level of ion flow through leak channels. However, the ability of neurons to function properly and communicate with other neurons through action potentials relies on ion flow through channels other than the non-gated leak channels. We will cover how these channels open in a later lesson. This chapter will examine ion flow through these channels after a stimulus and how the membrane potential changes in response.
Postsynaptic potentials (also called graded potentials) are changes in membrane potential that move the cell away from its resting state. For our purposes, postsynaptic potentials are measured in the dendrites and cell bodies. Ion channels that are opened by a stimulus allow brief ion flow across the membrane.

A stimulus can range from neurotransmitters released by a presynaptic neuron, changes in the extracellular environment like exposure to heat or cold, interactions with sensory stimuli like light or odors, or other chemical or mechanical events. The change in membrane potential in response to the stimulus will depend on which ion channels are opened by the stimulus.
An Excitatory Postsynaptic Potential (EPSP) occurs when sodium channels open in response to a stimulus. The electrochemical gradient drives sodium to rush into the cell. When sodium brings its positive charge into the cell, the cell’s membrane potential becomes more positive, or depolarizes. This change is called a depolarization because the cell’s membrane potential is moving toward 0 mV, and the membrane is becoming less polarized. At 0 mV, there is no potential or polarization across the membrane, so moving toward 0 would be a decrease in potential. This depolarization increases the likelihood a neuron will be able to fire an action potential, which makes this ion flow excitatory. Therefore, an EPSP is an excitatory change in the membrane potential of a postsynaptic neuron.

A postsynaptic potential is typically brief, with ion channels closing quickly after the stimulus occurs. If there is not another stimulus, the cell will return to the resting membrane potential.
An inhibitory postsynaptic potential, or IPSP, on the other hand, is caused by the opening of chloride channels. The equilibrium potential of chloride is -65 mV, so if the neuron is at rest at -60 mV, the electrochemical gradients drive chloride to flow into the cell when chloride channels open. Chloride brings its negative charge into the cell, causing the cell’s membrane potential to become more negative, or hyperpolarize. This change is called a hyperpolarization because the cell’s membrane potential is moving away from 0 mV, and the membrane is becoming more polarized. An IPSP decreases the likelihood a neuron will be able to fire an action potential, which make this ion flow inhibitory. Therefore, an IPSP is an inhibitory change in the membrane potential of a postsynaptic neuron.

An IPSP can also be caused by the opening of potassium channels. The equilibrium potential of potassium is -80 mV, so if the neuron is at rest at -60mV, the electrochemical gradients drive potassium out of the cell when potassium channels open. As positively charged potassium ions leave the cell, this causes the cell’s membrane potential to hyperpolarize. This demonstrates the importance of the equilibrium potential in driving ion movement.

Like an EPSP, an IPSP is also typically brief, and the membrane potential will return to rest if no additional stimulation occurs.
In the previous example, the resting membrane potential of that cell was -60 mV, so chloride moved into the cell. If the resting membrane potential was instead equal to chloride’s equilibrium potential of -65 mV, then chloride would be at equilibrium and move into and out of the cell; there would be no net movement of the ion. Even though this would lead to no change in membrane potential, the opening of chloride channels continues to be inhibitory. Increased chloride conductance would make it more difficult for the cell to depolarize and to fire an action potential.
If the resting membrane potential of the cell was more negative than chloride’s equilibrium potential—for example, at -70 mV—then chloride would leave the cell in order to move the membrane potential toward -65 mV. This would result in a depolarization of the membrane potential. However, the overall effect is still inhibitory because once the cell reaches -65 mV, the driving forces acting on chloride would try to keep the cell at that membrane potential, making it more difficult for the cell to depolarize further and fire an action potential.

A good rule of thumb is to remember that opening of sodium channels is excitatory whereas opening of potassium or chloride channels is typically inhibitory.
If an excitatory stimulus is followed by additional excitatory stimuli, the sodium channels will either remain open or additional sodium channels will open. The increased sodium conductance will cause the EPSPs to summate, depolarizing the cell further than one EPSP alone. Each neuron has a threshold membrane potential at which the cell will fire an action potential. The summation of EPSPs causes the neuron to reach that threshold.
Summation can occur in two ways. Temporal summation occurs when one presynaptic input stimulates a postsynaptic neuron multiple times in a row. Spatial summation occurs when multiple presynaptic inputs each stimulate the postsynaptic neuron at the same time. Both types of summation result in a depolarization of a higher magnitude than when only a single excitatory input occurs.
In addition to the summation of excitatory inputs, EPSPs can also summate with inhibitory inputs. The addition of an inhibitory stimulus will result in either a weaker depolarization compared to a single excitatory stimulus, or possibly no depolarization at all depending on the strength of the inhibitory input.
In the case of combined inhibitory and excitatory stimuli, both chloride and sodium channels will open. As sodium enters the cell, trying to move the membrane potential to +60 mV (the equilibrium potential of sodium) chloride will also enter, trying to keep the cell near -65 mV (the equilibrium potential of chloride).
As covered in previous chapters, the action potential is a very brief change in the electrical potential, which is the difference in charge between the inside and outside of the cell. During the action potential, the electrical potential across the membrane moves from a negative resting value to a positive value and back.
The propagation of the action potential from the axon hillock down the axon and to the presynaptic terminal results in the release of chemical neurotransmitters that communicate with a postsynaptic neuron.
The change in membrane potential during the action potential is a function of ion channels in the membrane. In the previous lessons, we have learned about the principles of ion movement and have discussed non-gated (leak) channels at rest, as well as ion channels involved in the generation of postsynaptic potentials. In this chapter, we will examine a different type of ion channel: voltage-gated ion channels. For our purposes, these channels are located primarily at the axon hillock, along the axon, and at the terminal. They are necessary for the propagation of the action potential.
Voltage-gated channels allow ions to cross the membrane using the same ion movement principles covered in previous lessons. The main difference between voltage-gated channels and leak channels are how they are opened or “gated”. Voltage-gated channels open when the cell’s membrane potential reaches a specific value, called threshold. The neuron reaches threshold after enough EPSPs summate together.
The action potential begins when the cell’s membrane potential reaches threshold. Once initiated in a healthy, unmanipulated neuron, the action potential has a consistent structure and is an all-or-nothing event. It will run through all the phases to completion.

The rising phase is a rapid depolarization followed by the overshoot, when the membrane potential becomes positive. The falling phase is a rapid repolarization followed by the undershoot, when the membrane potential hyperpolarizes past rest. Finally, the membrane potential will return to the resting membrane potential.
The rising phase is caused by the opening of voltage-gated sodium channels. These ion channels are activated once the cell’s membrane potential reaches threshold, opening immediately. The electrochemical gradients drive sodium into the cell causing the depolarization.
The falling phase of the action potential is caused by the inactivation of the sodium channels and the opening of the potassium channels. After approximately 1 msec, the sodium channels inactivate. The channel becomes blocked, preventing ion flow. At the same time, the voltage-gated potassium channels open. This allows potassium to rush out of the cell because of the electrochemical gradients, taking its positive charge out of the cell and repolarizing the membrane potential, which returns the cell’s membrane potential back near rest.

Like the voltage-gated sodium channels, the voltage trigger for the potassium channel is when the cell’s membrane potential reaches threshold. The difference is that the sodium channels open immediately, whereas the potassium channels open after a delay.
As the membrane potential returns to resting level, the sodium channels will de-inactivate, returning to the closed position, ready to be opened again by another voltage change. The potassium channels will also close, but they remain open long enough to cause a hyperpolarizing undershoot as potassium continues to move toward its equilibrium potential of -80 mV.
Once the voltage-gated channels close, the sodium-potassium pumps will reestablish the proper ionic concentrations needed for the electrochemical gradients. This action, along with open leak channels, will return the cell to its resting membrane potential.
Each neuron does have a maximum firing rate. And even if the stimulus continues to increase in strength, the neuron cannot fire at a higher frequency. The maximum firing rate of a cell is determined by the status of the ion channels in the neuronal membrane during the different phases of the action potential. During the absolute refractory period, a second action potential cannot be fired under any circumstances, regardless of the strength of the stimulus. The voltage-gated sodium channels are either open (during the rising phase) or inactivated (during the falling phase).
When the cell repolarizes and the voltage-gated sodium channels de-inactivate and return to a closed state, the cell is again able to fire another action potential. However, during the end of the falling phase and the during the undershoot, voltage-gated potassium channels are still open. During the undershoot, while the neuron is hyperpolarized, a larger-than-normal stimulus is needed to make the cell reach threshold again. This segment of the action potential is called the relative refractory period. Action potentials can be fired, but a stronger stimulus is needed than when the cell is at rest.
For a given cell, all action potentials have the same characteristics; they depolarize to the same membrane potential value and take the same amount of time. However, different neurons may exhibit different action potential characteristics. Likewise, if a neuron has a change in its environment, like altered extracellular ion concentrations, the shape of the action potential would change due to a change in the electrochemical gradients. For example, if the external concentration of sodium is decreased, the equilibrium potential of sodium (as well as the strength of the electrochemical gradients) will change, which will result in a slower rate of rise and a lower amplitude of the action potential.
The strength of a stimulus needs to be encoded by the neurons. We need to be able to perceive the difference, for example, between a dim light and a bright one. The frequency, or rate, of action potential firing informs the nervous system of stimulus strength.

Since the height of the action potential is always the same for a given neuron, the strength of the stimulus is determined by the frequency of action potential firing. A weak stimulus would cause fewer action potentials to be fired than a strong stimulus.
The action potential moves down the axon due to the influx of sodium depolarizing nearby axon segments to threshold.
Action potentials only move in one direction, from the cell body to the presynaptic terminal. The refractory period keeps the action potential from moving backward down the axon. As the action potential moves from one Node of Ranvier to the next, the inactivated sodium channels in the previous axon segment prevent the membrane from depolarizing again. Therefore, the action potential can only move forward toward axon segments with closed sodium channels ready for rising phase depolarization.
The presence of myelin leads to a significant increase in action potential conduction speed compared to an unmyelinated axon. For a myelinated axon, the action potential “jumps” between Nodes of Ranvier in a process called saltatory conduction. The nodes have a high density of voltage-gated channels, and the action potential is able to skip the axon segments covered by the myelin. In an unmyelinated axon, the action potential moves in a continuous wave. In additional to the saltatory conduction process, the presence of myelin also insulates the axon, preventing charge loss across the membrane, which also increases speed of the action potential.
The diameter of the axon also affects speed. The larger the diameter of the axon, the faster the propagation of the action potential down the axon. A larger axon leads to less resistance against the flow of ions, so the sodium ions are able to move more quickly to cause the regeneration of the action potential in the next axon segment.
In the previous chapter, we covered ion flow and membrane potential changes that occur in the neuron during the action potential. We have this level of understanding about how ions move during the action potential because of a special technique called a voltage clamp experiment that was used in the 1950s. The voltage clamp method allows researchers to study voltage-gated ion channels by controlling the membrane potential of a neuron.
To conduct a voltage clamp experiment, a portion of the axon, which would include the cell membrane and all the voltage-gated ion channels located there, is removed from a neuron and placed into a solution that mimics that of physiological extracellular solution. The ion concentrations across the membrane, as well as the electrochemical gradients, would remain the same.
The initial step in the voltage clamp method is to measure the membrane potential of the axon. A recording electrode is placed into the axon and a reference electrode (or ground electrode) is placed into the extracellular solution. The voltage difference between these two electrodes is the membrane potential of the axon.
The researchers running the experiment can set a desired membrane potential for the cell. The equipment then compares the desired membrane potential with the measured membrane potential from the electrodes. If these values differ, current is injected into the cell to change the measured membrane potential and make it equal to the desired potential.
The equipment continues this cycle for the length of the experiment. It constantly measures and compares the actual membrane potential with the desired potential, and then uses current to correct any changes, “clamping” the potential at one value.
The important aspect of the depolarization seen in the example is that it is above threshold. Moving the membrane potential above threshold will activate the voltage-gated ion channels. Sodium channels will open immediately, and sodium will begin rushing into the cell. This influx of positive ions would normally cause the membrane potential to depolarize, but the voltage clamp equipment will measure the ion flow and inject a current of equal strength and opposite charge into the axon to maintain the membrane potential at 0 mV. This happens almost instantly and is a constant process, so, as the ion flow changes, so does the injected current.
Since the ion channels function as expected during the voltage clamp experiment, the voltage-gated sodium channels will inactivate and the delayed voltage-gated potassium channels will open. This is because, like the sodium channels, they are also activated when the membrane potential reaches threshold. This causes the ion flow to change from inward to outward. Normally, potassium efflux would cause a repolarization of the membrane potential, but the voltage clamp equipment will again inject a current that is equal in strength and opposite in charge to the potassium flow to keep the membrane potential steady at 0 mV.
Researchers can determine how much current is moving through the voltage-gated ion channels by observing how much current the equipment must inject into the cell to keep the membrane potential steady. If the equipment has to inject negative current in for 2 milliseconds, then the researchers know that positive ions were flowing in for 2 milliseconds. The voltage-clamp setup allowed researchers in the 1950s to learn about how the voltage-gated ion channels were functioning during an action potential.
For the nervous system to function, neurons must be able to communicate with each other and they do this through structures called synapses. At the synapse, the terminal of a presynaptic cell comes into close contact with the cell membrane of a postsynaptic neuron.
There are two types of synapses: electrical and chemical.
Electrical synapses are a direct connection between two neurons. Imagine two neurons that are connected by an electrical synapse. First of all, both of them are complete cells on their own. Each one contains a complete plasma membrane surrounding the neuron, a nucleus, and all the individual organelles needed to carry out that cell’s basic life processes.

Cell membrane proteins called connexons form gap junctions between the neurons. The gap junctions form pores that allow ions to flow between neurons, so, as an action potential propagates in the presynaptic neuron, the influx of sodium can move directly into the postsynaptic neuron and depolarize the cell. The response in the postsynaptic cell is almost immediate, with little-to-no delay between signaling in the pre- and postsynaptic neurons.
Since the gap junctions allow diffusion of ions without any obstruction, the signal can flow bidirectionally through an electrical synapse. The electrochemical gradients will drive direction of ion flow.

This means that a signal does not always move sequentially from the presynaptic cell to the postsynaptic cell. Rather, ions and signaling molecules are free to move through the connexons in either direction. Also, each cell within an electrically-coupled network can receive inputs at any of the cells, making it able to detect several signals at once—the same way a huge satellite dish can detect more signals than a small dish.

Electrical synapses likely evolved because of evolutionary pressures that selected for speed. These synapses can pass signals as fast as electrical charges can move through an electrolyte-rich fluid like cytoplasm; almost instantaneous.

Another advantage of electrical synapses is that they can form a large network of interconnected neurons with synchronized activity. For example, neuroendocrine cells in the hypothalamus are connected by electrical synapses. When the “go” signal arrives, all the cells depolarize at once, which can result in the massive release of hormones into the bloodstream. A network can also cause sudden, powerful inhibition. Like an angry mob of people chanting, a network of electrical synapses connecting inhibitory interneurons allows the network to send an immediate “shutdown” signal under specific circumstances.
Electrical synapses share the cytoplasm between the two connected cells, so ions, ATP, and larger signaling molecules and proteins are able to move between the two cells. These signaling molecules play an important role in cellular mechanisms, which we will see in a later chapter.
At a chemical synapse, a signaling molecule is released by the presynaptic cell to influence the postsynaptic cell by binding to postsynaptic receptors. Since chemical synapses do not rely on a direct physical protein “tunnel” to connect the two neurons, the distance between the two cells can be much larger.

On average, a chemical synapse is a distance of about 20-40 nanometers, roughly a thousand times smaller than the diameter of a human hair. A chemical synapse can pass a variety of signals, depending on the neurotransmitter and the receptor. For example, some signals are directly excitatory and allow positively charged cations to enter the neuron causing depolarization. Other signals are hyperpolarizing, and therefore inhibitory. And yet other signals are much more complex, inducing changes in protein expression that can modify cellular excitability over the course of minutes or hours.
At a chemical synapse, the depolarization of an action potential reaching the presynaptic terminal causes release of neurotransmitters. These neurotransmitters are synthesized and stored in neurons. After being released, these neurotransmitters diffuse randomly across the synapse, where they are able to affect nearby neurons once the chemical binds to its corresponding receptor located in the cell membrane of the postsynaptic neuron. The structure and function of chemical synapses make them slower than electrical synapses and permit signaling in only one direction.

Because of the complexity of the signals that chemical synapses can convey, evolutionary development through time has allowed for a tremendous variety of responses. Chemical synapses allow for fine-tuning of neural networks, giving these nervous systems a larger range of possibilities. The nervous systems of “higher” organisms like humans tend to have several chemical synapses since these signals are likely necessary for complex behaviors and cognition.
As we discuss synaptic transmission, we will focus mainly on axodendritic synapses, in which the presynaptic terminal (axon) synapses on the dendrites of the postsynaptic cell. But synapses can also be located between the terminal and the cell body of the postsynaptic cell, called axosomatic, or even between the terminal and the axon of the postsynaptic cell, called axoaxonic.
As we have covered, when an action potential propagates down the axon to the presynaptic terminal, the electrical signal will result in a release of chemical neurotransmitters that will communicate with the postsynaptic cell.

At a chemical synapse, the process of neurotransmitter release is very tightly regulated. If there were no mechanisms to control the release of chemicals at the synapse, nerve cells would deplete their entire stock of neurotransmitter. Regulation of release depends on several proteins that are important parts of the process. These proteins are often embedded within cell membranes of the vesicles or the neuronal membrane.
There are a series of steps that take place during chemical synaptic transmission.

First, an action potential propagates down the axon until it arrives at the axon terminal, depolarizing the membrane of the presynaptic terminal.
When the action potential reaches the terminal, there is an influx of sodium ions. This inward positive current causes a depolarization of the terminal, activating voltage-gated calcium channels that are embedded in the cell membrane of the axon terminals. Due to the electrochemical gradient of calcium, when the voltage-gated calcium channels are opened, calcium will rush into the cell. The concentration of intracellular calcium, generally in the range of 100 nM, is much lower than the concentration outside the cell, therefore there is a strong electrochemical gradient that moves calcium into the terminal. As it turns out, an elevation of Ca2+ in the intracellular space is the “go ahead” signal that causes neurotransmitter release.
The voltage-gated calcium channels are concentrated in the presynaptic terminal at active zones, the regions of the membrane where small molecule neurotransmitters are released. At active zones, some synaptic vesicles are docked and are ready for immediate release upon arrival of the action potential. Other neurotransmitter-filled vesicles remain in a reserve pool outside of the active zone.

Vesicles filled with neuropeptides do not dock at active zones. They are located outside of the active zone, further away from the membrane and the high density of voltage-gated calcium channels. They are, therefore, slower to release than the small molecule transmitters.
Synaptic vesicles can be found in one of three places at the axon terminal.

Readily releasable pool. These vesicles are located close to the cell membrane at the axon terminal. In fact, many of them are already “docked”, meaning that their coat proteins are already interacting closely with the proteins on the inside of the cell membrane. When the depolarizing charge of an action potential reaches the terminal, these vesicles at the readily releasable pool are the first ones that fuse with the cell membrane and release their contents.
Recycling pool. These vesicles are the ones that have been depleted due to release. They are currently in the process of being refilled or reloaded with neurotransmitter. They are farther from the cell membrane, and the protein machinery is not primed for release, so it requires a more intense stimulation to release the contents of these vesicles.
Reserve pool. These vesicles are the farthest from the surface of the cell membrane, and most vesicles are held in this reserve pool. For these neurotransmitters to be released, very intense stimulation is required.
Docking of synaptic vesicles packaged with small molecule neurotransmitters occurs through the interaction of three membrane-bound proteins called SNARE proteins. Synaptobrevin is called a v-SNARE because it is located on the Vesicular membrane. Syntaxin and SNAP-25 are called t-SNARES because they are located on the terminal membrane, which is the Target membrane. The interaction of these three proteins leads to vesicle docking at the active zone.
The influx of calcium through the voltage-gated calcium channels initiates the exocytosis process that leads to neurotransmitter release. Calcium enters the cell and interacts with a vesicle-bound protein called synaptotagmin. Synaptotagmin is a calcium sensor that detects elevated levels of calcium in the axon terminal.

In the presences of calcium, the v-SNAREs and the t-SNAREs interact with one another, forming a molecular structure called a SNARE complex. The SNARE complex looks a lot like two twist ties that are wound tightly together. As they twist tighter together, it causes the vesicle membrane to approach the inside of the cell membrane, which results in vesicular fusion.
The last step of neurotransmitter release is the fusing of the cell membrane. In order to release their chemical contents into the synapse, vesicles need to fuse with the cell membrane. As the vesicular membrane merges with the interior of the neuronal membrane, the membranes fuse and the contents of the vesicle become exposed to the extracellular space. The neurotransmitters then float across the aqueous synapse, giving them the opportunity to interact with postsynaptic receptors.
After exocytosis of the transmitter molecules, neurotransmitters traverse across the synapse and bind to receptors on the postsynaptic membrane. Receptors fall into two main categories: ionotropic receptors (also called ligand-gated channels) and metabotropic receptors (also called G-protein coupled receptors). These two types of receptors will be covered in upcoming chapters.
Recall the process of summation from Chapter 8. The postsynaptic potentials generated from neurotransmitter binding summate at the axon hillock. If the membrane potential is over threshold potential for the cell, then a new action potential will be generated in the postsynaptic cell.

Postsynaptic potentials (graded potentials) can occur following different types of stimulation.

When neurotransmitters bind to receptors on postsynaptic cells, they cause the receptor proteins to undergo a conformational change, and open ligand-gated ion channels that produce depolarization or hyperpolarization.
It is important that neurotransmitter signaling be tightly regulated. This means that there needs to be ways to terminate chemical signaling. Inactivation can be accomplished in three different ways.

After being released, neurotransmitters can be altered into inactive substances.
Neurotransmitters can go through the reuptake process, where they are recycled by being transported back into the presynaptic cell and repackaged into synaptic vesicles.
Some neurotransmitters simply float away from the synapse due to the aqueous environment surrounding neurons.
Neurotransmitters are chemicals that are released at the synapse. In this chapter, we will introduce basic information about neurotransmitters and how they are identified. Next, an overview of neurotransmitter receptors will be provided.

Receptors are proteins located on the postsynaptic cell that are capable of sending a signal to change the function or activity of the postsynaptic neuron. Most receptors that function in neurotransmission are large transmembrane proteins. On the extracellular surface of the protein is a specific series of amino acid residues called the active site. The active site, also called the orthosteric site, is shaped to allow molecules of neurotransmitter to bind to the receptor. Receptors are classified into one of two main categories: Ionotropic receptors and Metabotropic receptors (G-protein coupled receptors).
Neurotransmitters are the chemicals released at the presynaptic terminal that then bind to the postsynaptic cell. A neurotransmitter system is the neurotransmitter and everything needed for the synthesis of the transmitter, the packaging of the transmitter into vesicles, the proteins necessary for reuptake of the transmitter into the presynaptic cell, degradation of the transmitter, and postsynaptic signaling of the transmitter. In the following chapters, we will discuss various neurotransmitter systems.

Though there are neurons that can release more than one type of neurotransmitter (referred to as co-transmitters), most neurons release just one type of neurotransmitter, allowing neurons to be identified by the neurotransmitter they release (e.g. dopaminergic neurons). The different neurotransmitters can be separated into three different chemical categories:

Amino Acids (Glutamate, GABA, Glycine)
Amines (Acetylcholine, Dopamine, Epinephrine, Histamine, Norepinephrine, Serotonin)
Peptides (Dynorphin, Enkephalin, Substance P, Neuropeptide Y)
To identify whether a chemical can be classified as a neurotransmitter, it must meet the following requirements:

The chemical has to be stored or located within the presynaptic neuron. Both immunohistochemistry and immunocytochemistry can use antibodies directed against a specific protein important for neurotransmitter synthesis or storage to localize the protein to a neuron and determine whether a neuron has the appropriate machinery to make the neurotransmitter and thus likely release the neurotransmitter.
The chemical has to be released from the presynaptic neuron following appropriate stimulation.
When the chemical is applied to the postsynaptic cell by an experimenter, the response of the postsynaptic cell should be similar to the response following normal release from the presynaptic cell.
Neurotransmitters can be classified on their function as either ‘excitatory’ or ‘inhibitory’. In the following chapters, we will see that glutamate is an example of an excitatory neurotransmitter. This is because the binding of glutamate to the postsynaptic cell typically generates excitatory postsynaptic potentials, which makes the inside of the cell closer to zero and thus closer to threshold potential for the cell, increasing the likelihood of firing an action potential. GABA and Glycine, however, are typically considered as inhibitory neurotransmitters. This is because the binding of either GABA or glycine to the postsynaptic cell typically generates inhibitory postsynaptic potentials, which makes the inside of the cell more negative and further from threshold potential of the cell, decreasing the likelihood of firing an action potential. 

Most neurotransmitters, however, can produced either excitatory postsynaptic potentials or inhibitory postsynaptic potentials depending on the properties of the postsynaptic receptor that they bind to. Neurotransmitters each bind to specific receptors that produce specific postsynaptic responses.

The subsequent chapters will review the main neurotransmitters including their synthesis, storage, and their receptors.
Ionotropic receptors are also called neurotransmitter-gated or ligand-gated channels. They are ion channels that open in response to the binding of a neurotransmitter. They are primarily located along the dendrites or cell body, but they can be present anywhere along the neuron if there is a synapse. Ionotropic receptors are important for receiving incoming information from other neurons.
Physically, ionotropic receptors are transmembrane proteins with a large-diameter pore through which ions can pass. Although ionotropic receptors are ion channels, they open in a different way than the voltage-gated ion channels needed for propagation of the action potential. The ionotropic receptors are ligand-gated, which means that a specific molecule, such as a neurotransmitter, must bind to the receptor to cause the channel to open and allow ion flow. As seen in previous chapters, the voltage-gated channels open in response to the membrane potential reaching threshold (a specific voltage).

Ionotopic channels are often said to use a direct signaling mechanism because the neurotransmitter binds directly to the ion channel that it is going to open.
These channels only open when a specific ligand binds to the active site on the extracellular side of the protein. Neurotransmitters and receptors fit together like a lock and key; only certain neurotransmitters are able to bind to and open certain receptors.

Once a neurotransmitter activates the ionotropic receptor, ions will move through the channel based on the electrochemical gradient for that ion. As a result of ion movement, the cell’s membrane potential will change. For example, if the ionotropic channel allowed for movement of sodium, the electrochemical gradient for sodium will promote sodium rushing into the cell, causing the inside of the cell to get more positive (decrease in membrane potential).

Ionotropic receptors are able to induce a change in membrane potential very rapidly, on the scale of milliseconds. Due to the nature of the amino acid residues that make up the pore of ionotropic receptors, they can be very selective for certain ions. For example, negatively charged residues lining the inside of the pore repel negatively charged Cl– ions while allowing positively charged cations to pass through the channel.
Metabotropic receptors (also called G-protein-coupled receptors [GPCRs]), are membrane-bound proteins. These receptor complexes cause the cell to change its metabolism in a way that leads to either excitation or inhibition of the postsynaptic cell. Like ionotropic receptors, metabotropic receptors are primarily located along the dendrites or cell body, but they can be present anywhere along the neuron if there is a synapse.

Unlike ionotropic receptors (direct mechanism), ions do not pass through GPCRs. Instead, metabotropic receptors use the actions of G proteins, proteins which induce changes in neuronal excitability through the action of second messenger signaling molecules. Due to these extra steps, GPCRs have slower effects than ionotropic receptors, but they can have long-lasting effects, unlike the brief action of a postsynaptic potential.
G-proteins are enzymes with three subunits: alpha, beta, and gamma. There are multiple types of alpha subunits (Gαs, Gαi, Gαq), and each initiate different cellular cascades in the neuron.

Functionally speaking, these G-proteins are capable of binding to molecules of guanosine triphosphate (GTP) or guanosine diphosphate (GDP). Chemically similar to ATP, GTP can function as a source of energy. G-proteins themselves exhibit catalytic activity of GTP. This means that they are capable of breaking down GTP into the less-energetic GDP. When GTP is bound to the GPCR, the receptor is active. When this molecule is hydrolyzed into GDP, the receptor becomes inactive.
A metabotropic receptor or GPCR is a transmembrane protein that has an extracellular binding site for a neurotransmitter. Metabotropic receptors are physically linked to G-proteins, which exist on the inner surface of the cell membrane.

When a neurotransmitter binds to a GPCR it undergoes a conformational change, which allows the receptor to interact with an associated inactivated G-protein complex.

The complex that binds is specific to the receptor; different metabotropic receptors for the same neurotransmitter can have different effects in the cell due to which G-protein binds. Once coupled to the receptor, the GDP molecule is exchanged for a GTP molecule and the G-protein becomes activated.
After activation, the G-protein complex will separate into the alpha-GTP subunit and the beta-gamma subunit. Both components can alter the function of effector proteins in the cell. Effector protein functions can range from altering ion permeability across the membrane by opening ion channels to initiating second messenger cascades. Second messenger cascades can have long-term, widespread, and diverse cellular effects including activation of cellular enzymes or altering gene transcription.
The cyclic AMP (cAMP) second messenger pathway is used by many GPCRs. When a neurotransmitter binds to a GPCR, it causes activation of the Gαs alpha subunit. The Gαs subunit (“s” for stimulatory) translocates within the cell to stimulate an effector enzyme called adenylyl cyclase. When activated, adenylyl cyclase converts ATP to cAMP in the cytoplasm. cAMP is considered a 2nd messenger (the 1st messenger was the neurotransmitter). As a second messenger, cAMP has the ability to alter proteins inside the cell. Specifically, cAMP activates another enzyme called protein kinase A (PKA) by binding to the regulatory subunits, allowing the catalytic (functional) subunits to separate and become active. PKA is a kinase, a group of enzymes that add a phosphate molecule to proteins, a mechanism called phosphorylation. The addition of the phosphate changes the activity of the protein and how it functions in the cell. Typically, phosphorylation activates proteins within the cell.
The end effects of this pathway will depend on which proteins are targeted. For example, cAMP can gate ion channels and PKA can phosphorylate ion channels altering permeability and membrane potential. Phosphorylation can open the channel, or it may modulate the activity of the channel, making the channel easier to open or remain open longer.
In addition to altering ion channel function, PKA can phosphorylate other proteins important for neuron function, such as proteins involved with neurotransmitter synthesis and release. One other critical target of PKA phosphorylation is the transcription factor CREB (cAMP response element-binding protein). Transcription factors bind to DNA in the nucleus and change the rate of gene transcription. Phosphorylation by PKA can cause CREB to initiate transcription of genes, creating new proteins for the neuron. Depending on which genes are transcribed, the effects on the neuron can be long-lasting.

Overall, neurotransmitters working through GPCRs and second messenger cascades (like the adenylyl cyclase pathway) can cause a diverse range of cellular effects: from opening ion channels, to changing protein activity via phosphorylation, to altering the proteins synthesized in the neuron.
Alternatively, a GPCR that is coupled with Gαi causes a decrease in excitability. In many ways, Gαi proteins serve the opposite function as Gαs proteins—the “i” stands for inhibitory. Whereas activation of Gαs increases the action of adenylyl cyclase, Gαi proteins decrease adenylyl cyclase activity. Therefore, Gαi activation decreases the intracellular concentration of cAMP, in turn decreasing PKA activity. Given the function of PKA as a kinase that increases cellular excitation as described above, a GPCR coupled to Gαi that causes decreased PKA activity inhibits cellular activity through multiple mechanisms, some of which include decreased current through receptors, decreased trafficking of receptors to the presynaptic neuronal membrane, and decreased transcription of certain genes.
Generally, Gαq is an excitatory G-protein alpha subunit. The Gαq subunit initiates a separate signaling pathway in the cell by activating the effector enzyme phospholipase C. Phospholipase C targets PIP2 (phosphatidylinositol 4,5-bisphosphate), which is a phospholipid present in the plasma membrane of the cell. PLC will split PIP2 into two separate second messenger molecules: the soluble IP3 (inositol 1,4,5-trisphosphate) and membrane-embedded DAG (diacylglycerol).
DAG remains in the membrane and interacts with protein kinase C (PKC). PKC is an enzyme that can act to increase neurotransmitter release probability.

One function of IP3 is to move to the endoplasmic reticulum, where it opens calcium channels embedded in the endoplasmic reticulum and allows calcium to flow into the cytosol, elevating intracellular calcium levels. This increase in calcium concentration can depolarize the cell and activate calcium-dependent processes, which often lead to cellular excitation.

Calcium also acts as a second messenger in the cell. One important effect is the binding of calcium to the calmodulin protein. This complex can then activate another kinase, the calcium/calmodulin-dependent protein kinase (CaMK). Both PKC and CaMK can phosphorylate specific cellular and nuclear proteins like PKA.

So, depending on the type of Gα subunit that the G-protein is associated with, there will be different outcomes for the cell. In general, Gαs will “stimulate” the cell by activating adenylyl cyclase. Gαi will “inhibit” the cell by inhibiting adenylyl cyclase. Gαq will “stimulate” the cell by activating phospholipase C.
One characteristic of GPCR activation is the signal amplification that takes place. One receptor is able to activate more than one G-protein complex. The effector protein activated by the G-protein can create many second messengers, and the activated protein kinases can each phosphorylate multiple cellular proteins. This means that one neurotransmitter can have a significant effect on cellular function.
Eventually, the cascade initiated by binding of the neurotransmitter to the GPCR needs to end. The alpha subunit of the G-protein is able to convert the bound GTP back to GDP after a short period of time, inactivating the G-protein. The alpha subunit will then interact with a beta-gamma subunit and stay in the resting state until activated by another GPCR. Enzymes in the cell called protein phosphatases find and remove the phosphate groups added to cellular proteins by the protein kinases. Finally, other cellular mechanisms exist to remove calcium from the cytoplasm and degrade other second messengers.
Neurotransmitters are chemicals that are released at the synapse. In this chapter, we will introduce basic information about neurotransmitters and how they are identified. Next, an overview of neurotransmitter receptors will be provided.

Receptors are proteins located on the postsynaptic cell that are capable of sending a signal to change the function or activity of the postsynaptic neuron. Most receptors that function in neurotransmission are large transmembrane proteins. On the extracellular surface of the protein is a specific series of amino acid residues called the active site. The active site, also called the orthosteric site, is shaped to allow molecules of neurotransmitter to bind to the receptor. Receptors are classified into one of two main categories: Ionotropic receptors and Metabotropic receptors (G-protein coupled receptors).
Neurotransmitters are the chemicals released at the presynaptic terminal that then bind to the postsynaptic cell. A neurotransmitter system is the neurotransmitter and everything needed for the synthesis of the transmitter, the packaging of the transmitter into vesicles, the proteins necessary for reuptake of the transmitter into the presynaptic cell, degradation of the transmitter, and postsynaptic signaling of the transmitter. In the following chapters, we will discuss various neurotransmitter systems.

Though there are neurons that can release more than one type of neurotransmitter (referred to as co-transmitters), most neurons release just one type of neurotransmitter, allowing neurons to be identified by the neurotransmitter they release (e.g. dopaminergic neurons). The different neurotransmitters can be separated into three different chemical categories:

Amino Acids (Glutamate, GABA, Glycine)
Amines (Acetylcholine, Dopamine, Epinephrine, Histamine, Norepinephrine, Serotonin)
Peptides (Dynorphin, Enkephalin, Substance P, Neuropeptide Y)
To identify whether a chemical can be classified as a neurotransmitter, it must meet the following requirements:

The chemical has to be stored or located within the presynaptic neuron. Both immunohistochemistry and immunocytochemistry can use antibodies directed against a specific protein important for neurotransmitter synthesis or storage to localize the protein to a neuron and determine whether a neuron has the appropriate machinery to make the neurotransmitter and thus likely release the neurotransmitter.
The chemical has to be released from the presynaptic neuron following appropriate stimulation.
When the chemical is applied to the postsynaptic cell by an experimenter, the response of the postsynaptic cell should be similar to the response following normal release from the presynaptic cell.
Neurotransmitters can be classified on their function as either ‘excitatory’ or ‘inhibitory’. In the following chapters, we will see that glutamate is an example of an excitatory neurotransmitter. This is because the binding of glutamate to the postsynaptic cell typically generates excitatory postsynaptic potentials, which makes the inside of the cell closer to zero and thus closer to threshold potential for the cell, increasing the likelihood of firing an action potential. GABA and Glycine, however, are typically considered as inhibitory neurotransmitters. This is because the binding of either GABA or glycine to the postsynaptic cell typically generates inhibitory postsynaptic potentials, which makes the inside of the cell more negative and further from threshold potential of the cell, decreasing the likelihood of firing an action potential. 

Most neurotransmitters, however, can produced either excitatory postsynaptic potentials or inhibitory postsynaptic potentials depending on the properties of the postsynaptic receptor that they bind to. Neurotransmitters each bind to specific receptors that produce specific postsynaptic responses.

The subsequent chapters will review the main neurotransmitters including their synthesis, storage, and their receptors.
Ionotropic receptors are also called neurotransmitter-gated or ligand-gated channels. They are ion channels that open in response to the binding of a neurotransmitter. They are primarily located along the dendrites or cell body, but they can be present anywhere along the neuron if there is a synapse. Ionotropic receptors are important for receiving incoming information from other neurons.
Physically, ionotropic receptors are transmembrane proteins with a large-diameter pore through which ions can pass. Although ionotropic receptors are ion channels, they open in a different way than the voltage-gated ion channels needed for propagation of the action potential. The ionotropic receptors are ligand-gated, which means that a specific molecule, such as a neurotransmitter, must bind to the receptor to cause the channel to open and allow ion flow. As seen in previous chapters, the voltage-gated channels open in response to the membrane potential reaching threshold (a specific voltage).

Ionotopic channels are often said to use a direct signaling mechanism because the neurotransmitter binds directly to the ion channel that it is going to open.
These channels only open when a specific ligand binds to the active site on the extracellular side of the protein. Neurotransmitters and receptors fit together like a lock and key; only certain neurotransmitters are able to bind to and open certain receptors.

Once a neurotransmitter activates the ionotropic receptor, ions will move through the channel based on the electrochemical gradient for that ion. As a result of ion movement, the cell’s membrane potential will change. For example, if the ionotropic channel allowed for movement of sodium, the electrochemical gradient for sodium will promote sodium rushing into the cell, causing the inside of the cell to get more positive (decrease in membrane potential).

Ionotropic receptors are able to induce a change in membrane potential very rapidly, on the scale of milliseconds. Due to the nature of the amino acid residues that make up the pore of ionotropic receptors, they can be very selective for certain ions. For example, negatively charged residues lining the inside of the pore repel negatively charged Cl– ions while allowing positively charged cations to pass through the channel.
Metabotropic receptors (also called G-protein-coupled receptors [GPCRs]), are membrane-bound proteins. These receptor complexes cause the cell to change its metabolism in a way that leads to either excitation or inhibition of the postsynaptic cell. Like ionotropic receptors, metabotropic receptors are primarily located along the dendrites or cell body, but they can be present anywhere along the neuron if there is a synapse.

Unlike ionotropic receptors (direct mechanism), ions do not pass through GPCRs. Instead, metabotropic receptors use the actions of G proteins, proteins which induce changes in neuronal excitability through the action of second messenger signaling molecules. Due to these extra steps, GPCRs have slower effects than ionotropic receptors, but they can have long-lasting effects, unlike the brief action of a postsynaptic potential.G-proteins are enzymes with three subunits: alpha, beta, and gamma. There are multiple types of alpha subunits (Gαs, Gαi, Gαq), and each initiate different cellular cascades in the neuron.

Functionally speaking, these G-proteins are capable of binding to molecules of guanosine triphosphate (GTP) or guanosine diphosphate (GDP). Chemically similar to ATP, GTP can function as a source of energy. G-proteins themselves exhibit catalytic activity of GTP. This means that they are capable of breaking down GTP into the less-energetic GDP. When GTP is bound to the GPCR, the receptor is active. When this molecule is hydrolyzed into GDP, the receptor becomes inactive.

A metabotropic receptor or GPCR is a transmembrane protein that has an extracellular binding site for a neurotransmitter. Metabotropic receptors are physically linked to G-proteins, which exist on the inner surface of the cell membrane.

When a neurotransmitter binds to a GPCR it undergoes a conformational change, which allows the receptor to interact with an associated inactivated G-protein complex.

The complex that binds is specific to the receptor; different metabotropic receptors for the same neurotransmitter can have different effects in the cell due to which G-protein binds. Once coupled to the receptor, the GDP molecule is exchanged for a GTP molecule and the G-protein becomes activated.
After activation, the G-protein complex will separate into the alpha-GTP subunit and the beta-gamma subunit. Both components can alter the function of effector proteins in the cell. Effector protein functions can range from altering ion permeability across the membrane by opening ion channels to initiating second messenger cascades. Second messenger cascades can have long-term, widespread, and diverse cellular effects including activation of cellular enzymes or altering gene transcription.
The cyclic AMP (cAMP) second messenger pathway is used by many GPCRs. When a neurotransmitter binds to a GPCR, it causes activation of the Gαs alpha subunit. The Gαs subunit (“s” for stimulatory) translocates within the cell to stimulate an effector enzyme called adenylyl cyclase. When activated, adenylyl cyclase converts ATP to cAMP in the cytoplasm. cAMP is considered a 2nd messenger (the 1st messenger was the neurotransmitter). As a second messenger, cAMP has the ability to alter proteins inside the cell. Specifically, cAMP activates another enzyme called protein kinase A (PKA) by binding to the regulatory subunits, allowing the catalytic (functional) subunits to separate and become active. PKA is a kinase, a group of enzymes that add a phosphate molecule to proteins, a mechanism called phosphorylation. The addition of the phosphate changes the activity of the protein and how it functions in the cell. Typically, phosphorylation activates proteins within the cell.
The end effects of this pathway will depend on which proteins are targeted. For example, cAMP can gate ion channels and PKA can phosphorylate ion channels altering permeability and membrane potential. Phosphorylation can open the channel, or it may modulate the activity of the channel, making the channel easier to open or remain open longer.
In addition to altering ion channel function, PKA can phosphorylate other proteins important for neuron function, such as proteins involved with neurotransmitter synthesis and release. One other critical target of PKA phosphorylation is the transcription factor CREB (cAMP response element-binding protein). Transcription factors bind to DNA in the nucleus and change the rate of gene transcription. Phosphorylation by PKA can cause CREB to initiate transcription of genes, creating new proteins for the neuron. Depending on which genes are transcribed, the effects on the neuron can be long-lasting.

Overall, neurotransmitters working through GPCRs and second messenger cascades (like the adenylyl cyclase pathway) can cause a diverse range of cellular effects: from opening ion channels, to changing protein activity via phosphorylation, to altering the proteins synthesized in the neuron.
Alternatively, a GPCR that is coupled with Gαi causes a decrease in excitability. In many ways, Gαi proteins serve the opposite function as Gαs proteins—the “i” stands for inhibitory. Whereas activation of Gαs increases the action of adenylyl cyclase, Gαi proteins decrease adenylyl cyclase activity. Therefore, Gαi activation decreases the intracellular concentration of cAMP, in turn decreasing PKA activity. Given the function of PKA as a kinase that increases cellular excitation as described above, a GPCR coupled to Gαi that causes decreased PKA activity inhibits cellular activity through multiple mechanisms, some of which include decreased current through receptors, decreased trafficking of receptors to the presynaptic neuronal membrane, and decreased transcription of certain genes.
Generally, Gαq is an excitatory G-protein alpha subunit. The Gαq subunit initiates a separate signaling pathway in the cell by activating the effector enzyme phospholipase C. Phospholipase C targets PIP2 (phosphatidylinositol 4,5-bisphosphate), which is a phospholipid present in the plasma membrane of the cell. PLC will split PIP2 into two separate second messenger molecules: the soluble IP3 (inositol 1,4,5-trisphosphate) and membrane-embedded DAG (diacylglycerol).
DAG remains in the membrane and interacts with protein kinase C (PKC). PKC is an enzyme that can act to increase neurotransmitter release probability.

One function of IP3 is to move to the endoplasmic reticulum, where it opens calcium channels embedded in the endoplasmic reticulum and allows calcium to flow into the cytosol, elevating intracellular calcium levels. This increase in calcium concentration can depolarize the cell and activate calcium-dependent processes, which often lead to cellular excitation.

Calcium also acts as a second messenger in the cell. One important effect is the binding of calcium to the calmodulin protein. This complex can then activate another kinase, the calcium/calmodulin-dependent protein kinase (CaMK). Both PKC and CaMK can phosphorylate specific cellular and nuclear proteins like PKA.

So, depending on the type of Gα subunit that the G-protein is associated with, there will be different outcomes for the cell. In general, Gαs will “stimulate” the cell by activating adenylyl cyclase. Gαi will “inhibit” the cell by inhibiting adenylyl cyclase. Gαq will “stimulate” the cell by activating phospholipase C.
One characteristic of GPCR activation is the signal amplification that takes place. One receptor is able to activate more than one G-protein complex. The effector protein activated by the G-protein can create many second messengers, and the activated protein kinases can each phosphorylate multiple cellular proteins. This means that one neurotransmitter can have a significant effect on cellular function.
Eventually, the cascade initiated by binding of the neurotransmitter to the GPCR needs to end. The alpha subunit of the G-protein is able to convert the bound GTP back to GDP after a short period of time, inactivating the G-protein. The alpha subunit will then interact with a beta-gamma subunit and stay in the resting state until activated by another GPCR. Enzymes in the cell called protein phosphatases find and remove the phosphate groups added to cellular proteins by the protein kinases. Finally, other cellular mechanisms exist to remove calcium from the cytoplasm and degrade other second messengers.
Neurotransmitters are the substances that are released at chemical synapses, and they are the signaling molecules that allow neurons to communicate with one another. To date, scientists have identified more than 100 neurotransmitters.

A few criteria must be met for a molecule to be called a neurotransmitter. First, the neurotransmitter must be synthesized within the presynaptic neuron. Second, the neurotransmitter must be released by the presynaptic neuron in response to stimulation. Third, when a postsynaptic neuron is treated with the neurotransmitter by a researcher, the molecule must cause the same effect in the postsynaptic neuron as when it is released by a presynaptic neuron.

The next several chapters will cover a subset of neurotransmitter systems. For each neurotransmitter system, we will provide information on: the synthesis and storage of the neurotransmitter in the presynaptic cell; the receptors that the neurotransmitter binds to on the postsynaptic cell and the postsynaptic effects; and how neurotransmitter signaling is terminated.
There are two main categories of neurotransmitters: small molecule neurotransmitters and peptide neurotransmitters (covered in Chapter 19). Synthesis and storage of these neurotransmitter groups differ. Small molecule neurotransmitters are synthesized and stored in the terminal for fast release. Neuropeptides are synthesized in the cell body and must be transported to the terminal, which can lead to slower release. Additionally, a neuron typically will synthesize and release only one type of small molecule neurotransmitter, but can synthesize and release more than one neuropeptide.

Molecules of neurotransmitters are often stored in synaptic vesicles before being released. Synaptic vesicles are tiny spheres of neurotransmitter enclosed by a phospholipid bilayer just like the cell membrane. These vesicles can be roughly characterized into two classes:

Small vesicles. Small vesicles are responsible for storage of small molecule neurotransmitters. Given the size of neurotransmitters, we can estimate that thousands to tens of thousands of molecules of neurotransmitter can be stored in each vesicle. Small vesicles store many of the neurotransmitters we most often think of, including glutamate, GABA, dopamine, and norepinephrine. Small vesicles are almost always exclusively found in the axon terminals.
Large dense-core vesicles. These vesicles are much larger than small vesicles. They store peptides such as dynorphin or enkephalin, which have chemical structures much larger than the small molecule neurotransmitters. Since these peptides are packaged into their vesicles near the nucleus, large dense-core vesicles can be found in the cell bodies and all along the axons in addition to the axon terminal.
Let’s first discuss the small molecule neurotransmitters. The small molecule neurotransmitters can be divided into two main groups: amino acid neurotransmitters and biogenic amines (also called monoamines). In addition to acting as neurotransmitters, the amino acids glutamate and glycine are used to synthesize proteins in all cell types throughout the body. GABA (Ɣ-Aminobutyric acid) is a metabolite of glutamate, but is not used in protein synthesis in the body. The biogenic amines include serotonin, histamine, and the subgroup catecholamines: dopamine, norepinephrine, and epinephrine. Acetylcholine does not fit into either division but is still considered a small molecule neurotransmitter.

Most small molecule neurotransmitters are synthesized by enzymes that are located in the cytoplasm (the exception is norepinephrine, see Chapter 17). This means that small molecule neurotransmitters can be synthesized and packaged for storage in the presynaptic terminal using enzymes present in the terminal.
In the last chapter, the mechanisms of ionotropic and metabotropic (GPCRs) were covered. In the chapters that follow, we will focus on a subset of neurotransmitter systems and identify the different neurotransmitter receptors and their function.
Acetylcholine was the first neurotransmitter discovered and chemically isolated, a feat which earned two researchers the shared Nobel Prize in Physiology or Medicine in 1936. One of the two scientists, a German pharmacologist named Otto Loewi, stimulated the vagus nerve connected to an isolated frog heart, which caused the heart rate to slow down. When he applied the surrounding solution from this experiment to a second heart, he observed that the second heart also slowed down, despite having no physical connection to the first heart. From this, he concluded that a chemical was being released by the vagus nerve that was decreasing the heart rate. This chemical was first called Vagusstoff, the German word meaning Vagus substance. Today, we know it as acetylcholine.

Acetylcholine (ACh) is a small molecule neurotransmitter best known for its role at the neuromuscular junction, the synapse between a motor neuron and a muscle fiber. In the presynaptic terminal, acetylcholine is synthesized from acetyl coenzyme A (acetyl CoA) and choline via the enzyme choline acetyltransferase (ChAT). The level of enzyme activity is the rate-limiting step in the synthesis pathway. The presence of ChAT in a neuron is used as a biochemical marker for neurons that produce acetylcholine. Acetylcholine is packaged into small vesicles for storage in the terminal via the vesicular acetylcholine transporter (VAChT), a protein found in the synaptic vesicle membrane.
Acetylcholine is able to act at both ionotropic and metabotropic receptors, and activity at both receptor classes is essential for normal function. The ionotropic receptors of the nervous system are called nicotinic acetylcholine receptors because they can be activated by nicotine in addition to acetylcholine. Nicotinic receptors are located primarily outside of the central nervous system in the periphery. Specifically, the nicotinic receptors are used at the neuromuscular junction, which is the junction of a motor neuron and a skeletal muscle. Acetylcholine is released by motor neurons, where it activates nicotinic acetylcholine receptors on skeletal muscle cells. This excites the muscle cells and causes them to contract.

Nicotinic acetylcholine receptors are non-selective cation channels. The channel is closed when acetylcholine is not bound to the receptor. The nicotinic receptor has two binding sites for acetylcholine. When acetylcholine is bound to both sites on the receptor, the pore of the channel opens to allow movement of both sodium and potassium. This ionotropic receptor is an example of a direct mechanism of action, due to the fact that the receptor and the channel are located on the same protein. The properties of the receptors cause more sodium to enter than potassium leaves, ultimately causing the membrane to depolarize. Thus, nicotinic receptors are always excitatory (produce EPSPs) and cause depolarization of the postsynaptic cell.

On the other hand, muscarinic acetylcholine receptors are GPCRs (or metabotropic receptors) and utilize an indirect mechanism of action. When acetylcholine binds to muscarinic receptors, the beta-gamma subunit of the G-protein complex translocates in the cell to affect potassium channels in the cell membrane, causing them to open. Due to the electrochemical gradient of potassium, potassium will leave the cell and cause membrane hyperpolarization, or IPSPs.

Muscarinic receptors are located in the heart, and their activation causes a decrease in heart rate due to this hyperpolarization caused by the muscarinic receptors (as Otto Loewi demonstrated with the isolated frog heart preparation.)
Different drugs have the ability to interact within a neurotransmitter system, in many cases by directly interacting with a neurotransmitter receptor protein. There are two main classes of drugs that we will discuss: agonists and antagonists. An agonist is a drug that binds to a receptor and acts to activate the normal function of that receptor. An antagonist is a drug that binds to a receptor that acts to block the normal function of that receptor. The acetylcholine neurotransmitter system can be used as an example to see the function of both agonists and antagonists.
Nicotine is an agonist for the nicotinic acetylcholine receptor (which is how the receptor got its name). Normally, the nicotinic receptor causes excitatory postsynaptic potentials. Because nicotine is an agonist for this receptor, when it binds to the nicotinic acetylcholine receptor it also causes excitatory post synaptic potentials and lead to an overall increase in activity.

There are also antagonists for the nicotinic acetylcholine receptor. Curare, a substance that comes from the resin of a tree in South America and α-bungarotoxin, a toxin found in Krait snake venom, are both examples of antagonists for the nicotinic acetylcholine receptor. Recall that normally the nicotinic acetylcholine receptor causes excitatory post synaptic potentials. As antagonists, curare and α-bungarotoxin will block excitatory postsynaptic potentials, leading to an overall decrease in activity.
Muscarine, a substance found in certain mushrooms, is an agonist for the muscarinic receptor (and how the receptor got its name). As an agonist, muscarine will promote the normal function of the receptor. Normally, muscarinic receptors produce inhibitory post synaptic potentials. Thus, muscarine binding to muscarinic receptor will cause inhibitory post synaptic potentials, causing an overall decrease in activity.

Atropine is a drug that acts as an antagonist at the muscarinic receptor. Antagonists block the normal function of the receptor. Because normally the muscarinic receptor is inhibitory, atropine will block the normal inhibitory effects, leading to an overall increase in activity.
The enzyme acetylcholinesterase, located in the synaptic cleft and within the postsynaptic membrane, chemically breaks down acetylcholine into acetic acid and choline.

Choline can also undergo the process of reuptake which will remove choline from the synapse (which will effectively stop acetylcholine signaling) and bring it into the presynaptic cell through the choline transporter. Acetylcholinesterase is an important enzyme to regulate acetylcholine within the body. Recall that acetylcholine is used at the neuromuscular junction between motor neurons and skeletal muscles. The acetylcholinesterase enzyme prevents continuous stimulation of our muscles, allowing tight control. In fact, acetylcholinesterase is one of the fastest acting enzymes within the body. Nerve gas and neostigmine (in Nigerian beans) both act to inhibit acetylcholinesterase, causing excessive acetylcholine signaling.
Glutamate is an amino acid transmitter and is the primary excitatory neurotransmitter in the brain. Glutamate is the same as the amino acid glutamic acid. There is more glutamate per volume of brain tissue than any other neurotransmitter.

In the presynaptic terminal, glutamine is converted into glutamate via the enzyme glutaminase, which is the rate-limiting step in the synthesis pathway. Glutamate is packaged into small vesicles for storage via the vesicular glutamate transporter (vGLUT). Staining for the presence of vGLUT is one way that researchers are able to identify glutamatergic neurons.
Glutamate can activate both ionotropic and metabotropic receptors. Glutamate is the primary excitatory neurotransmitter in the central nervous system and opens non-selective cation channels. There are three subtypes of ionotropic glutamate receptors: AMPA, kainate, and NMDA receptors.

The AMPA (α-amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid) and kainate receptors allow both sodium and potassium to cross the membrane. Although potassium can leave the cell when the receptors open, the electrochemical gradient driving sodium ion movement is stronger than the gradient driving potassium movement, resulting in a depolarization of the membrane potential.
The NMDA (N-methyl-D-aspartate) receptor requires the binding of glutamate to open, but it is also dependent on voltage. When the membrane potential is below, at, or near rest, a magnesium ion blocks the open NMDA receptor and prevents other ions from moving through the channel. Once the cell depolarizes, the magnesium block is expelled from the receptor, which allows sodium, potassium, and calcium to cross the membrane. The voltage change needed to open the NMDA receptor is usually a result of AMPA receptor activation.
Glutamate action is terminated by two mechanisms. Reuptake of glutamate molecules into the presynaptic terminal can occur, or glutamate can be transported into nearby glial cells. The excitatory amino acid transporters are sodium co-transporters and use the sodium electrochemical gradient to drive neurotransmitter transport. Within glial cells, glutamate is converted into glutamine by glutamine synthetase. Glutamine is then transported out of the glial cell and back into the presynaptic terminal for use in future glutamate synthesis. If glutamate is transported back into the presynaptic terminal, it can be repackaged in synaptic vesicles.
Glutamate is then used to synthesize Gamma-aminobutyric acid (GABA), the main inhibitory neurotransmitter in the brain. According to one estimate, about 25% of neurons in the brain are GABAergic.

In the presynaptic terminal, glutamate is converted into GABA via the enzyme glutamic acid decarboxylase (GAD), which—like the other synthesis pathways—is the rate-limiting step. GAD is often used as a biochemical marker for the presence of GABAergic neurons.  GABA is packaged into small vesicles for storage in the terminal via the vesicular inhibitory amino acid transporter (VIAAT).

Glycine is another inhibitory amino acid neurotransmitter, but unlike GABA, is mostly used by neurons of the spinal cord and brain stem. Serine hydroxymethyltransferase converts the amino acid serine into glycine in the presynaptic terminal. The rate-limiting step for glycine synthesis occurs earlier in the pathway prior to serine synthesis. Glycine is packaged into small vesicles by the vesicular inhibitory amino acid transporter (VIAAT) like GABA.
GABA and glycine receptors are chloride channels. Since an increase in chloride permeability across the membrane is inhibitory, the binding of GABA or glycine to their respective ionotropic receptor will cause inhibition.
Like glutamate, GABA and glycine action are terminated by either reuptake into the presynaptic terminal and packaging in synaptic vesicles or through transport into glial cells where breakdown can occur. The GABA and glycine transporter also use the sodium electrochemical gradient to drive the movement of the transmitter across the membrane.
The biogenic amines encompass multiple neurotransmitters, including serotonin, histamine, dopamine, norepinephrine, and epinephrine. Included within the biogenic amines is a separate group of neurotransmitters, the catecholamines.

This chapter will provide information for only serotonin and histamine. Catecholamines are covered in the following chapter.
Serotonin, a biogenic amine neurotransmitter, is known for its role in mood. As with dopamine (another monoamine neurotransmitter), there are only a few areas of the brain that synthesize serotonin, the major one being the Raphe nucleus in the brain stem.
The enzyme tryptophan hydroxylase is the first step of serotonin biosynthesis, converting the amino acid tryptophan into 5-hydroxytryptophan and is often used as a marker to identify serotonergic neurons. This is also the rate-limiting step of the synthesis pathway. Then aromatic L-amino acid decarboxylase converts the 5-hydroxytryptophan into serotonin. Serotonin is packaged into small vesicles by the vesicular monoamine transporter similar to the other monoamine neurotransmitters: dopamine, norepinephrine, and epinephrine.

Serotonin binds to many different classes of receptors, including both ionotropic and metabotropic receptors. Most of the serotonin receptors are metabotropic receptors that utilize G-proteins to cause the opening of ion channels, or alter the activity of phospholipase C or adenylyl cyclase. Due to the large number of different serotonin receptors, the effects of serotonin can vary depending on the properties of the postsynaptic receptor. Only one class of serotonin receptors are ligand-gated ion channels and utilize a direct mechanism of action.
Like the other monoamines, serotonin goes through reuptake and is transported back into the presynaptic terminal via the serotonin transporter (SERT). The difference between serotonin and the catecholamines dopamine, norepinephrine, and epinephrine is that monoamine oxidase is the only enzyme used for degradation.
Finally, histamine is another biogenic amine transmitter that is synthesized from histidine through the action of histamine decarboxylase, the rate-limiting step of the pathway. Like the other monoamine neurotransmitters, it is packaged into small synaptic vesicles via the vesicular monoamine transporter.

Though histamine has known roles in the immune system with allergic reactions and the inflammatory response, this chemical can also act as a hormone and a neurotransmitter within the central nervous system.
Catecholamines are a class of neurotransmitters that are found within the larger class of neurotransmitters, biogenic amines. The catecholamines share many characteristics.
Dopamine, a catecholamine transmitter, plays many roles in the nervous system, but it is best known for its roles in reward and movement.
In the presynaptic terminal, the amino acid tyrosine is converted into DOPA via tyrosine hydroxylase, which is the rate-limiting step in the synthesis of all the catecholamines. DOPA is then converted to dopamine by DOPA decarboxylase. Dopamine is packaged into small synaptic vesicles by the vesicular monoamine transporter (VMAT).

Unlike glutamate or GABA, dopamine-producing neurons are not widely abundant in the brain. Instead, there are generally only a few patches of neurons that produce dopamine, most of which are found in the midbrain. Two areas include the ventral tegmental area and the substantia nigra.
Dopamine binds to metabotropic receptors on postsynaptic cells. There are two classes of dopamine metabotropic receptors: D1-like receptors and D2-like receptors. D1-like receptors are typically associated with Gαs and cause activation of the cAMP/adenylyl cyclase second messenger system and the generation of EPSPs in the postsynaptic cell.

D2-like receptors, however, are typically associated with Gαi that inhibits the cAMP/adenylyl cyclase second messenger system and generate IPSPs in the postsynaptic cell.
Dopamine action is terminated by reuptake into the presynaptic terminal via the dopamine transporter (DAT). Once inside the cell, dopamine is either degraded via the actions of either monoamine oxidase (MAO) or catechol-O-methyltransferase (COMT), or it is repackaged into vesicles.
Norepinephrine-producing cells are localized in the pons of the brain stem, a structure called the locus coeruleus. The locus coeruleus is very small, but these neurons send projections widely throughout the brain. Outside of the brain, we think of norepinephrine as being responsible for triggering the sympathetic nervous system response of the body, the “fight-or-flight” reaction that prepares the body for physical activity in times of fear or acute stress.
In neurons that release norepinephrine, which is another catecholamine transmitter, once dopamine is packaged into small synaptic vesicles, a membrane-bound enzyme called dopamine beta-hydroxylase converts dopamine into norepinephrine. Therefore, unlike the other small molecule neurotransmitters, norepinephrine is synthesized within the vesicles, not in the cytoplasm. Like dopamine, the rate-limiting step of this synthesis pathway is the activity of tyrosine hydroxylase.
Norepinephrine binds to metabotropic adrenergic receptors (α1, α2, and β). The binding of norepinephrine to its receptor activates second messenger signaling cascades that will cause either EPSPs or IPSPs, depending on the receptor subtype.
Termination of norepinephrine signaling is similar to the termination of dopamine signaling. Reuptake into the presynaptic terminal occurs via the norepinephrine transporter (NET), and then the transmitter is either degraded within the cell by MAO or COMT or repackaged into synaptic vesicles.
Epinephrine, also called adrenaline, is a catecholamine, but it is often considered a hormone instead of a neurotransmitter. Epinephrine is primarily released by the adrenal medulla into the circulation; it is used as a neurotransmitter in only a small number of neurons.
Epinephrine is synthesized from norepinephrine in the cytoplasm by the enzyme phenylethanolamine-N-methyltransferase, so epinephrine synthesis requires norepinephrine to exit the vesicles where it was synthesized. After synthesis in the cytoplasm, epinephrine is repackaged into small vesicles via the vesicular monoamine transporter.
Epinephrine also binds to α and β adrenergic receptors (described above for norepinephrine) and causes similar activity when bound to these receptors.
Epinephrine, similarly to norepinephrine, also goes through reuptake into the presynaptic cell. Further, it is also degraded within the cell by both MAO or COMT or repackaged into synaptic vesicles.
Although we generally think of
neurotransmitters as neurochemicals that
function as described above, there are a
few atypical neurotransmitters that don’t
quite fit the mold of the other chemical
signals.
Neuropeptides are a class of large signaling molecules that some neurons synthesize. Neuropeptides are different from the traditional neurotransmitters because of their chemical size. Neuropeptides are a short string of amino acids and are known to have a wide range of effects from emotions to pain perception. Unlike small molecule neurotransmitters, neuropeptides are synthesized in the cell body and transported to the axon terminal.
Like other proteins, neuropeptides are synthesized from mRNA into peptide chains made from amino acids. In most cases, a larger precursor molecule called the prepropeptide is translated into the original amino acid sequence in the rough endoplasmic reticulum. The prepropeptide is processed further to the propeptide stage. The remaining processing and packaging of the final neuropeptide into a vesicle occurs in the Golgi apparatus.

Monoamines like dopamine, norepinephrine, or serotonin have a molecular weight around 150-200, while one of the smaller neuropeptides, enkephalin, has a molecular weight of 570. One of the largest neuropeptides, dynorphin, has a molecular weight greater than 2,000. Because of their large size, neuropeptides have to be packaged in dense core vesicles very close to the site of production near the nucleus, rather than in clear vesicles right at the terminal. These large vesicles must then move from the soma to the terminal.
The packaged peptides need to be transported to the presynaptic terminals to be released into the synaptic cleft. Organelles, vesicles, and proteins can be moved from the cell body to the terminal via anterograde transport or from the terminal to the cell body via retrograde transport. Anterograde transport can be either fast or slow.

The packaged neuropeptides are transported to the synaptic terminals via fast anterograde axonal transport mechanisms.
Neuropeptides such as enkephalin and dynorphin are agonists at a class of receptors called the opioid receptors. These opioid receptors fall into four main types. The three classical opioid receptors are named using Greek letters: δ (delta), μ (mu), and κ (kappa); the fourth class is the nociceptin receptor. All of these receptors are inhibitory metabotropic receptors which signal using the Gαi protein. These receptors are expressed in several brain areas, but expression is particularly heavy in the periaqueductal gray, a midbrain area that functions to inhibit the sensation of pain. Drugs that activate the opioid receptors, like morphine, oxycontin, or fentanyl, are the most effective clinical treatments that we know of for acute pain. Unfortunately, these same drugs also represent a tremendous health risk, as opioid drugs can be lethal in overdose and have a high risk of substance use disorder.
Endocannabinoids are endogenous lipid neurotransmitters that are a bit unusual compared to the other neurotransmitters that we have covered. First, they signal in a retrograde manner. This means that the endocannabinoids neurotransmitters are released by the postsynaptic cell and bind to receptors on the presynaptic cell. Additionally, endocannabinoids are not packaged into vesicles and released by fusion with the cell membrane.

Instead, when the postsynaptic cell has an action potential, it causes voltage-gated calcium channels in the postsynaptic cell to open, and for calcium ions to rush into the postsynaptic cell. The local increase in calcium concentration within the postsynaptic cell triggers the cell to synthesize endocannabinoids. Again, these neurotransmitters are not stored in vesicles like the other neurotransmitters that have been discussed. Instead, these lipid neurotransmitters are made on demand, or synthesized ‘de novo’. As lipids, the endocannabinoids are membrane permeable and can diffuse out of the cell through the cell membrane. The two most well-characterized eCBs in humans are called 2-Arachidonoylglycerol (2-AG) and Anandamide (ANA).

The endocannabinoids bind to one of two receptors, CB1 or CB2. Both receptor types are inhibitory metabotropic receptors that are located on the presynaptic cell and coupled to Gαi. Generally, CB1 receptors are found in the nervous system, while the CB2 receptors are found elsewhere in the body, such as in the immune system. Activity of the metabotropic CB1 receptors causes presynaptic calcium channels to close, reducing the concentration of calcium in the presynaptic cell, and thus decreasing the amount of neurotransmitter released by the presynaptic cell.

The endocannabinoid system is widely used by various systems in the body. It is estimated that endocannabinoid receptors are the most abundant GPCRs in the whole body. These substances were named because they are endogenous chemicals that are functionally similar to compounds found in plants of the genus Cannabis. One reason cannabis is used is because of its ability to interact with our endocannabinoid receptors.
The nervous system is capable of signaling via the gas nitric oxide (NO). This gas transmitter is not stored in vesicles, but is synthesized as it is needed. NO is formed when the amino acid arginine is degraded by the enzyme NO synthase (NOS). Because NO is a gas, it easily permeates across cell membranes. Therefore, the receptors for NO do not need to be transmembrane proteins expressed on the cell surface. Instead, the receptor for NO is an intracellular receptor called soluble guanylate cyclase (sGC). SGC works through a signaling pathway that is different from other metabotropic receptors so far described. SGC is linked with the signaling molecule cyclic GMP (cGMP), which activates protein kinase G (PKG). PKG can either be excitatory or inhibitory, depending on the intracellular components.
Drugs and toxins can alter neuron functioning in a range of ways, from activation to inhibition and all levels of modulation. Although many drugs exist that alter molecular process typical of many cells, this lesson will focus on neuron-specific targets.
As we have seen, the synapse is an incredibly complex structure, and for small molecule neurotransmitters, the entire “lifecycle” of the transmitter occurs in this space: synthesis, packaging, release, action, and termination. This means there are numerous targets upon which drugs and toxins can act to alter synaptic communication.
Drugs can alter neurotransmitter synthesis pathways, either increasing or decreasing the amount of neurotransmitter made in the terminal, affecting how much transmitter is released. An example of this is administration of L-DOPA, a dopamine precursor molecule in the dopamine synthesis pathway that results in increased dopamine production; it is used as a treatment for Parkinson’s Disease.

Neurotransmitter packaging is another site of possible drug action. Reserpine, which has been used to treat high blood pressure, blocks the transport of the monoamine transmitters into vesicles by inhibiting the vesicular monoamine transporter (VMAT). This decreases the amount of neurotransmitter stored and the amount of neurotransmitter released in response to an action potential.
The neurotransmitter receptors are another critical location for drug and toxin action. Agonists mimic neurotransmitter effects, whereas antagonists block neurotransmitter effects. Muscimol, a component of some mushrooms, is an agonist for the ionotropic GABA receptor. Bicuculine, a component of some plants, is an antagonist to this receptor and blocks the action of GABA. Additionally, many chemicals are able to modulate receptors in either a positive or negative fashion. Alcohol binds to the GABA receptor and increases the time the receptor is open when GABA binds.
Finally, neurotransmitter degradation and reuptake can also be altered by drugs and toxins. Depending on the neurotransmitter, enzymes located in either the synapse or in the terminal are responsible for degradation of the transmitter, and these enzyme can be blocked by drugs. Organophosphates are found in many pesticides and prevent the action of acetylcholinesterase, the enzyme that breaks down acetylcholine in the synapse. This inhibition increases acetylcholine action on the postsynaptic neuron. Monoamine oxidase inhibitors (MAOIs) prevent monoamine oxidase from degrading the biogenic amine neurotransmitters. MAOIs have been used as antidepressants since they increase the amount of transmitter available. Additionally, drugs can prevent the reuptake of neurotransmitters into the presynaptic terminal. Cocaine blocks the dopamine transporter, which results in increased action of dopamine in the synapse.
Drugs and toxins can also affect neuron function by acting outside of the synapse. For example, some chemicals change voltage-gated ion channel dynamics. Veratridine, a compound found in plants from the lily family, prevents voltage-gated sodium channels from inactivating. Initially, this causes an increase in neurotransmitter release, but it can quickly lead to excitotoxicity.
The nervous system is one of the most complex systems that we know of. Parts of this system malfunction frequently, and the results are a wide range of neurological disorders that affect humans, from injury to genetic disorders. The gross anatomy of the nervous system is an important foundation to the studies of other aspects of neuroscience. This chapter covers some of the major anatomical structures in the nervous system.
Broadly speaking, the nervous system can be divided into two main categories: The central nervous system (CNS) and the peripheral nervous system (PNS). Simply put, the CNS is the brain and spinal cord, while the PNS is all the other nerve cells in the body in the periphery. The two systems are not isolated from each other; information passes rapidly between the PNS and the CNS, and vice versa. When a signal that originates in the PNS moves to the CNS, we sometimes say that the signal is incoming or ascending, while the CNS to PNS direction is outgoing or descending. Information that arrives into the CNS is also called an afferent signal, while information leaving the CNS is an efferent signal. These two terms are frequently confused, but you can use the knowledge of other words that start with “e” to remember that an “exit” or an “escape” is something that moves away for ‘efferent’, and “arrive” for ‘afferent’. Alternatively, an efferent signal is something that has an effect on the outside world, while an afferent signal affects the person.
Anatomically, the CNS consists of two organs, the brain and the spinal cord. The brain is the main organ where movement originates, where thoughts and plans develop, and where consciousness is housed. The brain is what pushes us to act on our drives and desires, where language begins, and where memories are stored. The intact adult brain weighs about 1.5 kg (3 pounds), which is barely 2% of total body weight. Despite this relatively small size, it is extremely power hungry, and uses up about one-fifth of the body’s total energy expenditure.
When talking about parts of the brain, it is helpful to have a set of directional terms that can describe the location of various anatomical structures unambiguously.

Familiarity with the terminology used to describe location and relationships within the nervous system is critical as we move forward into examining brain systems.
Directional terms are used to locate one structure, usually in relation to another structure. Some terms, like dorsal or ventral, are relative to the axis of the central nervous system, so the direction these terms define changes if used for brain regions versus other body regions. Other terms, like superior or inferior, keep their meaning across the entire body.

Anterior: In front of; toward the face
Posterior: Behind; toward the back
Superior: Above; toward the head
Inferior: Below; toward the feet
Medial: Toward the middle
Lateral: Toward the edge
Dorsal: Toward the top of the brain or the back of the spinal cord
Ventral: Toward the bottom of the brain or the front of the spinal cord
Rostral: Toward the front of the brain or the top of the spinal cord
Caudal: Toward the back of the brain or the bottom of the spinal cord
Often anterior and rostral are used interchangeably and posterior and caudal are used interchangeably.

Neuroanatomists use all of these terms to describe the relationship of one structure to another. For example, we’ll see in Chapter 22 that introduces the four lobes of the brain, the frontal lobe is anterior or rostral to the parietal lobe, and the parietal lobe is dorsal to the temporal lobe. These anatomical words can also be combined to subdivide complex brain regions. For example, a structure called the thalamus has many small subsections, such as the dorsomedial nucleus or the ventropostero-lateral nucleus. Naming structures with this anatomical language is useful in identifying where they are located in a brain scan or autopsy, but these words tell us nothing about function.
As a three-dimensional structure, the brain can be sectioned, or cut, for visualization or analysis in several ways. Here, we will describe the three main orientations, each at right angles to the others.

The frontal or coronal plane is a vertical plane in a medial to lateral direction, dividing objects into front and back pieces.
The sagittal plane is also a vertical plane but in a rostral-caudal direction, meaning it divides objects into right and left regions.
Finally, the horizontal plane divides objects into top and bottom regions.
In a sliced section of the brain, you might notice that brain tissue has different colored areas. Some brain tissue is pale and almost white, and these areas are described as white matter. Generally, white matter represents pathways of communication. White matter regions are comprised of axons. It appears white due to the myelin sheath on the axons. Other sections of brain tissue have a darker pink/gray color, appropriately called gray matter. These areas are usually dense with cell bodies and dendrites. Gray matter is the location of most synapses.
The brain has two very similar halves, the left and right hemisphere. Oftentimes, in the neurotypical individual, information passes between both hemispheres rapidly: what one hemisphere senses or learns, so does the other hemisphere. It is the white matter tracts that allow for this transfer of information. When a white matter pathway crosses from one side of the body to another, we call it a decussation.

Commissures are white matter tracts that connect gray matter between the left and right hemispheres of the brain. The main commissure that allows for the passage of information between the two hemispheres is called the corpus callosum.

Association fibers are white matter tracts that connect different bits of gray matter within the same hemisphere of the brain. These connections do not cross the midline.

Projection fibers are white matter tracts that connect the hemispheres of the brain with lower brain structures or with the spinal cord. They “project” from the cortex to the lower brain structures or spinal cord.
In the following chapters, some of the many structures that make up the brain will be introduced. To begin this discussion, we will identify some of the basic development of the nervous system to understand how different areas of the brain are organized.

Very early in development, an embryo looks like a flat disc with 3 different layers of cells.

Endoderm: will eventually develop into the viscera (organs of the body)
Mesoderm: will eventually develop into the bones and muscles
Ectoderm: will eventually develop in the nervous system and the skin
Let’s focus on the ectoderm that will develop into the nervous system. The ectoderm layer will fold together in a process called neurulation to form a neural tube. Neurulation  occurs within the first month following conception in humans.

During neurulation, the middle of the neural plate folds first, followed by the anterior and posterior ends. The central nervous system will develop from the walls of the neural tube and the hollow lumen of the tube will become the cerebral ventricles and spinal canal within the central nervous system.

Early in pregnancy, there can be problems with the process of neurulation and the formation and closure of the neural tube. Collectively, these are referred to as neural tube defects that include defects that occur within the brain, spine, or spinal cord. One of the more common neural tube defects is spina bifida. In spina bifida, the neural tube fails to close completely, and as a result the backbone that typically protects the spinal cord also does not form appropriately. This event can occur anywhere along the spine, and will typically result in nerve damage at that particular site that will potentially lead to physical and / or intellectual disability ranging in severity with the degree of damage.

Anencephaly is a neural tube defect that is caused by the failure of the anterior portion of the neural tube to close. Anencephaly is a serious birth defect that typically prevents the development of the anterior portion of the brain and associated skull.

Unfortunately, many neural tube defects occur very early in pregnancy, such that many women do not yet know that they are pregnant. As a result, daily folic acid supplements or a diet that includes foods rich in folate is recommended to all women of reproductive age to help prevent neural tube defects in the event of a pregnancy.
Early in development, the anterior portion of the neural tube has three distinct vesicles, which will each develop into different structures. These vesicles, from most anterior to most posterior, are the prosencephalon (forebrain), the mesencephalon (midbrain), and the rhombencephalon (hindbrain).

Through development, the walls of these vesicles will differentiate into adult brain structures. Differentiation is the process by which structures become more complex and functionally specialized during development. The names of these early vesicles can be used to describe either the stages through development, or a grouping of structures that eventually form in adulthood. In the following chapters, we will learn more about some of these anatomical structures.
The prosencephalon, or the forebrain, is most anterior in the neural tube and eventually develops into the “higher order” brain regions, including the cerebral cortex. Most of the time, when you see an image of an intact brain from the side or the top, the structures that are visible to you are the forebrain structures. The prosencephalon is made up of the telencephalon and the diencephalon.

As the prosencephalon continues to develop, additional structures will form that are associated with the cerebral hemispheres. For instance, the optic vesicles that bud off the surface of the prosencephalon will differentiate into the retinas of the eyes—thus, the retina is made up of neural tissue. The olfactory bulbs will differentiate from the ventral surface of the cerebral hemispheres.

Note that as the walls of the tube develop into these structures, the lumen of the tube remains and will become the fluid-filled ventricles of the brain. The lateral ventricles will form from the tube within the cerebral hemispheres and the third ventricle will be found ventrally surrounded by the diencephalon.
The cerebral cortex makes up the outermost layer of the brain. The word “cortex” comes from the word meaning “bark”, the outer layer of a tree. The cerebral cortex is the most evolved structure of the human brain and is responsible for higher order thinking. Here, the brain processes behaviors such as attention, memory, and language.

The basal ganglia are made up of a series of brain structures (including the caudate and putamen, globus pallidus, substantia nigra, and subthalamic nucleus) that are used for such behaviors as motor and habit learning, emotional processing, and action selection.
The thalamus is often referred to as a “sensory relay station” in the brain, since almost every sensory modality (sight, taste, touch, and hearing) passes information through the thalamus before being directed to the appropriate area of the cortex.

The hypothalamus is also within the diencephalon. This structure serves as an autonomic control center to alter visceral function and a communication route to the body’s endocrine system through control of anterior pituitary hormones and production of posterior pituitary hormones. Neural signals originating in the hypothalamus have the capability to influence the chemistry and function of the entire body. The hypothalamus also has nuclei that function in emotional responses, and regulate body temperature, food intake, water balance, and sleep.
Moving more caudally, the mesencephalon (or the midbrain) differentiates into the tectum and the tegmentum.
The tectum (which means “roof”) is the dorsal portion of the midbrain and it has two major structures: the superior colliculus and inferior colliculus. The superior colliculus is important in reflexive eye movements that allow you to quickly orient to something changing in your environment. The inferior colliculus relays auditory information to the thalamus for auditory function.
The tegmentum (which means “floor”) is the ventral portion of the midbrain. There are many structures in the tegmentum and they can perform a wide variety of functions. For example, the periaqueductal gray allows us to respond to painful stimuli, the red nucleus and substantia nigra coordinate complex movements, and the ventral tegmental area is important for the processing of reward and motivation.
The most posterior/caudal portion of the neural tube is the rhombencephalon (or hindbrain). Evolutionarily speaking, the rhombencephalon represents the oldest part of the central nervous system. These structures likely evolved some 570 million years ago.
The more rostral portion of the hindbrain differentiates into two structures: the cerebellum and the pons. The cerebellum, or “little brain”, is best known as a structure that enables motor control functions, such as balance, coordination, posture, and learning physical actions. The cerebellum helps us recognize and predict sequences of events during motor learning. More recently, the cerebellum has also been recognized to play a role in non-motor functions like learning. The pons (which means “bridge”) is an important structure that relays impulses between the motor cortex and the cerebellum. It has a critical function to help us perform involuntary functions like breathing.
The caudal portion of the hindbrain differentiates into the medulla. The medulla is found at the far posterior end of these three early developmental vesicles. The medulla contains many clumps of neurons that are responsible for functions that an organism carries out unconsciously. It contains a cardiovascular center that is especially important in maintaining and changing blood pressure and heart rate, and also has connections to the pons to help regulate breathing. The medulla contains areas that can detect toxins in the blood that come from dietary sources, triggering vomiting. Other behaviors like hiccupping, swallowing, coughing, and sneezing are also controlled by the medulla.

Moving beyond this anterior portion of the neural tube that contains the prosencephalon, mesencephalon, and rhombencephalon, the neural tube continues down the length of the embryo. The remainder of the neural tube will differentiate into the spinal cord, with the lumen of the tube becoming the central canal of the spinal cord. The spinal cord is important in relaying information to and from the body.

The brain is comprised of the cerebrum, cerebellum, and brainstem. The cerebrum is the most prominent region of the brain. It is divided into left and right hemispheres. The hemispheres have many of the same functions. For example, each perceives touch on one side of the body, but some functions demonstrate laterality, meaning they are primarily controlled on one side of the brain.

Most of what we think of when we imagine the brain is the cerebral cortex in humans. The cortex has many folds to increase the surface area of the brain. The bumps or raised ridges on the outer surface are called gyri (singular gyrus) and the grooved indentations are called sulci (singular sulcus). A large, deep sulcus is sometimes also called a fissure.
Although each gyrus and sulcus has a name that either identifies its function or location, there are only three sulci that we will introduce here to help orient us around the neuroanatomical features of the cortex. The longitudinal fissure is the most obvious fissure in the brain. It divides the two hemispheres, running along the anterior–posterior axis, visible from a dorsal view of the brain. If you were to cut along the longitudinal fissure completely, you would get two symmetrical portions of brain: the left and right hemispheres.

The central sulcus is a large fissure that starts at the dorsal part of the brain at about the halfway point on the anterior–posterior axis. In a sagittal view, the central sulcus runs ventrally about half the length of the brain. The other groove worth noting is the lateral fissure. This one runs roughly along the anterior-to-posterior direction, and curves gently dorsally. Again, in a sagittal view, it is roughly seen in the middle third of the brain in the anterior–posterior axis.

The cortex is roughly divided into four major lobes, which are named after the bones of the skull that surround each section of brain. The lobes are paired, meaning that the whole brain contains two of each, a left and a right. In general, the structures are roughly symmetrical.
The frontal lobes are the most rostral, located in the front of the brain. The posterior border of the frontal lobe is the central sulcus. Among mammals, it is the largest of the four lobes. The frontal lobes are responsible for higher level executive functions like attention, critical thinking, and impulse control. The frontal lobes allows us to do mental math, to hold a string of letters in our head to be repeated backward, and to suppress socially unacceptable actions. Our personality is influenced by the frontal lobe. An injury to these brain structures can result in a radical change in a person’s behavior.

They are the last brain region to fully develop, not completing development until individuals reach their mid 20s. The frontal lobes are also the location of the primary motor cortex, the region of the brain responsible for planning and executing movement. Specifically, the primary motor cortex is located in the precentral gyrus, which is directly anterior to the central sulcus.

Phineas Gage, who was mentioned back in Chapter 1, is one of the most famous case studies in neuroscience.

The mid-1800s saw an expansion of industry in the United States. The most reliable and quickest way to move goods and people was with the railways that were starting to zig-zag across the growing country. The factor slowing down railway expansion was terrain: land had to be relatively flat for the tracks to be laid down. Terraforming mountains was a dangerous ordeal, and in the years before TNT (a relatively safe explosive) was developed, work accidents were a risk that these demolition workers faced.

Phineas Gage was one of those workers. In the green mountain hills of Vermont, Gage was putting explosive powder into a crack in a mountain to clear land for a new railway. As Gage packed the explosive using a three-foot-long metal rod, a spark accidentally ignited the blast prematurely, causing the tamping iron to rocket cleanly through Gage’s skull. Miraculously, Gage survived the blast. Within a month, he had made an almost complete recovery. Gage was talking excitedly with his doctors, he was eating voraciously, and even reported experiencing no pain. While the doctors noticed that his entire frontal lobe had been destroyed, it was his friends who noticed the dramatic change in his personality: whereas he was once a friendly man, adored and respected by his coworkers, the new Gage was irreverent, generally unlikable, and prone to using profanity at the most inappropriate times. The pre-injury Gage was a shrewd businessman who followed through with his plans, but Gage now was unreliable and at times, acted in a more like an animal. Because of the injuries to his frontal lobe, his friends described him as being “no longer Gage”.
The central sulcus lies caudal to the frontal lobe and divides the frontal lobes from the parietal lobes. The primary somatosensory cortex is located in the postcentral gyrus of the parietal lobe and is responsible for the perception of touch and pain. With our skin, we are able to detect light touch, temperature, pain, vibration, and many other modalities. This ability to sense different tactile properties of things in the world around us with our body is one of the major functions of the parietal lobe. Another closely related sense, proprioception (the ability to identify where parts of your body are located), is also processed by neurons of the parietal lobe. The parietal lobes also perform higher-level visual processing.
The temporal lobes are located on the side of the brain, separated from the frontal and parietal lobes by the lateral fissure. Like the parietal lobe, the temporal lobe plays a role in sensory processing, specifically with hearing, smell, taste, and higher-level visual processing. The auditory system allows our brain to interpret sound waves. The ability to remember important facts depends on memory-related processes. These functions are carried out in part by a brain structure called the hippocampus, which is buried medially and ventrally in the temporal lobe. The temporal lobe also houses some structures that are important for language.
The occipital lobes, the most caudal lobes, are located in the back of the brain. Anatomically, there is not an obvious border that separates the occipital lobe from adjacent areas of the cortex. The occipital lobe is the smallest of the four lobes. The main function of the occipital lobe is for processing of visual stimuli. Our eyes are capable of capturing light and converting that light into signals. The primary visual cortex of the occipital lobe, also called V1, interprets those signals into a representation of the visual world. Other vision-related stimuli, such as objects in motion, object orientation, and color are also processed by neurons in the occipital lobe.
The cerebellum lies inferior to the occipital lobes. The cerebellum is divided into two hemispheres like the cerebral cortex. The cerebellum is best known for its role in regulation and control of movement, but it is also involved in cognitive functions like emotions.

The brainstem is located between the cerebrum and the spinal cord. It is important for regulating critical functions like heart rate, breathing, and sleep. It is also the location of most of the cranial nerves.

The spinal cord, which is part of the central nervous system but not part of the brain, is responsible for receiving sensory information from the body and sending motor information to the body. Involuntary motor reflexes are also a function of the spinal cord, indicating that the spinal cord can process information independently from the brain.

Viewing the brain from above shows the bilateral symmetry of the left and right cerebral hemispheres, which are separated by the longitudinal fissure. The frontal, parietal, and occipital lobes can be seen. Similar to the lateral view, the central sulcus divides the frontal lobe from the parietal lobe. The precentral gyrus—which is the location of the primary motor cortex—sits rostral to the central sulcus, whereas the postcentral gyrus—which is the location of the primary somatosensory cortex—lies caudal to the central sulcus.
Underneath the brain, the frontal and temporal lobes are visible, as is the cerebellum. Like the dorsal view, the longitudinal fissure divides the cerebrum into right and left hemispheres. The pons and medulla (components of the brain stem) connect the cerebrum to the spinal cord.
Cranial nerves are also visible on the ventral surface of the brain. The olfactory tract leads out to the olfactory bulb, which connects to the olfactory nerve. The optic tract crosses the midline at the optic chiasm, and then the optic nerve projects to the retina. Other cranial nerves enter or leave the brain at the level of the brainstem. The hypothalamus is located caudal to the pons and the mammillary bodies project out from the hypothalamus.
A mid-sagittal section slices the brain through the longitudinal fissure and separates the right hemisphere from the left. It also reveals more structures. In a mid-sagittal view, all four cortical lobes are visible. The frontal lobe is separated from the parietal lobe by the central sulcus, the occipital lobe is in the posterior region of the brain, and the temporal lobe can be seen behind the brainstem. The cerebellum, pons, medulla, and spinal cord are seen caudal to the cerebrum, but in this view, the midbrain—which is made up of two regions: the tegmentum and tectum—is also visible superior to the pons. The corpus callosum is located in the center of the cerebrum and is a white matter bundle made up of axons crossing from one hemisphere to the other. Surrounding the corpus callosum is the cingulate gyrus, a region important for emotion.
The diencephalon region of the brain consists of the region around the thalamus and hypothalamus. It is located inferior to the fornix and lateral ventricle, posterior to the anterior commissure, and superior to the brainstem. The fornix is a nerve fiber bundle containing primarily output from the hippocampus. The anterior commissure sits above the hypothalamus and is a white matter tract (like the corpus callosum) that allows information to cross from one hemisphere to the other. The thalamus is best known for its role as a relay and processing location for the sensory and motor systems. The hypothalamus has a variety of functions including control of stress and the “fight or flight” response of the autonomic nervous system, reproduction, sleep, thirst, hunger, and other homeostatic functions. The mamillary bodies sit in the posterior part of the hypothalamus and are important for memory. The optic nerves from the retina cross at the optic chiasm and then the optic tracts continue back into the diencephalon.

In the brainstem, the tectum of the midbrain consists of the superior and inferior colliculi, which are important for vision and hearing, respectively. Finally, the reticular formation is located throughout the brainstem. Networks within the reticular formation are important for regulating sleep and consciousness, pain, and motor control.

Coronal sections of the brain allow deep tissue structures to be visible. A cut through the anterior portion of the temporal lobe shows the amygdala, a region important for emotion, located in the medial temporal lobe. The regions of the basal ganglia are also visible: the striatum (which consists of the caudate and the putamen) and the globus pallidus. The basal ganglia has multiple functions, but is best known for its role in regulation of movement. The lateral ventricle sits medial to the basal ganglia and below the corpus callosum. The third ventricle is located in the middle of the brain, inferior to the lateral ventricle. The longitudinal fissure separates the left and right cerebral hemispheres and the lateral sulcus is the border between the frontal and temporal lobes.
A coronal section taken closer to the central sulcus will make the hippocampus visible. The hippocampus is known for its role in memory and spatial awareness. At this location, the basal ganglia is more defined; the caudate and putamen are still present, but the two separate regions of the globus pallidus (the internal and external segments) can be seen, as well as the subthalamic nucleus and the substantia nigra. The thalamus is located on either side of the third ventricle. The corpus callosum is superior to the lateral ventricle. The cerebrum is divided in half by the longitudinal fissure and the lateral sulcus separates the temporal lobe from the frontal and parietal lobes.
Although we mostly think about the neurons that make up the brain and spinal cord as being the main characters of the nervous system, there are many other anatomical features that play important supporting roles. These are often non-neuronal structures that are still critically important in allowing the nervous system to do what it needs to do.
The brain is a soft and delicate internal organ housed inside the skull. If there weren’t some protective buffer separating the soft brain matter from the rigid bone, the jelly-like brain would be smashed up against the inside of the skull and get injured as the head moves around.

The meninges are a series of protective membranes that minimize this kind of damage. They surround the brain and extend all the way down the spinal cord. Think of the meninges as an organic type of “bubble wrap” that encases a fragile nervous system.

There are three types of membranes that collectively make up the meninges. From the outermost to innermost layer, they are:

Dura mater. The dura is made of thick, fibrous material and can get to be 0.8 mm thick in the adult body (if you took a piece of printer paper and fold it in half four times, that should give you an idea of how thick the dura mater is in the adult human). The dura mater is physically attached to the inside of the skull with highly resilient connections found at the sutures between the plates of the cranium. The name originates from Latin meaning “tough mother”.
Arachnoid mater. The arachnoid mater is the middle layer of the meninges. The fibers are very delicate and resemble a spider web, which is where the name comes from. Within this space, there are protrusions that allow for CSF to drain into sinuses, which allow for recycling of soluble substances. Most of the CSF in the brain exists underneath this layer in the subarachnoid space.
Pia mater. The pia mater is the third layer of the meninges. It is very fragile, is in direct contact with the surface of the brain, and closely follows the sulci and gyri. The name means “pious mother”.
Inflammation of the meninges is a potentially deadly condition called meningitis. Exposure to infectious agents like viruses or bacteria such as Neisseria meningitidis (that leaks from the blood into the meninges) is a common cause of the inflammation. When the meninges are inflamed, the brain gets compressed from all sides, increasing intracranial pressure, producing many of the same symptoms seen in hydrocephalus: fever, stiff neck, headache, seizures, and altered mental status. The N. meningitidis bacteria and the viruses are highly transmissible in close contact, but vaccinations are highly effective at minimizing the infection rate. As with bacterial infections, broad-spectrum antibiotics are effective at treating the infection.
Like every other organ in the body, the brain requires oxygen and nutrients to function. In humans, this function is accomplished by the blood that is pumped around the body using a network of blood vessels called the circulatory system. The brain has a very high demand for oxygen and nutrients: at only 2% of total body weight, it receives about 15% of total cardiac output.
Stroke is an extremely common, life-threatening medical condition that results in a loss of blood flow to the brain. According to 2016 statistics from the World Health Organization, stroke is the second-highest cause of death worldwide. The number one risk factor for stroke is high blood pressure. There are two common types of strokes that a person may experience.

More than 80% of all strokes are ischemic strokes (pronounced is-keemik), which happens when normal blood flow is interrupted, causing cell death by deprivation of oxygen and nutrients to brain tissue. Generally, this type of injury can happen when a blood clot forms, travels through the circulatory system, and gets lodged in a tiny brain blood vessel, thus, blocking the passage of blood.

The other 20% of strokes are hemorrhagic strokes, which result from a burst blood vessel that causes bleeding into the brain. The presence of uncontrolled blood inside the brain causes an increase in intracranial pressure, which can be lethal. Many brain cells may die since they cannot take up oxygen directly from the blood. Additionally, blood has dramatically different properties than the normal solution brain cells live in, and this can cause the neurons to trigger a self-destruction program. Generally, hemorrhagic stroke is more deadly than ischemic stroke.

Because the different blood vessels of the brain’s circulatory system are responsible for providing blood to specific areas of the brain, it is possible to diagnose the specific area where the stroke is happening based on the presentation of symptoms. For example, if the middle cerebral artery blood is occluded by an ischemic stroke, the left hemisphere motor cortex will lose blood flow. Because of the contralateral organization of the descending motor pathway, the patient may therefore present with paralysis or weakness in the right half of the body. It is vitally important to correctly diagnose and differentiate between the two types of strokes. An ischemic stroke may be treated with injection of a “clot-busting” drug, a substance that helps the body break down the offending blockage. However, these clot-busters could make the bleeding from a hemorrhagic stroke even worse.

It is important for oxygen and nutrients to pass from the blood into the brain tissue. Small blood vessels outside of the brain, such as the capillaries in the fingertips, have very thin walls—sometimes the width of a single cell—and are, therefore, highly permeable to gases. These vessels can either contain tiny holes or large protein structures that physically transport substances across the blood vessel. On the other hand, it is also advantageous to separate toxins and foreign pathogens in the bloodstream from getting into brain tissue.

The blood–brain barrier (BBB) is an anatomical adaptation that selectively transports substances necessary for normal biological function, while simultaneously excluding potentially harmful invaders from the brain. The BBB physically surrounds blood vessels in the brain. It is made up of endothelial cells and a type of glial cell called an astrocyte. The BBB is injured in a variety of medical disorders, ranging from stroke, epilepsy, and Alzheimer’s disease, just to name a few. It is still unknown what role the disruption of the BBB plays in brain disorders.

The exclusive nature of the BBB can be a double-edged sword. It is difficult to deliver a drug into the brain from the blood stream if that drug is unable to pass through the BBB. For example, the current gold standard pharmaceutical treatment for Parkinson’s disease is to increase the brain’s levels of dopamine. However, dopamine does not pass through the BBB. To get around this, physicians give the BBB-permeable substance L-DOPA, which the brain is able to convert into dopamine. Many other therapeutic drugs do not cross the BBB, so researchers are developing methods using electromagnetic fields to temporarily weaken the barrier, or surround the drugs in nanoparticles so small that the body cannot identify them as foreign.

There are hollow spaces within the brain called ventricles. The human brain has a total of four ventricles. The two very large, paired ventricles (one in each hemisphere) are the lateral ventricles. They are connected medially to the third ventricle, which extends to the posterior aspect of the brain. From here, the cerebral aqueduct that runs ventrally extends into the fourth ventricle before continuing into the central canal: a narrow space that runs all the way through the length of the spinal cord along the midline.

The entire ventricular system is interconnected. The ventricles are filled with a liquid called cerebrospinal fluid (CSF). CSF is basically a high-salt water solution. Because of the high osmolarity of CSF, it is a very buoyant solution. Like a fully grown person who can float easily on the surface of the extremely salty Dead Sea, CSF allows the brain to remain “floating” inside the skull. Without CSF, the brain weighs almost 1.5 kg (~3 lbs). Cells and blood vessels at the ventral base of the brain would be crushed under the weight of the brain itself. But when the brain is surrounded by CSF, it weighs less than 50 grams, almost two orders of magnitude lighter!

CSF is also found within the meninges that encase the brain. In fact, more than 80% of the CSF in the body exists in this space outside the brain. This liquid serves as a form of “cushioning” that protects the brain from rapid head movements. If it weren’t for this physical protection, the inertia of head movement may cause your brain to smash against the inside of the rigid skull if you move your head too quickly.

The CSF layer allows the head to withstand some sloshing of the brain, but a movement that is too abrupt can cause a traumatic brain injury. CSF can also function as a way to wash impurities out of the brain. The volume of CSF in the typical human body is about 150 mL, a little more than half a cup. Because there is frequent turnover of CSF, the material gets absorbed back into the body regularly. Each day, the body produces about half a liter of CSF, so the brain cycles through the entire volume a few times.
Hydrocephalus, historically called “water on the brain”, is a common condition affecting the brain of about 1 in 200 newborns and a small number of adults. In patients with hydrocephalus, the volume of CSF increases, which elevates intracranial pressure, causing symptoms such as fever, stiff neck, headache, seizures, or altered mental status.

In adults, the skull is rigid and unmoving. But in newborns with hydrocephalus, the plates of the skull are not completely fused together. Often, these children will have a bulging parts on the skull and an expansion of the forehead.

Increased CSF volume can happen in a couple ways. The clearance of CSF may fail while production remains normal, or the entrance to the central canal in the spinal cord may be narrowed or blocked by a tumor, leading to an increase in the volume in the brain. A common treatment for hydrocephalus is to surgically implant a shunt (a hollow tube that runs from the ventricle down into the abdominal space) that allows for drainage, thus decreasing intracranial pressure.

The earliest methods of analyzing nervous system anatomy were crude: manual dissection of the brain post-mortem (after death). The techniques discussed below were developed to allow scientists to see some aspect of the anatomy of the nervous system—either gross anatomical differences or connectivity. Additional techniques were developed to see how the living brain functions.
The following techniques are used to analyze brain structure.
“Does the patient have a brain tumor and where is the brain tumor located?”

“Are the meninges intact?”

The CT scan relies on X-ray technology. X-rays are high energy beams of electromagnetic radiation that are capable of passing through many physical objects. Traditional two-dimensional X-rays, such as those used to image a broken bone or tooth decay, use radiographic film to detect where the X-rays get blocked. When an X-ray passes unimpeded, it causes the film to darken. But, wherever the X-rays are blocked, the film remains white. Therefore, material that is more dense (such as bone) appears as white, less dense material (such as the air surrounding the body or CSF) appears dark. Other tissue are some shade of gray in between.

The CT scan is essentially a three-dimensional X-ray that revolves around the person as they move through the scanner. Instead of using radiographic film, the CT scan uses a computer that detects the passage of X-rays, located directly across the emission source of the X-ray. Instead of a flat, two dimensional-image, the CT scan uses an X-ray gun that revolves around the person’s body as they advance slowly through a large circular hole. The computer is then able to compile the series of two-dimensional images and turn them into a three-dimensional reconstruction that can be used to see the brain from any projection. CT scans give us a spatial resolution of about 0.5 mm.

CT scans are generally used clinically to assess diagnostic changes over several days (such as before and after tumor removal or to determine if an intracranial bleed has healed), so temporal resolution is not a major consideration. As an anatomical analysis that can easily identify tissues of different density, it is great for identifying and diagnosing particular brain conditions. Brain tumors can be visualized in a CT scan, since they are identified by an increase in tissue density compared to normal brain tissue. Hydrocephalus, an abnormal and potentially deadly expansion of the CSF-filled ventricles, can be quickly identified by this analysis. Meningitis, an inflammation of the meninges, may present as increased contrast in the CT scan.

The big advantage of the CT scan is that it is noninvasive. You can use a CT scan in order to diagnose and identify the cause of a condition while a person is still alive, and hopefully work towards developing an intervention. It is also a relatively quick technique. A full-head CT scan takes only minutes, which allows for a rapid diagnosis of anatomical structures. However, X-rays are highly mutagenic. Prolonged exposure to X-rays dramatically increases the risk of developing various cancers, since X-rays interfere with the process of DNA replication. It is estimated that the radiation exposure in a single head CT scan is similar to the background exposure of X-rays in a few months. When a CT scan is prescribed, the diagnostic information gained from a CT scan is more important than the risks from increased radiation exposure.

Example questions answered:

“Are their structural abnormalities in a brain structure?”

“What are the measurements of a brain structure?”

Magnetic resonance imaging (MRI) is used for imaging brain structures. An MRI is able to more clearly differentiate between different types of tissues with high resolution. It can be used in place of CT scan for visualization of structures that are very small or need finer detail than can be seen with a CT scan.

The MRI machine is a circular tunnel through which a person on a table moves. As the person moves through the scanner, an extremely powerful magnet revolves around their head. The power of a typical magnet used in a hospital MRI may be as powerful as 10,000 gauss (1 Tesla)—strong enough to lift a car. The more powerful fMRI machines can be as powerful as 100,000 gauss (10 Tesla). The stronger the magnets, the better the spatial resolution that the machine can produce (our current best spatial resolution is on the order of millimeters).

MRI technology detects and quantifies the movement of water molecules, which moves differently in gray matter than white matter. The movement of a water molecule in biological tissue is not completely random, largely because the brain is made up of heterogeneous tissue.

Although the technique has a great capacity for analyzing brain structure, the nature of the machine itself presents limitations. The machine can also be very loud, which is not trivial if you are interested in using this technology on younger patients. The use of a tremendously powerful magnetic field presents a different set of limitations. At the risk of severe injury or death, the patient entering the scanner cannot have any magnetosensitive implants, such as metallic aneurism clips, intrauterine devices, or shrapnel. Even older generation tattoos have trace amounts of metal that cause burns when exposed to the magnets of the MRI machine.
“Is the volume of the white matter tract medial longitudinal fasciculus important for normal language processing?”

“Does spinal cord compression cause neurological deficits?”

While a CT scan is great for detecting gross anatomical anomalies like tumors or intracranial bleeding, it has a difficult time with subtle anatomical changes like differences between gray matter and white matter tracts. A technique for identifying these differences was proposed in 1994, called diffusion tensor imaging (DTI).

DTI quantifies white matter because of the morphological features of white matter. More specifically, DTI uses MRI technology to detect and quantify the movement of water molecules, which move differently in gray matter than white matter. The movement of a water molecule in biological tissue is not completely random, largely because the brain is made up of heterogeneous tissue. White matter is very different from gray matter. A water molecule is more easily able to diffuse along the same direction as a tract of white matter but has a difficult time moving perpendicularly across such tissue. When looking at DTI images, they will have coloring added to the figure to show the different white matter tracts.

Axonal projections are directional, with the soma at one end and the axon terminal at the other. One of the shortcomings of DTI is that it cannot give us information about the directionality of the axonal projections.
The following techniques are used to study brain function.
Example questions answered:

“Which areas of the brain decrease in activity when a person experiences mild cognitive impairment?”

“Do drug-dependent people have a high density of opioid receptors?”

The positron emission tomography (PET) scan is an application of nuclear medicine best known for its applications in the medical setting for the diagnosis of cancer. Before the PET scan, a radioactive compound called a tracer is injected into the bloodstream. The PET scanner itself is a large circular device that looks similar to the CT scanner. The tracer is chemically unstable, and it produces a signal within the body that can be detected by the PET scanner as the person moves through the machine. A common tracer is a radioactive analog of glucose. Areas of the brain that are active will metabolize glucose for energy. Therefore, when an area of the brain increases in energetic demand, that change can be detected by identifying the increase in glucose movement.

PET scans can be effective at diagnosing and identifying the location of tumors in the nervous system. It also provides an overall picture of brain activity, which may be useful in diagnosing disorders of cognitive deficits, like dementia associated with Alzheimer’s disease. PET scans have also been used to image the activity of specific brain areas as a person performs behavioral tasks, but this use of PET scan has largely been replaced by functional magnetic resonance imaging. Another application of PET scanning is to visualize levels of receptors in vivo.

When looking at PET images, they will have coloring added to the figure to show where, anatomically, activity in the brain has increased or decreased. By convention, many times an increase in brain activity is depicted with warm colors (yellow, orange, red) whereas a decrease in brain activity is depicted with cool colors (blue, purple).

The downside of the PET scan as a diagnostic tool is similar to a limitation of the CT scan. A person is exposed to radioactive compounds and gamma wave radiation, which are potentially mutagenic. In images produced by a PET scan, it is often difficult to identify boundaries between tissue, even between dramatically different internal organs. To make up for this deficit, PET scans are frequently performed simultaneously with an anatomical analysis like a CT scan. PET scans generally have very poor spatial and temporal resolution.

Example questions answered:

“Do neurons in the right hemisphere cingulate gyrus increase in activity when a person sees their loved ones?”

“Which areas of the brain change in activity when a person is planning a motor action?”

The functional magnetic resonance imaging (fMRI) technique is probably the most well-known method of studying brain activity. Because fMRI can be performed while a person is engaged in a task, many research studies use fMRI as a means to correlate behavior with activity patterns in specific parts of the brain.

fMRI measures differences in blood flow and oxygen levels. Like the PET scan, the fMRI hinges on the idea that more active areas of the brain have different metabolic demands than less active areas of the brain. When there is more activity in one area of the brain, the neurons in that area need more oxygen. This change in blood flow is detected by the fMRI. The main reason fMRI is useful in so many research applications is that you are able to visualize brain activity real-time during the performance of complex behavioral tasks. You can present specific visual stimuli to a person in an fMRI scan and evaluate which parts of the brain change in activity. For example, seeing pictures of faces causes increased blood flow into the fusiform face area. You can ask a person to perform a gambling task and evaluate the areas of the prefrontal lobe that are responsive to risk taking.

When looking at fMRI images, they will have coloring added to the figure to show anatomically where activity in the brain has increased or decreased. By convention, many times an increase in brain activity is depicted with warm colors (yellow, orange, red) whereas a decrease in brain activity is depicted with cool colors (blue, purple).

The limitations introduced with MRI earlier are the same for fMRI. In addition, due to the small tube, it can be difficult to study anxiety with endangering the patient. Further, the data collected by fMRI can be very difficult to analyze and are frequently subject to false positives. fMRI also assumes that increased blood flow is directly correlated with the amount of neural activity, which may not always be the case.
It is sometimes easy to think of neuroscience as a focused study of the brain: How does activity of the brain contribute to behavior? In what ways does the brain change in disease? Why do the cells of the brain behave the way they do?

The truth is there are many parts of the body that also fall under the broad study of neuroscience. For example, the automatic kneejerk reflex that a clinician examines when they tap on your patellar tendon is a test of the nervous system. The reflex is driven by sensory neurons that detect muscle stretch, motor neurons that cause the kicking response, and interneurons that prevent the opposing muscle from acting. We have neural circuits that provoke changes in the activity of our internal organs, from the beating of our heart to the digestion of food, and the study of these systems is certainly part of neuroscience as well.

Moving posterior from the brainstem is the other organ of the central nervous system: a long, thin structure of nervous tissue called the spinal cord. It functions to carry information both upwards towards the brain and downwards towards the body’s other organs and muscles. It can also process sensations and form an appropriate motor response in the absence of brain input.
The spinal cord begins at the base of the brainstem and runs down to the small of your back, giving it a length around 44 cm (17.5 inches). The spinal cord is housed within a series of bones, called the vertebral column. Although the spinal cord itself is continuous, it can be divided based on the overlying vertebrae. A combination of a letter and a number is used to identify each section of the spinal cord; the letter corresponds to the vertebral section and the number refers to the number of bones down from the previous section (the smaller numbers are more anterior, larger numbers more posterior). The diameter and shape of the spinal cord changes over the length of vertebral column, a result of the function of the spinal nerves. For example, the region where motor neurons are located (ventral horn) is larger in the cervical region of the spinal cord compared to other regions of the spinal cord with minimal motor output.

Branching off from each section of the spinal cord are two pairs of nerves, the afferent (incoming to the CNS) sensory nerve roots, which branch from the dorsal side of the spinal cord, and the efferent (outgoing from the CNS) motor nerve roots, which branch from the ventral side of the spinal cord. These two branches meet and extend away from the spinal cord. After merging, they are called the spinal nerves.

The vertebral column is divided into four main regions: cervical, thoracic, lumbar, and sacral. The spinal cord and spinal nerves that enter and exit the vertebral column are divided into these regions as well. Moving from anterior (top) to posterior (bottom), the four regions of the spinal cord are:

Cervical. The cervical region corresponds to C1 through C7. Nerves that exit through the cervical region innervate the muscles in the neck, shoulders, arms, and hands. Afferent nerves detect somatosensory inputs from these same areas. Sections C3 through C5 innervate the diaphragm, so an injury at this level or higher can quickly lead to death since the person may stop breathing. The spinal cord is at the widest diameter at the cervical area, as it has a swelling that corresponds to the many inputs and outputs to the arms.
Thoracic. The thoracic region corresponds to T1 through T12. These regions innervate the middle trunk area, the intercostal muscles between the ribs, and abdominal muscles. Branches of the spinal nerves in the thoracic areas are responsible for changing the activity of the various internal organs during a fight-or-flight response (more on the autonomic nervous system in Chapter 27).
Lumbar. The lumbar region corresponds to L1 through L5. These pathways carry motor command information to the hips, thighs, and knees. Afferent lumbar inputs detect sensory information from the ventral side of the legs, such as the top of the thigh or the shin bone. As in the cervical region, the lumbar region has a swelling that increases the diameter of this section of spinal cord compared to the thoracic or sacral areas.
Sacral. At the posterior-most end of the spinal cord is the sacral region, which corresponds to S1 through S5. Sacral spinal nerves control flexing of the toes. These nerves detect sensory information around the genital organs and the dorsal aspects of the legs, like the buttocks and the back of the thighs. There are also parasympathetic nerves that come from the sacral region and these innervate the colon, bladder, and genital organs (more on the autonomic nervous system in Chapter 27). Since information must pass through the anterior regions of the spinal cord to reach the posterior parts of the body, the more anterior an injury, the more parts of the body that are affected.
From L2 through S5, the spinal cord exists as the cauda equina, meaning “horse’s tail” due to the appearance of the cord as individual nerves that branch from the main spinal cord. These nerves then innervate the pelvis area and lower limbs. This area of the spinal cord is where spinal tap and epidural procedures take place due to the decreased risk of spinal injury.
The spinal cord is part of the central nervous system, but the fibers that leave and enter the spinal cord are located in the peripheral nervous system. These spinal nerves can then extend to or from target tissues throughout the body.
Nerves are collections of neuron axons found within the peripheral nervous system and can be classified as sensory, motor, or mixed nerves. The dorsal root is an example of a sensory (afferent) nerve that is responsible for carrying information toward the central nervous system. The ventral root is an example of a motor (efferent) nerve that is responsible for carrying information away from the central nervous system. Most nerves in the body are classified as mixed nerves that contain both sensory and motor fibers.
Like the brain, the spinal cord is also made up of regions of white matter and gray matter. White matter regions are comprised of axons. It appears white due to the myelin sheath on the axons. Gray matter regions are comprised of cell bodies and dendrites. Gray matter is the location of most synapses.

In cross section, the gray matter of the spinal cord is found medially, and the white matter is found laterally. When referring to the spinal cord, we will typically use the directional terms “dorsal” and “ventral”. By convention, when looking a cross section of the spinal cord (a horizontal cut through the cord), the dorsal portion of the spinal cord will be located at the top of the image and the ventral portion of the spinal cord will be located at the bottom of the image. There are a few structures to be aware of when examining the spinal cord in cross section.
The white matter in the spinal cord is divided into structures called columns because the axons in these regions are either ascending toward the brain or descending toward the appropriate spinal nerve. The dorsal column is on the dorsal or posterior side of the spinal cord, the ventral horn is on the ventral or anterior side of the spinal cord, and the lateral column lies between them. The gray matter is likewise divided into regions called horns. The dorsal horn is the location of sensory synapses, the ventral horn is the location of motor neuron cell bodies, and the lateral horn is the location of cell bodies of the autonomic nervous system. The dorsal root and ventral root consist of the axons of afferent (dorsal) and efferent (ventral) fibers. They combine to form the spinal nerves. Sensory neuron cell bodies are located in the dorsal root ganglion, a gray matter region of the dorsal root.

All somatosensory receptor neurons have their cell bodies located in the dorsal root ganglion; a structure found just outside the dorsal aspect of the spinal cord. The receptor neurons (also called primary afferent fibers) of the somatosensory system are bipolar neurons, meaning they have one process from the cell body that splits into two branches. Afferent fibers coming from the periphery through the spinal nerves enter the spinal cord via the dorsal root. The cell bodies of sensory neurons are located in the dorsal root ganglion. The axons continue into the spinal cord and typically synapse in the dorsal horn. Interneurons are very short neurons that are a communication link between cell types in the spinal cord. They can be either excitatory or inhibitory depending on their role. They can also cross the midline of the spinal cord. The cell bodies of motor neurons that innervate skeletal muscles are located in the ventral horn. The efferent axons of these neurons leave the spinal cord via the ventral root and then enter the spinal nerve on their way to their target tissue.

The ventral portion of the spinal cord is concerned with motor output, or efferent signals. Muscle fibers are innervated by alpha motor neurons that have their cell bodies in the ventral horn of the spinal cord. Their axons leave the spinal cord via the ventral roots and travel to the muscle via efferent peripheral spinal nerves.

In summary, sensory information is concerned with the dorsal portion of the spinal cord whereas motor information is concerned with the ventral portion of the spinal cord.
The Peripheral Nervous System (PNS) functions as the intermediary between the central nervous system (CNS) and the rest of the body, including the skin, internal organs, and muscles of our limbs. The PNS can be divided into three main branches:

Somatic nervous system
Autonomic nervous system
Enteric nervous system
In this chapter, the somatic and autonomic nervous systems will be compared and contrasted. An overview of the enteric nervous system will also be provided.
The somatic and autonomic nervous system differ in their:

Target/effector organs
Efferent pathways and the neurotransmitters that are used
How the target/effector organ responds to the neurotransmitter
The somatic nervous system represents all the parts of the PNS that are involved with the outside environment, either in sensing the environment or acting on it. For example, the nerves that detect pressure or pain on the foot are part of the afferent somatic nervous system. We also think of the somatic nervous system as the branch that sends signals to our skeletal muscles. The nerves that innervate the muscles of the legs as we run are part of the efferent somatic nervous system. The somatic nervous system is also called the “voluntary nervous system” since it is used to cause muscle movement related to intentional actions.

The somatic nervous system has an efferent path from the central nervous system to the target / effector organ that is made up of one neuron. The axon of this neuron is heavily myelinated, which allows for fast delivery of messages. This somatic motor neuron has its cell body in the central nervous system and has an axon that extends all the way to the target/effector organ, which—for the somatic nervous system—will be a skeletal muscle.
All somatic motor neurons release the same neurotransmitter, acetylcholine, onto the skeletal muscle target/effector organ at the neuromuscular junction (NMJ). The NMJ is one of the largest synapses in the body and one of the most well-studied because of its peripheral location. Acetylcholine is the neurotransmitter released at the NMJ and it acts upon ligand-gated, non-selective cation channels called nicotinic acetylcholine receptors that are present in postjunctional folds of the muscle fiber. Acetylcholinesterase, an enzyme that breaks down acetylcholine and terminates its action, is present in the synaptic cleft of the neuromuscular junction.
Nicotinic acetylcholine receptors allow for the influx of sodium ions into the muscle cell. The depolarization will cause nearby voltage-gated channels to open and fire an action potential in the muscle fiber. In a healthy system, an action potential in the motor neurons always causes an action potential in the muscle cell. The action potential leads to contraction of the muscle fiber.
The autonomic nervous system encompasses all the branches of the peripheral nervous system that deal with the internal environment. As with the somatic nervous system, the autonomic nervous system is comprised of nerves that detect the internal state as well as nerves that influence the internal organs. The body carries out all sorts of functions and responses unconsciously without any intentional control. It can do so by sending signals to smooth muscles and glands. The signals that cause us to sweat when it is hot, our pupils to dilate when it is dark, and our blood pressure to adjust when we stand up too quickly are all driven by the nerves of the autonomic nervous system.

The autonomic nervous system has an efferent path from the central nervous system to the target/effector organ that is made up of a chain of two neurons with a ganglion in the middle. Recall that a ganglion is a collection of neuron cell bodies in the periphery.

The neuron that has its cell body in the central nervous system is called the preganglionic neuron. The preganglionic cell axon is lightly myelinated and extends to a ganglion in the periphery where it synapses on the second neuron in the chain called the postganglionic neuron. The postganglionic neuron has its cell body in the ganglion and its unmyelinated axon extends from the ganglion to the target/effector organ, which for the autonomic nervous system will be: smooth muscle, cardiac muscle, glands, or organs.

The first synapse happens at the site of the ganglion. All preganglionic cells release acetylcholine onto the postganglionic cells. The acetylcholine binds to nicotinic acetylcholine receptors, which results in the generation of an excitatory postsynaptic potential for the postganglionic cell body. This effectively passes the message between the preganglionic and postganglionic cells.

The second synapse occurs between the postganglionic cell and the target/effector organ. Postganglionic neurons in the autonomic nervous system release either norepinephrine or acetylcholine (more on this later). These neurotransmitters can have either stimulatory or inhibitory activity at the target organs, dependent on the properties of the postsynaptic receptor that they bind to.
Within the autonomic nervous system, synapses have a different structure than what is observed at the NMJ of the somatic nervous system. Instead, autonomic axons are highly branched and have enlarged varicosities that are spread along the axon. These varicosities contain synaptic vesicles that are filled with neurotransmitters. The varicosities form synapses ‘en passant’ (literally meaning ‘in passage’) with the target organ. These axon branches with varicosities drape over the cells of the target tissue, allowing a single axon branch to affect change over a greater area of the target tissue and better distribute autonomic activation at the target tissue.
In summary, the somatic nervous system has a one neuron path that originates in the central nervous system. That neuron extends all the way to the skeletal muscle (target tissue) where it releases acetylcholine. The acetylcholine binds to nicotinic acetylcholine receptors that cause EPSPs in the muscle fibers and giving a stimulatory effect. The autonomic nervous system (both branches) use a two neuron pathway between the CNS and the target tissues that are smooth muscle, cardiac muscle, glands, and organs. The sympathetic division consists of short presynaptic neurons that synapse on longer postsynaptic neurons in peripheral ganglia that are situated close to the spinal cord. The parasympathetic division consists of long presynaptic neurons that synapse on shorter postsynaptic neurons in peripheral ganglia that are situated close to the target organ. Like the somatic motor system, the primary neurotransmitter in the parasympathetic division is acetylcholine. In the sympathetic division, the preganglionic neuron releases acetylcholine, but the postganglionic neuron releases norepinephrine. The effects of these neurotransmitters at the target tissue can be either stimulatory or inhibitory depending on the properties of the postsynaptic receptor. This information is summarized in the figure and table below.
There are two branches of the autonomic nervous system, called the sympathetic nervous system and the parasympathetic nervous system, that typically have opposite effects at target tissues.

Consider a scenario in which you encounter a bear on hike through Yellowstone National Park. Your heartrate would likely increase and your breathing rate would increase as you contemplate how to survive your encounter. This complex set of physiological reactions are due to activation of one of the branches of the autonomic nervous system: the sympathetic nervous system. The sympathetic nervous system mobilizes a set of physiological changes to a threat that is sometimes called the fight-or-flight response, which is activated when we are faced with a threat, either perceived or real. All of these rapid bodily responses result in the body preparing to attack or defend itself. Increased respiration allows the body to take in more oxygen, and dilation of blood vessels in the muscles allows that oxygen to get to the muscles, which is needed for muscle activation.

Now, consider a completely opposite scenario. You’ve just eaten a large meal and you are spending the evening watching television on your couch. You would probably feel relaxed, satisfied, and more than a little sluggish. A different physiological response is happening, a behavior called the rest-and-digest response. These physiological changes are driven by the other main branch of the autonomic nervous system, called the parasympathetic nervous system.
The sympathetic nervous system and the parasympathetic nervous system are referred to as antagonistic. These branches are called ‘antagonistic’ because they typically have opposite effects at target tissues.

There is dual innervation at many target organs of the autonomic nervous system. This means that target organs receive connections from both sympathetic and parasympathetic neurons. In a sense, this dual innervation provides both a ‘break’ and an ‘accelerator’ for changing the activity of our internal organs, offering a good amount of control.

Both the sympathetic nervous system and parasympathetic nervous systems influence the internal organs simultaneously. At all times, the heart is getting signals from the sympathetic nervous system which increase heart rate, and signals from the parasympathetic nervous system which decreases heart rate. However, this seesaw-like balance can shift quickly in either direction, such as inducing a sympathetic response if a fearful stimulus is encountered.
The sympathetic and parasympathetic nervous systems differ anatomically as well. The sympathetic preganglionic neurons are short and the sympathetic postganglionic neurons are long. The parasympathetic preganglionic neurons are long and the parasympathetic postganglionic neurons are short.
The cell bodies of the preganglionic neurons of the sympathetic nervous system are located in the thoracic and lumbar sections of the spinal cord, so we can use thoracolumbar to describe the site of origin. The axons leave the central nervous system and travel only a short distance to the peripheral ganglion. In the sympathetic system, most of the ganglia are located along the spinal cord in the sympathetic paravertebral chain. A few sympathetic ganglia, called prevertebral, are located slightly more laterally. The preganglionic neurons synapse on the postganglionic neurons in the sympathetic ganglia. The postganglionic neurons then travel the rest of the distance to synapse on the target organs.
One exception to this structure is the innervation of the adrenal medulla. The adrenal gland is a structure located at the top of each kidney. The gland has an outer portion called the cortex and an inner portion called the adrenal medulla, which is made up of cells called chromaffin cells. The sympathetic preganglionic cell releases acetylcholine at the synapse with the chromaffin cells of the medulla and releases acetylcholine onto the chromaffin cell that is serving as a modified post-ganglionic neuron. Then the chromaffin cells of the adrenal medulla release epinephrine and norepinephrine into the bloodstream. Within the bloodstream these neurotransmitters can act as hormones affecting change throughout the body leading to a rapid onset of sympathetic activity and sustained activation.
The sympathetic preganglionic cell bodies are located in the intermediolateral cell columns in the lateral horn of the spinal cord, a gray matter region between the dorsal and ventral horns. The neurons send their axons out through the ventral root, and then can take one of multiple pathways. The axon can terminate in the paravertebral ganglion at the same spinal level as the cell body, or the axon can extend up or down the sympathetic chain to synapse on a postganglionic fiber at a different spinal level. Another possible pathway is to enter and exit the sympathetic chain without synapsing and continue on to terminate in a prevertebral ganglion located closer to the target organ.
On the other hand, parasympathetic neurons originates predominantly in the cervical spinal cord (near the neck), with some signals originating in the sacral areas (near the tail bone). The parasympathetic nervous system usually receives signals from several cranial nerves. Cranial nerve X, also called the vagus nerve innervates multiple bodily organs in the midsection of the body. For the parasympathetic nervous system, the ganglia are located very close to the target tissues. Therefore, the preganglionic neuron must be very long to reach all the way to the ganglion to makes its first synapse. But due to the proximity of the ganglion to the target tissue, the postganglionic neuron is very short.
We have already established that at the first synapse in the chain of autonomic neurons, all preganglionic neurons release acetylcholine, which binds to excitatory nicotinic receptors on the postganglionic neurons. This is true of both the sympathetic and parasympathetic nervous system. However, the two branches of the autonomic nervous system have different effects at target tissues because they use different neurotransmitters that produce either stimulatory or inhibitory effects at target tissues.

The sympathetic postganglionic neurons release norepinephrine at target tissues. Norepinephrine (and epinephrine) binds two major classes of adrenergic receptors: alpha adrenergic receptors and beta adrenergic receptors. The effects of norepinephrine (and epinephrine) can be either excitatory or inhibitory depending on the properties of the postsynaptic receptor.

The parasympathetic postganglionic neurons release acetylcholine at target tissues. The target tissues express muscarinic acetylcholine receptors. The effect of the acetylcholine can be either excitatory or inhibitory depending on the subtype of muscarinic (metabotropic) receptors. The location of function of these transmitters and receptors are critical for clinical use, for example, when treating high blood pressure or sexual dysfunction.
Visceral functions are regulated through a number of autonomic reflexes, but they can be directly controlled by higher brain areas. Within the brain stem, the medulla most directly controls autonomic activity. The medulla receives most of its information via the vagus nerve (a mixed nerve that contains both sensory and motor fibers). Within the medulla are a variety of control centers that regulate functions such as cardiovascular activity, respiratory rate, vomiting, and swallowing. The pons, another brain stem structure also serves as an autonomic control center for respiration.

In addition to brain stem structures, there are also higher order brain areas that are important for autonomic control. The hypothalamus can directly regulate the medulla, and is also critical for the regulation of water balance, temperature control, and hunger. The Limbic System, made up of a number of structures including the the hippocampus and amygdala, functions in our expression of emotion. The limbic system structures are responsible for visceral responses associated with emotional states, including blushing, fainting, pallor, nervous cold sweats, racing heart rate, and uneasy feelings in the stomach.

Further, the cerebral cortex and cerebellum also function in autonomic control. The cerebral cortex has been shown to regulate lower brain structures especially in autonomic control associated with emotion and personality. The cerebellum has connections to the medulla that are critical for the control of autonomic functions such as sweating and nausea.
The internal organs that carry out digestive functions, such as the esophagus, stomach, and intestines, are surrounded by a dense mesh of neurons that regulate their activity. Consisting of half a billion nerve cells, this net of neurons cause the digestive tract to increase or decrease the rate of these processes depending on the body’s demands The enteric nervous system receives signals from both the sympathetic and parasympathetic nervous systems, and functions without our conscious knowledge. Historically, these digestive functions have been classified as part of the autonomic nervous system, but these responses do not share the same reflex pathway, and the enteric signals can work entirely independent of the vagus nerve, for example.
Each sensory system is obviously quite different in the type of stimulation that it responds to and the manner in which environmental stimuli is converted to neuronal signaling. However, there are many principles that can be generalized across sensory systems.
Our sensory systems work by converting different types of stimuli in the environment (i.e. visible light, sound waves, chemical molecules) into action potentials in the nervous system. This conversion is called sensory transduction and occurs in all sensory systems.
Sensory transduction begins at the sensory receptors. Each sensory system has specialized cells that are able to detect the environmental stimuli. Photoreceptors detect light, chemical receptors in the tongue and nose detect odors and taste, mechanoreceptors detect touch, and hair cells detect sound.
We have learned about postsynaptic potentials in neurons, receptor potentials are similar membrane potential changes that happen in sensory receptors in response to a stimulus.
Receptive fields are easiest to understand in the visual and somatosensory systems. The receptive field for a neuron is the region of the retina or skin where a stimulus (light or touch) will evoke a response in the neuron. Receptive fields in the auditory system can consist of a certain frequency of sound and/or the location of sound in space.

Receptive fields can vary in size and shape depending on the characteristics of neuron (i.e. type, location in body, location in pathway). Receptive fields become more complex as information travels to the brain.
Lateral inhibition is a process used by sensory systems to enhance the perception of signals, particularly at edges, points, or other changes in the stimulus. It occurs because overlapping receptive fields can inhibit each other. This inhibition enhances the perceived differences between the stimulus and the area not stimulated.
There are a number of different ways in which the nervous system encodes complex information. Two that are common within the sensory systems are line coding and population coding.
In the labeled line coding of information, one cell encodes for one type of sensory quality. Pain is a good example of this. If a pain receptor is activated, the resulting sensation will be pain, regardless of the manner in which the receptor is stimulated. In other words, the sensory neurons are specifically tuned to one sensory stimulus. If that receptor-cell type was dysfunctional, the sensation will not be perceived. For example, there is a mutation that prevents sodium channels in pain receptors (but not other cell types) from working. When this mutation occurs, the subject cannot feel pain.

In populating coding, one cell can encode more than one sensory modality, and it is the combination of many cells that make up the perception. An example of this is color vision. Each color photoreceptor is most sensitive to a specific color (blue, green, or red), but a range of wavelengths can elicit changes in firing rates in the neuron. Therefore, the responses from a population of color photoreceptors must be combined to perceive the full spectrum of color.

Higher level processing of taste and olfaction also uses population coding – sometimes the sense of smell is needed in addition to the sense of taste to fully perceive a flavor. Have you ever been congested from a cold and food just doesn’t taste the same? That’s due to this combining of the senses for a full perception.
In general, the route sensory information takes from the periphery to the central nervous system is similar among most of the systems. Environmental stimuli become encoded by a specialized receptor in the periphery. Information then enters the central nervous system via the spinal cord or brainstem and relays through the thalamus, a structure that sits deep in the forebrain. The only sensory system that does not relay through the thalamus is the olfactory system. The thalamus then sends projections out to the primary cortical regions for each sensory system.
It’s common to hear that sensory information “relays” through the thalamus on the way to the cortex (for example, in the paragraph above). This language can give the impression that the thalamus is only responsible for making sure the sensory signal gets from periphery to the cortex. This greatly underestimates the thalamic role. The thalamus is known to contribute to the processing and modification of the sensory signal.
Humans are remarkably dependent on the visual system to gain information about our surroundings. Consider how tentatively you walk from the light switch to your bed right after turning off the lights!

The visual system is complex and consists of several interacting anatomical structures. Here, we will describe the process of how photons of light from our surroundings become signals that the brain turns into representations of our surroundings.
Visual sensation starts at the level of the eye. The eye is an organ that has evolved to capture photons, the elementary particle of light. Photons are unusual because they behave as both particles and as waves, but neuroscientists mostly focus on the wave-like properties. Because photons travel as waves, they oscillate at different frequencies. The frequency at which a photon oscillates is directly related to the color that we perceive.

The human visual system is capable of seeing light in a very narrow range of frequencies on the electromagnetic spectrum. On the short end, 400 nm wavelengths are observed as violet, while on the long end, 700 nm wavelengths are red. Ultraviolet light oscillates at a wavelength shorter than 400 nm, while infrared light oscillates at a wavelength longer than 700 nm. Neither ultraviolet nor infrared light can be detected with our eyes.
Photons pass through several anatomical structures before the nervous system processes and interprets them. The front of the eye consists of the cornea, pupil, iris, and lens. The cornea is the transparent, external part of the eye. The cornea refracts, or bends, the incoming rays of light so that they converge precisely at the retina, the posterior most part of the eye. If the light rays fail to properly converge, a person would be near-sighted or far-sighted, and this would result in blurry vision. Glasses or contact lenses bend light before it reaches the cornea to compensate the cornea’s shape.

After passing through the cornea, light enters through a hole in the opening in the iris at the center of the eye called the pupil. The iris is the colored portion of the eye that surrounds the pupil and along with local muscles that can control the size of the pupil to allow for an appropriate amount of light to enter the eye. The diameter of the pupil can change depending on ambient light conditions. In the dark, the pupil dilates, or gets bigger, which allows the eye to capture more light. In bright conditions, the pupils constricts, or gets smaller, which decreases the amount of light that enters the eye.

The next structure that light passes through is the lens. The lens is located behind the pupil and iris. Like the cornea, the lens refracts light so that the rays converge on the retina. Proper focusing requires the lens to stretch or relax, a process called accommodation. A circular muscle that surrounds the lens, called the ciliary muscle, changes the shape of the lens depending on the distance of the object of focus.

The retina is the light-sensitive region in the back of the eye where the photoreceptors, the specialized cells that respond to light, are located. The retina covers the entire back portion of the eye, so it’s shaped like a bowl. In the middle of the bowl is the fovea, the region of highest visual acuity, meaning the area that can form the sharpest images. The optic nerve projects to the brain from the back of the eye, carrying information from the retinal cells. Where the optic nerve leaves, there are no photoreceptors since the axons from the neurons are coming together. This region is called the optic disc and is the location of the blind spot in our visual field.
In addition to the photoreceptors, there are four other cell types in the retina. The photoreceptors synapse on bipolar cells, and the bipolar cells synapse on the ganglion cells. Horizontal and amacrine cells allow for communication laterally between the neuron layers.
When light enters the eye and strikes the retina, it must pass through all the neuronal cell layers before reaching and activating the photoreceptors. The photoreceptors then initiate the synaptic communication back toward the ganglion cells.
Photoreceptors are the first cells in the neuronal visual perception pathway. The photoreceptors are the specialized receptors that respond to light. They are the cells that detect photons of light and convert them into neurotransmitter release, a process called phototransduction.

Morphologically, photoreceptor cells have two parts, an outer segment and inner segment. The outer segment contains stacks of membranous disks bounded within the neuronal membrane. These membranous disks contain molecules called photopigments, which are the light-sensing components of the photoreceptors. Hundreds of billions of these photopigments can be found in a single photoreceptor cell. The inner segment contains the nucleus and other organelles. Extending from the inner segment is the axon terminal.

Photoreceptors are classified into two categories, named because of their appearance and shape: rods and cones. Rod photoreceptors have a long cylindrical outer segment that holds many membranous disks. The presence of more membranous disks means that rod photoreceptors contain more photopigments and thus are capable of greater light sensitivity.

Cone photoreceptors have a short, tapered c, and cylindrical outer segment that holds fewer membranous disks than rod photoreceptors. The presence of less membranous disks means that cone photoreceptors contain less photopigments and thus are not as sensitive to light as rod photoreceptors. Cone photoreceptors are responsible for processing our sensation of color (the easiest way to remember this is cones = color). The typical human has three different types of cone photoreceptors cells, with each of these three types tuned to specific wavelengths of light. The short wavelength cones (S-cones) respond most robustly to 420 nm violet light. The middle wavelength cones (M-cones) exhibit peak responding at 530 nm green light, and the long wavelength cones (L-cones) are most responsive in 560 nm red light. Each of these cones is activated by other wavelengths of light too, but to a lesser degree. Every color on the visible spectrum is represented by some combination of activity of these three cone photoreceptors.

The idea that we have two different cellular populations and circuits that are used in visual perception is called the duplicity theory of vision and is our current understanding of how the visual system perceives light. It suggests that both the rods and cones are used simultaneously and complement each other. The photopic vision, uses cone photoreceptors of the retina, and is responsible for high-acuity sight and color vision in daytime. Its counterpart, called scotopic vision, uses rod photoreceptors and is best for seeing in low-light conditions, such as at night. Both rods and cones are used for mesopic vision, when there are intermediate lighting conditions, such as indoor lighting or outdoor traffic lighting at night.

In addition to having different visual functions, the rods and cones are also distributed across the retina in different densities. Visual information from our peripheral vision is generally detected by our rod cells, which are most densely concentrated outside the fovea. Cone photoreceptor cells allow for high-acuity vision. They are most densely packed at the fovea, corresponding to the very center of your visual field. Despite being the cell population that we use for our best vision, cone cells make up the minority of photoreceptors in the human retina, outnumbered by about 20-times more rod cells.
Rod cells are organized to have high synaptic convergence, where several rod cells (up to 30) feed into a single downstream route of communication (the bipolar cells, to be specific). An advantage of a high-convergence network is the ability to add many small signals together to create a seemingly larger signal. Consider stargazing at night, for example. Each rod is able to detect low levels of light, but signals from multiple rod cells, when summed together, allows you to recognize faint light sources such as a star. A disadvantage of this type of organization is that it is difficult to identify exactly which photoreceptor is activated by the incoming light, which is why accuracy is poor when seeing stimuli in our peripheral vision. This is one of the reasons that we cannot actually read text in our peripheral vision or see the distinct edges of a star. Rod photoreceptors are maximally active in low-light conditions.

Unlike rod cells, cone cells have very low synaptic convergence. In fact, at the point of highest visual acuity, a single cone photoreceptor communicates with a single pathway to the brain. The signaling from low-convergence networks is not additive, so they are less effective at low light conditions. However, because of this low-convergence organization, cone cells are highly effective at precisely identifying the location of incoming light.
The retina is not completely uniform across the entire back of the eye. There are a few spots of particular interest along the retina where the cellular morphology is different: the fovea and the optic disk.

There are two cellular differences that explain why the fovea is the site of our best visual acuity. For one, the neurons found at the fovea are “swept” away from the center, which explains why the fovea looks like a pit. Cell membranes are made up mostly of lipids, which distort the passage of light. Because there are fewer cell bodies present here, the photons of light that reach the fovea are not refracted by the presence of other neurons. Secondly, the distribution of photoreceptors at the fovea heavily leans toward cone type photoreceptors. Because the cone cells at the fovea exhibit low convergence, they are most accurately able to pinpoint the exact location of incoming light. On the other hand, most of the photoreceptors in the periphery are rod cells. With their high-convergence circuitry, the periphery of the retina is suited for detecting small amounts of light, though location and detail information is reduced.
Another anatomically interesting area of the retina is an elliptical spot called the optic disk. This is where the optic nerve exits the eye. At this part of the retina, there is an absence of photoreceptor cells. Because of this, we are unable to perceive light that falls onto the optic disk. This spot in our vision is called the blind spot.
The photoreceptors are responsible for sensory transduction in the visual system, converting light into electrical signals in the neurons. For our purposes, to examine the function of the photoreceptors, we will A) focus on black and white light (not color vision) and B) assume the cells are moving from either an area of dark to an area of light or vice versa.

Photoreceptors do not fire action potentials; they respond to light changes with graded receptor potentials (depolarization or hyperpolarization). Despite this, the photoreceptors still release glutamate onto the bipolar cells. The amount of glutamate released changes along with the membrane potential, so a hyperpolarization will lead to less glutamate being released. Photoreceptors hyperpolarize in light and depolarize in dark. In the graphs used in this lesson, the starting membrane potential will depend on the initial lighting condition.
When the photoreceptor moves into the light, the cell hyperpolarizes. Light enters the eye, reaches the photoreceptors, and causes a conformational change in a special receptor protein called an opsin. The opsin receptor has a pre-bound chemical agonist called retinal. Together, the opsin + retinal makes up the photopigment rhodopsin.

When rhodopsin absorbs light, it causes a conformational change in the pre-bound retinal, in a process called “bleaching”.  The bleaching of rhodopsin activates an associated G-protein called transducin, which then activates an effector enzyme called phosphodiesterase (PDE). PDE breaks down cGMP in the cell to GMP. As a result, the cGMP-gated ion channels close. The decrease in cation flow into the cell causes the photoreceptor to hyperpolarize.

In the dark, the photoreceptor has a membrane potential that is more depolarized than the “typical” neuron we examined in previous chapters; the photoreceptor membrane potential is approximately -40 mV.

Rhodopsin is not bleached, thus the associated G-protein, transducin, remains inactive. As a result, there is no activation of the PDE enzyme, and levels of cGMP within the cell remain high. cGMP binds to cGMP-gated sodium ion channels, causing them to open. The open cation channels allow the influx of sodium and calcium, which depolarize the cell in the dark.

Photoreceptors synapse onto bipolar cells in the retina. There are two types of bipolar cells: OFF-center bipolar cells and ON-center bipolar cells. These cells respond in opposite ways to the glutamate released by the photoreceptors because they express different types of glutamate receptors. Like photoreceptors, the bipolar cells do not fire action potential and only respond with graded postsynaptic potentials.
In OFF-center bipolar cells, the glutamate released by the photoreceptor is excitatory. OFF-center bipolar cells express ionotropic glutamate receptors. In the dark, the photoreceptor is depolarized, and thus releases more glutamate. The glutamate released by the photoreceptor activates the ionotropic receptors, and sodium can flow into the cell, depolarizing the membrane potential. In the light, the photoreceptor is hyperpolarized, and thus does not release glutamate. This lack of glutamate causes the ionotropic receptors to close, preventing sodium influx, hyperpolarizing the membrane potential of the OFF-center bipolar cell. One way to remember this is that OFF-center bipolar cells are excited by the dark (when the lights are OFF).
In ON-center bipolar cells, the glutamate released by the photoreceptor is inhibitory. ON-center bipolar cells express metabotropic glutamate receptors. In the dark, the photoreceptor is depolarized, and thus releases more glutamate. The glutamate released by the photoreceptor binds to the metabotropic receptors on ON-center bipolar cells, and the G-proteins close cation channels in the membrane, stopping the influx of sodium and calcium, hyperpolarizing the membrane potential. In the light, the photoreceptor is hyperpolarized, and thus does not release glutamate. The absence of glutamate results in the ion channels being open and allowing cation influx, depolarizing the membrane potential. You can remember that ON-center bipolar cells are excited by the light (when the lights are ON).

Retinal ganglion cells are the third and last cell type that directly conveys visual sensory information, receiving inputs from the bipolar cells. OFF-center and ON-center bipolar cells synapse on OFF-center and ON-center ganglion cells, respectively. The axons of the retinal ganglion cells bundle together and form the optic nerve, which then exits the eye through the optic disk. Retinal ganglion cells are the only cell type to send information out of the retina, and they are also the only cell that fires action potentials. The ganglion cells fire in all lighting conditions, but it is the relative firing rate that encodes information about light. A move from dark to light will cause OFF-center ganglion cells to decrease their firing rate and ON-center ganglion cells to increase their firing rate.
Each bipolar and ganglion cell responds to light stimulus in a specific area of the retina. This region of retina is the cell’s receptive field. Receptive fields in the retina are circular.

Size of the receptive field can vary. The fovea has smaller receptive fields than the peripheral retina. The size depends on the number of photoreceptors that synapse on a given bipolar cell and the number of bipolar cells that synapse on a given ganglion cell, also called the amount of convergence.
Let’s use an example of an ON-center bipolar cell to look at the structure of receptive fields in the retina. The bipolar and retinal ganglion cell receptive fields are divided into two regions: the center and the surround. The center of the receptive field is a result of direct innervation between the photoreceptors, bipolar cells, and ganglion cells. If a light spot covers the center of the receptive field, the ON-center bipolar cell would depolarize, as discussed above; the light hits the photoreceptor, it hyperpolarizes, decreasing glutamate release. Less glutamate leads to less inhibition of the ON bipolar cell, and it depolarizes.
The surround portion of the receptive field is a result of indirect communication among the retinal neurons via horizontal and amacrine cells. The surround has an opposing effect on the bipolar or ganglion cell compared to the effect of the center region. That is to say, that the center and surround of the receptive field are opposite to each other. So, an ON-center bipolar or ganglion cell, can also be referred to as an “ON-center OFF-surround cell”, and an OFF-center bipolar or ganglion cell can also be referred to as an “OFF-center ON-surround cell”.

Therefore, if light covers the surround portion, the ON-center bipolar cell would respond by hyperpolarizing. The light would cause the photoreceptor in the surround to hyperpolarize. This would cause the horizontal cell to also hyperpolarize. Horizontal cells have inhibitory synaptic effects, so a hyperpolarization in the horizontal cell would lead to a depolarization in the center photoreceptor. The center photoreceptor would then cause a hyperpolarization in the ON-center bipolar cell. These effects mimic those seen when the center is in dark. So, even though the center photoreceptor is not directly experiencing a change in lighting conditions, the neurons respond as if they were moving toward dark.
The center-surround structure of the receptive field is critical for lateral inhibition to occur. Lateral inhibition is the ability of the sensory systems to enhance the perception of edges of stimuli. It is important to note that the photoreceptors that are in the surround of one bipolar cell would also be in the center of a different bipolar cell. This leads to a direct synaptic effect on one bipolar cell while also having an indirect effect on another bipolar cell.
Although some of the images used here will simplify the receptive field to one cell in the center and a couple in the surround, it is important to remember that photoreceptors cover the entire surface of the retina, and the receptive field is two-dimensional. Depending on the level of convergence on the bipolar and ganglion cells, receptive fields can contain many photoreceptors.
In this chapter we will learn about how the information from the retina is processed centrally within the brain.
Before learning the pathway that visual information takes from the retina to the cortex, it is necessary to understand how the retina views the world around us. The full visual field includes everything we can see without moving our head or eyes.
The full visual field can be divided in a few ways. Each individual eye is capable of seeing a portion of, but not the entire, visual field.
The full visual field can also be divided into the right and left hemifields. The hemifields range from the most peripheral point to the center point, splitting the full visual field into two equal regions. Both eyes are involved in viewing each hemifield. The fovea separates the retina into two sections: the nasal retina and the temporal retina. The nasal retina is the medial portion that is located toward the nose. The temporal retina is the lateral portion that is located toward the temples and temporal lobe. The nasal retina from one eye along with the temporal retina from the other eye are able to view an entire hemifield.
Finally, the full visual field can be separated into monocular and binocular regions. Each monocular field is visual space that can only be viewed by one eye. The binocular region is visual space that can be viewed by both eyes.
Visual information from each eye leaves the retina via the ganglion cell axons at the optic disc, creating the optic nerve. The optic nerve, or cranial nerve II, exits the posterior end of the eyeball, and travels posteriorly along the ventral surface of the brain. Like all other cranial nerves, the optic nerve is paired, meaning there is one for each eye. Both optic nerves merge at a spot called the optic chiasm, then diverge yet again as they travel posteriorly towards the thalamus.

The axonal connections in the optic nerve are not quite as simple as its anatomical appearance. From each optic nerve, some of the nerve fibers cross the midline (decussate), headed towards the contralateral hemisphere. Other nerve fibers meet at the optic chiasm, but then project into the ipsilateral hemisphere.

Prior to entering the brain, axons from the nasal portion of each retina cross the midline at the optic chiasm but the temporal portion of each retina does not cross at the optic chiasm.
Since the axons from the nasal retina cross to the opposite side of the nervous system but the temporal retina axons do not, this leads to the brain processing input from the contralateral (opposite side) visual hemifield. Therefore, the right side of the brain receives visual information from the left hemifield and vice versa. The easy way to keep track of this unusual system is to remember that all information from the left visual field enters the right hemisphere of the brain, while visual information from the right visual field enters the left hemisphere of the brain.
The retinal ganglion cells that exit the retina and project into the brain can take different paths. The retinofugal projection (fugal means “to flee”) is one of the major projection paths of the retinal ganglion cells. Most retinal output projects to the lateral geniculate nucleus of the thalamus and then to the primary visual cortex, however there are subsets of cells that are routed through other non-thalamic pathways.
Not all of the axons convey direct visual information into the thalamus for visual perception. Some ganglion cells project to the superior colliculus, a midbrain region via the retinotectal pathway (recall that the superior colliculus is a structure of the tectum). This pathway communicates with motor nuclei and is responsible for pupillary control. Specifically, it is responsible for movements that will orient the head and eyes toward an object to focus the object in the center of the visual field, the region of highest visual acuity.

A subset of specialized retinal ganglion cells project to the suprachiasmatic nucleus in the hypothalamus through the retinohypothalamic tract (starts in the retina, ends in the hypothalamus). It does not carry any conscious visual information. The retinohypothalamic tract conducts light information from a small group of intrinsically-photosensitive retinal ganglion cells. This structure functions to help the body adapt its sleep-wake cycle in the face of changing day-night patterns This region is critical for circadian rhythms and the sleep/wake cycle.
In conscious visual perception, the first synapse of the optic nerve is formed in the thalamus at a subregion called the lateral geniculate nucleus, or LGN. The optic tract enters the brain and ascends to synapse in the lateral geniculate nucleus of the thalamus. From there, axons project to the primary visual cortex, also called the striate cortex or V1, located in the occipital lobe.
The lateral geniculate nucleus of the thalamus (LGN) has six distinct layers when examined in cross section. The LGN serves as the first synaptic site of the retinal ganglion cells that exited the retina.

Importantly, visual information is separated at the level of the LGN such that visual information from each visual field is all processed in the contralateral LGN. This means that information from the left visual hemifield, collected via the right temporal retina and the left nasal retina will all be processed within the right LGN. Information from the right visual hemifield, collected via the left temporal retina and the right nasal retina will all be processed by the left LGN.

Within the LGN, input coming from each eye is kept separate by the layers of the LGN. For example, notice that half of the layers of the right LGN process information from the right eye and the other half of the layers process information from the left eye.
The outputs of the LGN are a series of axonal bundles called the optic radiations. From the LGN of the thalamus, the optic radiations project to the occipital lobe at the caudal (posterior) end of the brain. Once visual information travels into the cortex, the process is less about sensation and mostly about perception.
The outputs of the LGN are axons which form synapses in the primary visual cortex, which is also called V1 or the striate cortex. ‘Striate’ means ‘stripe’ and is named due to the presence of a large white stripe that can be seen in unstained tissue during surgical dissection. This white stripe is the bundle of incoming optic tract axons, which are heavily myelinated.

Each neuron in V1 receives visual information from a specific patch of retinal cells. This organizational pattern, where a section of retinal inputs map onto neurons of a specific section of V1, is called retinotopic organization. This retinotopic organization is conserved from the retina to the LGN, and finally to the primary visual cortex. Visual information from the fovea, despite being only 1% of the total visual field, takes up about half of all neurons in V1. After processing in V1, visual information is passed along to other cortical areas that contribute to various aspects of visual perception.
The cortex of the brain is arranged into six layers, named with the Roman numerals I-VI. The cells within these layers have different morphology. These cortical layers are especially visible within the striate cortex (V1). Within this region, the thickness of the cortex between the pia mater that is in contact with the top of the cortex and the white matter underlying the cortex is very thin (around 2 mm in thickness).
These cells within the six layers of the cortex are arranged in what are called ‘cortical columns’. This arrangement was discovered by Dr. Vernon Mountcastle in the 1950s. You can imagine that due to the directionality of communication in neurons, that information travels up and down the cells within a single cortical column.
Dr. David Hubel and Dr. Torsten Wiesel followed up on this critical discovery by Mountcastle to describe neuronal processing within the visual cortex. Their discoveries in this field led to them being awarded the Nobel Prize in the field of Physiology or Medicine in 1981. Highlighted below are some of their major contributions.
Hubel and Wiesel used microelectrodes to map the functioning of the visual cortex. In one of their famous experiments, Hubel and Wiesel used anesthetized cats to determine how the visual cortex processes visual information. During their experiment, they were showing the anesthetized cat different visual stimuli through the projection of slides with different images onto a screen while recording from neurons within the visual cortex. Due to when this experiment was done, these slides were large and plastic and had to be physically inserted into a projector. In the process of inserting these slides into the projector, a bar of light was projected onto the screen by the edge of the slide. Quite by surprise, the act of changing the slides (and the bar of light that resulted) caused the neurons within the cat brain to fire action potentials. Hubel and Wiesel determined that the stimulus causing the neurons to fire was the angle of the bar of light projected on the screen.

In fact, the neurons within the visual cortex responded best to a line in a specific orientation and the firing rate of the neuron increased as the line rotated toward the “preferred” orientation. The firing rate is highest when the line is in the exact preferred orientation and different orientations are preferred by different neurons. This discovery was due to some great luck for Hubel and Wiesel as they were recording from neurons that had a preferred orientation that exactly matched the angle of changing the slides in their projector!
This orientation selectivity within the visual cortex is the same for all neurons located within a single cortical column. This means that the cells in each cortical column will respond optimally to a line at a preferred orientation. So, if a recording electrode is inserted vertically through the cortex to record from cells within a single cortical column, all cells will respond optimally to the same sensory stimulus. If the recording electrode is inserted horizontally, such that it records across multiple cortical columns, each cortical column will respond optimally to a different sensory stimulus.
Another experiment by Hubel and Wiesel determined the existence of ocular dominance columns, or columns of neurons within the visual cortex that respond preferentially to either the left or right eye.

For this experiment, Hubel and Wiesel injected a radioactive amino acid into one of the eyes of a monkey. This amino acid then travels by anterograde transport through the retinal ganglion cells of the eye through the first synapse at the lateral geniculate nucleus of the thalamus, and then through the next synapse with the striate cortex. Radioactivity within the striate cortex can then be visualized through the process of autoradiography.

In an autoradiograph image of the striate cortex, there are alternating areas that appear white in color with areas that appear black in color (similar to the stripes on a zebra). The areas of the cortex that appear white are the areas that took up the radioactive amino acid and are processing information from the injected eye. The areas of the cortex that appear black are areas that do not have the radioactive amino acid and are processing information from the eye that was not injected. Recall, that although information from the left visual hemifield is processed on the right side of the brain, the left visual hemifield information is collected from both eyes via the left nasal retina and right temporal retina. Therefore, both eyes are processed across both the left and right visual cortex.
Interestingly, in newborn cats that had not had any visual experience, they did not observe the ocular dominance columns. Instead, they saw that the inputs of the left and right eye overlapped substantially within the visual cortex. Hubel and Wiesel were interested in understanding how these ocular dominance columns develop between infancy and adulthood and whether their development was dependent on visual experience.

For their experiment, they took a kitten immediately after birth, and sewed the right eye of the kitten closed, so that the eye could no longer have any visual experience, a condition called monocular deprivation (‘mono’ meaning ‘one’ and ‘ocular’ meaning ‘eye’). After this six-week period of monocular deprivation, the eye of the cat was reopened so that it could take in the visual environment. A control group of cats had normal visual experience for this same six-week period.

In control cats that did not experience monocular deprivation, Hubel and Wiesel found that they developed normal ocular dominance columns at six weeks post birth. The cats that experienced monocular deprivation for the first six weeks of life, however, showed abnormal development of the ocular dominance columns. The columns that normally served the right eye (that was sewn shut) shrank in size, and the neighboring columns that served the left eye grew into the unoccupied cortical space. Hubel and Wiesel were able to conclude that visual experience was necessary for the ocular dominance columns to develop. In fact, they found that there was a critical period in cat visual development in the first six weeks of life where visual experience is required for normal visual development.

Importantly, these structural changes also translated into functional changes for the vision of the cat. Cats that experienced monocular deprivation had decreased visual function in the eye that was sewn shut for the rest of the cat’s life. Even though the sewn shut eye was reopened after the critical period, the development of the ocular dominance columns in the brain was already complete and thus the brain could never process visual information from the sewn shut eye.
Sensory system processing of input does not end upon reaching the primary sensory cortex in any sensory system. Information typically gets sent from the primary sensory cortex to other sensory association regions throughout the brain. The characteristics of sensory information becomes more complex as this higher-level processing occurs.
In the visual system, there are two broad streams of information that leave the striate cortex. Visual information passes through two streams of communication: the dorsal stream and the ventral stream. In the ventral stream, information travels from the primary visual cortex down through the inferior temporal lobe is responsible for determining object recognition, or what an object is. Differentiating between an apple and a person occurs in this stream. In the dorsal stream, information travels from the striate cortex up through the parietal lobe and is responsible for motion or spatial components of vision.
The dorsal stream is described as the “where” pathway because these structures help us identify where objects are located in the space around us. One of the most important regions in the dorsal pathway is region MT, also called V5, which contributes to perception of motion. In this region, neurons are preferentially activated by a specific direction of movement by an object – for example, left to right or up to down. As an example, remember the receptive fields in the primary visual cortex were activated by lines at a specific orientation. Like that, in V5, the neurons would be activated by lines moving in a specific direction.

As information continues to be processed through the dorsal stream, the neurons become selective for more complex motions. The dorsal stream is also important for processing our actions in response to visual stimulation, for example, reaching for an object in the visual field or navigating around objects while walking.

These structures also guide us when we move through our environments, contributing to our sense of spatial awareness. For example, a task such as reaching out to grab an object in front of you uses a combination of these features, so this task is guided largely by dorsal stream structures.
The ventral stream is the “what” pathway, and helps in the identification of objects that we see. Object identification is a key function of our visual system. The ventral visual stream is responsible for this process. Further, ventral stream structures are important for visual memory. Like the more complex activation characteristics of region MT in the dorsal stream, neurons in Area V4 in the ventral stream show more complex receptive fields and show sensitivity to shape and color identification. In fact, there is a rare clinical condition in humans called achromatopsia, in which individuals have partial or complete loss of color vision. These individuals still have normal functioning cones within the retina, and normal LGN and primary visual cortex function. Instead, they typically have damage to occipital and temporal lobes, where the ventral stream is located.

A major output of area V4 is area IT, located within the inferior temporal lobe. As information travels to area IT it continues to be processed and differentiation of objects occurs. Neurons located in area IT are important in learning and memory in visual perception (have I seen that before?), and have been found to respond to colors and shapes.

Another region within the ventral stream called the fusiform face area, located in the fusiform gyrus, which lies on the ventral aspect of the temporal lobe, contains neurons that are activated by faces and can be specialized to one specific face. When the visual system senses these complex stimuli, those signals get processed through these ventral stream pathways. These incoming stimuli are compared with the memories stored in the ventral stream, and this comparison contributes to our capacity for perception and identification.

The two streams are not independent of each other. Rather, successful organisms require the melding of both components of visual perception. For example, imagine you are a prehistoric organism living in a food-scarce environment. Approaching a small berry tree, you would use ventral stream structures to correlate the berries with memories: Did these berries taste good and give me the calories I need to survive? Or did these berries make me violently ill, and are therefore probably poisonous? If they are the delicious berries that I want, I will use the dorsal stream structures to take note of their precise location so I can reach out for them and pick the berries . In this example, proper interaction of the dual streams contributes to goal-driven actions.
The inferior temporal lobe also makes reciprocal connections with the structures in the limbic system. The limbic system plays an important role in processing emotions and memory, both of which are significant components to visual perception. The amygdala ties visual stimuli with emotions and provides value to objects. A family member will have emotional ties that a stranger will not. The hippocampus is responsible for learning and memory and helps establish memories of visual stimuli.
Our nervous system is equipped with a variety of specialized biological “tools” that can detect much more than just photons of light. We can detect the shape of air waves, and interpreting those signals give us sound information and the perception of music. In this chapter we will trace how sounds travel through the structures of the ear, ultimately causing the auditory receptors to alter their activity and send their signals to the brain.
Unlike photons of light, sound waves are compressions and rarefactions of a medium. For us land animals, that medium is usually air, but sound waves can propagate very well in water or through solids. Before we get to the anatomical structures involved in sound perception, it is important to first understand the physical nature of sound waves. All sounds, from the clattering of a dropped metal pan to the melodies of a Mozart violin concerto, are contained in their corresponding sound waves. Two components of sound waves are frequency and amplitude.

Frequency, or “How often do the sound waves compress?” The greater the frequency, the higher the pitch. The highest notes humans are able to hear is around 20,000 Hz, a painfully-shrill sound for those who can hear it. People often tend to lose their high frequency hearing as they age. On the opposite end of the spectrum, low frequency sounds are the deep rumbles of bass, and the human ear can hear sounds down in the 20 Hz range.
Amplitude, or “How much do the waves displace the medium from baseline?” The larger the amplitude of the wave, or the greater distance between the peak and the trough of the signal, the louder the sound is. Loudness is measured in decibels (dB). To give you an idea of approximate sound intensities, the background noise of a quiet library is about 40 dB, and a typical conversation is close to 60 dB. A rock concert or lawnmower is between 100 and 110 dB, which is right around the pain threshold. Prolonged exposure to these high amplitude sound waves can lead to permanent damage to the auditory system resulting in hearing loss or tinnitus (a ringing in the ear, even in the absence of a sound stimulus).
Our auditory system is a series of physical structures and nervous system components that are responsible for conveying sound waves into meaning and context.

The external component of the auditory system begins with the pinna. Its shape functions as a funnel, capturing and channeling sound waves into the auditory canal. The pinna and the auditory canal are parts of the outer ear. Also, because the pinna is asymmetrical, its shape helps us determine where a sound is coming from. In some nonhumans, the pinna serves these functions and more. For instance, some animals are able to disperse excess heat through their ears (elephants), and some even use them to display emotion (dogs, horses).

At the end of the auditory canal is the tympanic membrane, or ear drum. This membrane is a very delicate piece of tissue at only 0.1 mm thin and is subject to damage by physical injury such as head trauma, nearby explosions, or even changes in air pressure during scuba diving. When incoming sound waves reach the tympanic membrane, it vibrates at a matching frequency, and amplitude. The tympanic membrane also represents the boundary between the outer ear and the middle ear.
The middle ear is an air-filled chamber. Physically attached to the tympanic membrane are the ossicles, a series of three bones that convey that vibrational sound information. These bones in order, called the malleus, incus, and stapes, conduct vibrations of the tympanic membrane through the air-filled middle ear. The stapes has a footplate that attaches to a structure called the oval window, which serves as the junction between the middle ear and the inner ear. The middle ear serves important functions in both sound amplification and sound attenuation.
The tympanic membrane and the ossicles function to amplify incoming sounds, generally by a tenfold difference. This amplification is accomplished through 2 mechanisms:

Due to the ossicles being connected, the ossicles act in a lever-like fashion to amplify the movements of the tympanic membrane to the oval window
The stapes has a smaller area on the oval window than the tympanic membrane, thus movements of the larger tympanic membrane must be transformed into smaller and stronger vibrations at the oval window.
This amplification is important because the inner ear is filled with liquid rather than air, and sound waves do not travel very well when moving from air into a denser medium – think about how muffled sounds are when you submerge your head underwater.
The movement of the ossicles are partially regulated by two different muscles, the tensor tympani muscle which connects with the malleus, and the stapedius muscle which connects to the stapes. When these muscles contract, it causes the ossicles to be more rigid and for the ossicles to move less, which decreases the intensity of loud sounds. This response, called the acoustic reflex, dampens incoming sound by about 15 dB. (This is why we talk much louder than normal when we first leave a concert: we have lessened auditory feedback from our ears, so we tend to talk louder to compensate.) The muscles contract at the onset of loud noises with a slight delay of 50-100ms.
The inner ear is a fluid-filled structure made up of two structures: the cochlea that functions in hearing, and the semicircular canals that function in balance.

The auditory part of this structure is a small spiral-shaped structure about the size of a pea, called the cochlea (cochlea is named for the Ancient Greek word “snail shell”.) The cochlea has two small holes at its base: the oval window and the round window.
When we examine a cross-section of the cochlea, we can see that there are 3 distinct fluid-filled chambers called the scala vestibuli, the scala media, and the scala tympani. These chambers are separated from each other by membranes.

The fluid found within the scala vestibuli and scala tympani is called perilymph and it has a low concentration of potassium and a high concentration of sodium. The scala media is filled with a fluid called endolymph that has a high concentration of potassium and a low concentration of sodium.

Reissner’s membrane separates the scala vestibuli from the scala media. The basilar membrane separates the scala tympani from the scala media.
Think of the cochlea as a rolled-up cone. If this cone was theoretically unrolled, the widest diameter portion, called the base, would be closest to the oval window, while the narrowest portion, called the apex, would be at the center of the spiral.

The basilar membrane runs down the middle of the cochlea. The width of the basilar membrane changes as it runs down the length of the cochlea from the base to the apex. This change in shape from the base to the apex is important: objects with different stiffness vibrate at different frequencies. The base of the cochlea is stiff and rigid and will vibrate at high frequencies. Whereas the apex is wider and less stiff, so it vibrates at lower frequencies.

Because different frequencies of sound affect different areas of the basilar membrane, the basilar membrane is what is referred to as tonotopically organized. In fact, you can think about the way that frequencies are mapped to the basilar membrane similar to a backwards piano.
Let’s consider how sounds will affect the cochlea. For simplicity’s sake, the figure here shows only the scala vestibuli and the scala tympani (not the scala media) with the basilar membrane running down the middle. Keep in mind that due to the flexibility of Reissner’s membrane that separates the scala vestibuli from the scala media, we can assume that pressure changes in the scala vestibuli are transferred through the scala media, ultimately affecting the basilar membrane.

When sounds move through the outer and middle ear, it causes vibration of the stapes footplate at the oval window. The movement of the stapes at the oval window is similar to a piston pushing at the oval window at the same frequency and amplitude as the incoming sound.
When the stapes pushes into the oval window, it causes movement of the perilymph within the scala vestibuli.
This causes the sounds to move through the cochlea as a wave from the base to the apex, displacing the flexible basilar membrane at different locations dependent on the frequency of sound.
At the apex of the basilar membrane is a hole called the helicotrema that connects the perilymph of the scala vestibuli to the perilymph of the scala tympani and allows for the pressure to be transferred from the scala vestibuli to the scala tympani.
The pressure then moves through the scala tympani back towards the base of the cochlea until it pushes out at the round window.
Embedded within the basilar membrane is a structure called the Organ of Corti. The Organ of Corti is the first nervous system structure that is responsible for processing physical vibrations and converting them into signals that the nervous system can interpret. The Organ of Corti contains the components necessary for converting sound waves into action potentials. Recall that the scala media that surrounds the Organ of Corti contains endolymph, a fluid that has a high concentration of potassium and a low concentration of sodium.

A separate membrane hangs over the Organ of Corti called the tectorial membrane. Recall that “tectum” means roof. The tectorial membrane acts as a roof over the Organ of Corti.

Embedded along the interior surface of the Organ of Corti are the somata of hair cells, the primary sensory neurons that interpret physical movement. They are named “hair cells” because of their cellular structure; each hair cell has somewhere between 30 and a few hundred hair-shaped stereocilia that protrude away from the Organ of Corti, reaching into the endolymph.

Importantly, hair cells are not neurons. They do not produce action potentials and do not have axons. In fact, hair cells are a specialized type of epithelial cell. We have two different populations of hair cells, the inner hair cells and outer hair cells.

The outer hair cells are arranged in three rows. Their stereocilia extend into the endolymph  and are physically embedded within the tectorial membrane.
The inner hair cells are arranged in a single row. Their stereocilia extend into the endolymph but are not embedded within the tectorial membrane. Instead, the stereocilia of the inner hair cells freely float within the endolymph.
Although the hair cells themselves are not neurons, the mechanical bending of the hair cell stereocilia will be converted into a neural signal. Hair cells synapse on spiral ganglion cells (neurons). The axons of the spiral ganglion cells make up the auditory nerve, which will project into the cochlear nuclei of the medulla.

As we have learned, when a vibration reaches the oval window, this causes the basilar membrane to move in response to the change in pressure. The basilar membrane is located at the base of the hair cells, and as the basilar membrane moves up and down, it pushes the hair cell stereocilia into the tectorial membrane above, causing the stereocilia to bend.
Let’s take a closer look at the structure of the hair cell.

The stereocilia of the hair cell have different lengths and are arranged from shortest to tallest. At the tip of each stereocilium are mechanically-gated ion channels. These are mechanically-gated because they open and close in response to physical movement. The stereocilia are linked together with spring-like proteins called linker proteins. These linker proteins are specifically attached to small covers that block movement through mechanically-gated ion channels when closed.

The stereocilia can bend in two different directions, toward the shortest stereocilium or towards the tallest stereocilium. At rest (no sound), the stereocilia are not bent. Some of the mechanically-gated ion channels are open, and some are closed.
When the stereocilia bend towards the tallest stereocilium, the distance between the stereocilia increases and the spring-like linker proteins are stretched, causing the opening of the covers on the mechanically-gated ion channels.

Recall that the stereocilia are surrounded by endolymph, which is high in potassium and low in sodium. When the mechanically-gated ion channels are opened, potassium ions will flow into the hair cells, moving down its concentration gradient. As the positively charged potassium ions move into the hair cell, it causes the hair cell to depolarize.

If the stereocilia instead bend towards the shortest stereocilium, the distance between the stereocilia gets smaller. The mechanically-gated ion channels cannot open and the channels that were previously opened when the cell was at rest, will now be shut. As a result, there is less potassium influx into the hair cell and thus less positive charge in the hair cell than there was at rest, leading to hair cell hyperpolarization.
Located within the hair cell are vesicles that are filled with glutamate (an excitatory neurotransmitter). When hair cells are depolarized, this causes the opening of voltage-gated calcium channels in the hair cell membrane. The influx of calcium will ultimately cause the vesicles full of glutamate to fuse with the hair cell membrane and release the glutamate into the synapse with the spiral ganglion cell.
Most of the spiral ganglion cells (>95%) collect information from the inner hair cells. In fact, one inner hair cell will synapse onto many different spiral ganglion cells. Whereas a small number of spiral ganglion cell (<5%) collect information from the outer hair cells. Thus, the inner hair cells are responsible for sending the majority of auditory signals from the cochlea into the brain for processing.
Although the outer hair cells are not responsible for the majority of the signal to the spiral ganglion cells, they serve another function. The outer hair cells function as the cochlear amplifier to increase the intensity of vibrations within the cochlea. It is estimated that the outer hair cells increase sound by anywhere between 20 and 80 dB.

There is a motor protein called prestin within the outer hair cell membrane. As a motor protein, prestin can mechanically contract and elongate within the outer hair cells, changing the length of the outer hair cell. The membrane of the outer hair cell shortens and lengthens with the movement of the basilar membrane. When the basilar membrane is displaced upwards, this causes the prestin protein to contract, further shortening the length of the outer hair cell. When the basilar membrane is displaced downward, the prestin protein elongates the length of the outer hair cell. Essentially, the prestin within the outer hair cells amplifies the movement of the basilar membrane in both directions.

When the cochlear amplifier is functional, it doesn’t only change the displacement of the basilar membrane, but it also has effects on the inner hair cells. The cochlear amplifier will cause the inner hair cells to bend more than they would without the amplifier present. In this way, although the outer hair cells have fewer direct signals to the spiral ganglion cells, they still contribute to the firing of the auditory nerve through their influence on the inner hair cells.
Many people experience permanent hearing loss, a decrease in volume by 25 dB or more. Hearing loss is divided into two categories.

Conductive hearing loss is a result of changes to the auditory system up to the oval window, such as a tumor in the ear canal, a perforation of the tympanic membrane, or changes in middle ear pressure (such as how everything sounds muffled while changing altitudes when an airplane takes off, for example).

Sensorineural hearing loss results from changes at the level of the inner ear or further up in the neural pathway, such as hair cell damage, a brain tumor, bacterial or viral infections, or exposure to various toxins or drugs.

The most common cause of hearing loss is excessive noise exposure. Although the acoustic reflex is capable of dampening the intensity of the incoming vibrations, prolonged exposure to high amplitude sound waves can still cause damage. Motorcycles, the maximum volume on headphones, or loud venues like concerts and clubs can produce sounds in the 95-110 dB range, which can cause some permanent hearing loss. Additionally, the acoustic reflex is not fast enough to minimize damage from sudden, loud sounds in excess of 120 dB, such as a gunshot. All of these sources of acoustic trauma are preventable by wearing appropriate hearing protection, which can decrease the intensity of sounds by up to 30 dB. Old age is another common cause of hearing loss, likely because older people have had more accumulated exposure to noise.

An estimated 1 in 3 people older than 65 have hearing deficits. We are born with about 15,000 hair cells, but throughout the course of our life, many get damaged irreparably. Hair cells at the base of the cochlear are more sensitive to injury, so it is common for people to lose sensitivity to high-frequency sounds. The loss of these hair cells can begin as early as a person’s 20s. Partial hearing loss can be reversed with the help of medical devices. A hearing aid is a processor that helps to filter out background noise, decrease pitch, and amplify incoming sounds.

A cochlear implant is a surgically-implanted device that receives incoming sound information and directly stimulates the auditory nerve via electrodes, bypassing the external components of the auditory system.
All sensory systems follow the same general path of communication into our nervous systems and awareness. First, the incoming signal must reach a that can change its electrical properties in response to the stimulus. Then, that information initiates a series of signals into the CNS, reaching structures such as the thalamus, primary sensory cortical areas, and finally, higher order perception. Although there are several sensory components throughout our body that detect these signals, there are no sensory receptors in our central nervous system. We previously saw this pattern for the visual system, and now we’ll see it mirrored in many ways by the auditory system. For the auditory system, following the activation of hair cells within the cochlea, sound information is transmitted to brain structures including the thalamus and cortex for processing to be perceived as sounds.
Hair cells within the cochlea form glutamatergic synapses onto spiral ganglion cells. The axons of these neurons make up the vestibulocochlear nerve (Cranial nerve VIII). Neurons project to and synapse on neurons within the ipsilateral cochlear nuclei of the medulla. Because the medulla neurons only process sound from one ear, these cells are referred to as monaural. (one ear).

The cochlear nuclei neurons within the medulla have axons that split and synapse on both the ipsilateral and contralateral superior olive within the pons. The superior olive is the first structure that processes sound information from both ears, so it is referred to as binaural. All remaining structures in the central auditory pathway process sounds from both ears, and thus are also binaural.

From the pons, neurons travel via the lateral lemniscus (a lemniscus is a collection of axons) and then synapse on the inferior colliculus of the midbrain tectum. Signaling within the inferior colliculus is important for interactions between multiple sensory inputs and a motor response. These inferior colliculus neurons are particularly responsive to biologically-relevant sounds, such as unexpected noises, which may signal an approaching predator. Processing in the inferior colliculus helps the animal focus their attention on these stimuli.

The inferior colliculus then conveys that auditory information into the medial geniculate nucleus, one of the nuclei of the thalamus. These thalamic neurons then send projections into the primary auditory cortex located dorsally in the temporal lobe.
The structures responsible for the central processing of sound, including the basilar membrane, the spiral ganglion, the cochlear nucleus, the inferior colliculus, and the auditory cortex are tonotopically organized, meaning that adjacent physical areas are responsible for conveying information from adjacent frequencies. For example, the hair cells that respond most to 440 Hz vibrations are right next to cells that respond maximally to 441 Hz, but far away from cells that respond most to 14,000 Hz. Likewise, in the auditory cortex, the cells that best process 440 Hz are adjacent to those that best process 441 Hz, but far away from those that maximally respond to 14,000 Hz.
The auditory cortex (also called A1) is located within the temporal lobes in both hemispheres of the brain. Similar to the visual cortex, the auditory cortex is also made up of 6 layers of cells that have columnar organization. Each cortical column responds to a specific frequency. The auditory cortex is tonotopically organized like the other structures in the central auditory pathway. It is organized as isofrequency bands, like strips, that respond to relatively the same frequency.
Sound localization is an important function for animals. We can localize sounds in the horizontal plane and the vertical plane via different mechanisms.
When considering how we localize sounds in the horizontal plane, we assume that the sound does not change in elevation. As humans, our ears are located on the sides of our heads, which means that sounds will arrive at our ears at different times depending on the origin of the sound. The time between when sound reaches the first ear until the time it reaches the second ear is referred to as the interaural time difference (ITD).

If we assume that there are 20 cm between the two ears of a human, then we can determine the ITD for the left ear. If a sound is coming directly from the right, then there will be a 0.6 msec ITD for the left ear. If sounds are coming from directly in front of a person, then the time that it takes to reach the right ear will be exactly the same as the time that it takes to reach the left ear, thus there is no ITD (0 msec). If we consider an intermediary angle of sound origin coming from 45° we can determine that the ITD will be 0.3 msec, exactly between the values from when sounds originate directly in front and directly to the right.

In order for us to locate sounds in the horizontal plane, we need a brain structure that can process information from both ears. Recall from the central auditory pathway that the first structure that processes information from both ears (binaural) is the superior olive.
One of the primary functions of the superior olive is to help us figure out if a sound originates from the left or the right side of our head by determining this interaural time difference. Let’s imagine a sound wave originating from the left. The sound will interact with the left ear before it interacts with the right ear. When the sound interacts with the left ear, it will activate the hair cells in the left cochlea, the left spiral ganglion, and then the left cochlear nucleus (all monaural structures). The left cochlear nucleus cells will generate action potential that will travel along their axons toward the superior olive.

After a short delay, the sound wave will interact with the right ear, thus activating the hair cells of the right cochlea, the right spiral ganglion, and the right cochlear nucleus. The right cochlear nucleus will then generate its own action potential that will travel toward the superior olive. While this is occurring, the action potential generated by the left cochlear nucleus has traveled further along the left cochlear nucleus cell axon.

The action potentials generated from both the left and right cochlear nucleus will converge within the superior olive (a binaural structure). The axons of the cochlear nucleus cells have different length paths before they reach the neurons of the superior olive, allowing them to act as ‘delay lines’. The neurons of the superior olive act as coincidence detectors. When the action potentials arrive at one superior olive neuron at the same time, the postsynaptic potentials will summate, leading to maximal activation of this superior olive neuron and the generation of an action potential. If the action potentials do not arrive at the same time, then summation will not occur. The specific superior olive neuron that experiences the summation translates to where in the horizontal plane the sound originated, allowing us to localize sounds.

Humans are better at localizing sounds in the horizontal plane when we can detect the onset of the sound. However, when there are continuous tones, we need to utilize different ways to localize sounds in the horizontal plane. We can use interaural intensity (loudness) differences to localize sounds when they are continuous. Sounds are louder the closer you are to them. A difference in volume between what one ear and the other ear perceives can also be evaluated by neurons in the superior olive.

Interaural intensity differences are also useful in localizing high frequency sounds in the horizontal plane. At high frequencies (that have a wavelength shorter than the distance between our ears), the head creates a ‘sound shadow’ for the ear opposite the sound. When a high frequency sound is coming directly from the right side, the head creates a sound shadow for the left ear, making the sound louder for the right ear than it is for the left ear. Again, if a high frequency sound originates from directly in front of a person, then the sound will reach the ears with the same intensity, as the sound shadow will be behind the head. When a high frequency sound originates from an intermediate angle, then there will be intermediate intensity differences between the two ears.

Low frequency sounds do not create a sound shadow like high frequency sounds. This is because the wavelength of low frequency waves (e.g. 200 Hz) have a wavelength longer than the width of the distance between the ears, so the intensity will be the same at both ears but the sound will arrive at the two ears at different times (interaural time difference).

High frequency sounds (e.g. 7000 Hz) have a wavelength that is shorter than the width of the distance between the ears, which is why the head creates a sound shadow that will alter the intensity of the sound between the two ears.

Interaural time difference is used for low frequency sounds in the 20-2000 Hz range, whereas interaural intensity difference is used for high frequency sounds in the 2000-20,000 Hz range. Together these two processes are called the duplex theory of sound localization.
Because both ears (in humans and most non-humans) are at the same height, sounds in the vertical plane that change in elevation alone can be difficult to localize. This is because the interaural time difference and interaural intensity between the two ears remains constant as elevation changes. This is why sometimes people and animals tilt their heads to try to hear better.

The structure of our pinna is important in vertical localization. Recall that our pinna is the external portion of our ear that funnels sounds into the auditory canal. For sound localization, the pinna has many ridges and folds, which cause sound waves to be reflected off these bumps and take different paths on their way to the auditory canal. The pinna of humans is relatively fixed in location, but other animals (like dogs) have the ability to move their pinna to better localize sounds.

Interestingly, not all animals have ears that are located at the same height on their head. Some species of owls have ear openings at different heights on their heads, increasing their ability to localize the source of a sound on the vertical axis. By having ears at different heights, the owls are able to use interaural time differences in the vertical plane because the sound will reach their ears at different times.
When we tilt our head to the side, or look up and down, that movement information is conveyed to our brain using the vestibular system. The vestibular system is a sort of three-dimensional compass that can detect head movement, and that information helps us figure out how our head is oriented and how to balance ourselves in changing conditions. The vestibular system is made up of two structures that are intimately tied in with the anatomical features of the inner ear.

Adjacent to the cochlea within the inner ear is a structure called the vestibular labyrinth made up of the otolith organs (saccule and utricle) and the semicircular canals.
Next to the cochlea and within the vestibular labyrinth are two membranous sacs, the saccule and the utricle. Collectively, these structures are called the otolith organs and are responsible for determining gravity through the tilt of the head and linear acceleration. These structures are centrally located within the vestibular labyrinth.

Due to their differences in structure, the two otolith organs have slightly different functions. The saccule is more sensitive to vertical movements, like when you are standing in a moving elevator. The utricle is more responsive to horizontal movements, such as when driving.
Similar to the other inner ear structure, the cochlea, the structures of the vestibular labyrinth also contain hair cells. The hair cells located within the otolith organs are biologically similar to the hair cells in the cochlea. These hair cells have stereocilia that extend into a gelatinous cap that contains otoconia, which are small crystals of calcium carbonate. The otolith organs are important in sensing gravity. Tilting the head causes the otoconia to move (due to gravity), which will push the hair cell stereocilia and cause them to bend.
The tallest stereocilium (singular of stereocilia) is called the kinocilium. Similar to the function of hair cells within the cochlea, movement that bends the stereocilia toward the kinocilium results in depolarization due to potassium influx through open mechanically-gated ion channels within the tips of the stereocilia. Movement that bends the stereocilia away from the kinocilium causes the mechanically-gated ion channels to close, decreasing potassium influx and causing hyperpolarization.
The other major structure of the vestibular labyrinth are the semicircular canals. The semicircular canals are the structures that are responsible for detecting head rotation and angular acceleration.

Anatomically, the semicircular canals are a series of three arch-shaped membranous tubes within the vestibular labyrinth, each one oriented at a right angle to each other. Because of this shape, the semicircular canals sense and convey information about any direction of head movement.

These semicircular canals are filled with endolymph, the same potassium-rich solution that is in the cochlea that is important for auditory sensation. At the end of each of the three canals is a small swelling called the ampulla. Contained in the ampulla is a gelatinous membrane called the cupula. Here, hair cells extend stereocilia into the cupula. The tallest stereocilium is again referred to as the kinocilium.

When we rotate our head, the endolymph within the semicircular canals has a delay in movement due to inertia, and as a result the endolymph will move the cupula in the opposite direction of head movement. The physical movement of the cupula also pushes the cilia of the hair cells within the cupula. As previously discussed in the cochlea and the otolith organs, these hair cells also have mechanically-gated ion channels located in the tips of the stereocilia and function in the same way, with deflection towards the kinocilium resulting in depolarization and deflection away from the kinocilium resulting in hyperpolarization.

When we stop rotating, the endolymph within the semicircular canals continues to move for a brief period of time due to inertia (which contributes to our feeling of dizziness when we stop rotating).
The vestibular system is responsible for coordinating our balance through our head and body movements. As such, the neurons of the vestibular system signal to motor neurons that adjust head, eye, and body position.

The vestibular hair cell information is passed to the brain via excitatory synapses onto a branch of the vestibulocochlear nerve (CN VIII). The cell bodies of these neurons are in Scarpa’s ganglion. These axons send projections to several brain areas, notably the cerebellum, which is a structure critically important for balance. CN VIII also projects into the vestibular nuclei of the medulla. From there, neurons signal to areas of the thalamus that ultimately control motor areas of the face, extraocular motor neurons that ultimately control eye movement, and the spinal cord that is responsible for limb and neck motor movements to help maintain body and head position.
Your gustatory system, which mediates your sense of taste, helps you walk the line between health and illness. It acts as a short-range detection system, as you must actually put something in your mouth to taste it.

The gustatory system guides you towards foods that are energy rich and keeps you away from food that could make you sick. Humans can perceive five basic tastes: salty, sour, bitter, sweet, and umami. These specific taste modalities all support this balance. Sweet foods taste good because foods rich in sugar, such as fruit and wheat, contain large amounts of usable energy, and humans have evolved to find these foods appetizing. In contrast, toxic compounds are often bitter, causing you to respond with feelings of disgust. Salty taste indicates a substance with high salt content and sour taste indicates an acidic food, and umami taste indicates a high protein food.

Some of our taste is innate, like sweetness, whereas other tastes are learned like bitterness. This explains why many individuals do not initially like the taste of coffee, and why many individuals prefer to have their coffee with sugar when they first start drinking it. Our tastes can also be modified by our dietary needs, like craving a salty food.
Although taste receptor cells are most prevalent on the tongue, there are other regions of the mouth and throat, including the palate, pharynx, and epiglottis, that also are sensitive to food and play a role in taste perception.

Other sensory information is also tightly linked to our sense of taste. Smell is important in our sense of taste as odorant compounds from food can reach odor receptors in the nasal cavity. How a food looks (sense of vision) is also important to how it tastes. The texture and temperature of the food is also important (somatosensory information). Even a sense of pain, related to the spicy level of the food relates to our sense of taste.
The surface of the tongue is covered in small, visible bumps called papillae. Taste buds are located within the papillae, and each taste bud is made up of taste receptor cells, along with supporting cells and basal cells, which will eventually turn into taste receptors cells.

The taste cells have a lifespan of approximately two weeks, and the basal cells replace dying taste cells. The taste cells have microvilli that open into the taste pore where chemicals from the food can interact with receptors on the taste cells. Although taste cells are not technically neurons, they synapse and release neurotransmitters on afferent axons that send taste perception information to the brain.
The entire tongue is capable of perceiving all five tastes, meaning there are taste receptors for each taste present across the entire surface. However, some regions of the tongue have a slightly lower threshold to respond to some tastes over others. The tip of the tongue is the region most sensitive to sweet, salt, and umami tastes. The sides are most sensitive to sour, and the back of the tongue to bitter tastes.

Currently, it is believed that humans sense five basic tastes: Salty, sour, sweet, bitter, and umami. Salty and sour taste are both mediated by ionotropic taste receptors, while sweet, bitter, and umami taste are mediated by metabotropic taste receptors.
Salt taste is mediated by the presence of epithelial sodium channels. These receptors are usually open, and when foods are ingested with high salt concentrations, sodium flows into the cell causing a depolarization. This change in membrane potential opens voltage-gated sodium and calcium channels. The increased calcium influx causes the release of serotonin-filled vesicles. The serotonin acts on the afferent taste axon causing depolarization and action potentials.
Salty foods elicit a biphasic response depending on concentration. Foods cooked with a low concentration of salt taste bland and are not very appetizing; however, high salt concentrations elicit a strong aversive reaction – imagine how disgusted you were when you first tried to cook and were overly generous with the salt!

Additionally, the appeal of salt at a given moment depends on our body’s need for salt at the time. Several hormones such as the appetite-stimulating hormone ghrelin contribute to regulating the concentration of salt in the body by mediating Na+ absorption. Current salt levels can also impact appetite for salt. For example, in chronically-sodium deprived animals, high salt solutions are highly rewarding.

Why are we so sensitive to the taste of salt? As it turns out, both sodium and chloride are essential nutrients. They are critical for maintaining blood volume and pressure, for regulating body water, for maintaining muscle contractions, and mediating action potentials.
Foods taste sour because of their acidity, and when acids are present in water, they produce hydrogen ions (protons). Therefore, a sour food has high acidity and a high concentration of hydrogen ions, thus a low pH. The exact mechanism for sour taste transduction has yet to be worked out, but it is believed that protons enter the cell through an ion channel, and then block potassium channels. The decreased efflux of potassium, along with the presence of the protons, depolarizes the cell causing voltage-gated sodium and calcium channels to open. Like salt taste transduction, the increase in intracellular calcium causes release of serotonin into the synapse.
The purpose for our ability to sense acids in our food is under debate. Sour tastants do not inherently provide any nutritional value, except in the case of Vitamin C. Humans and other higher primates cannot synthesize Vitamin C on their own, so it’s possible that we evolved to find a combination of sourness and sweetness attractive enough to consistently consume Vitamin C-rich fruits. However, sour can be aversive, motivating us to avoid spoiled or unripe foods that might contain pathogens.
Bitter, sweet, and umami compounds all activate taste receptor cells via G-protein coupled receptors. The bitter receptors are from the T2R family of receptor proteins; humans have over 25. Each taste cell can express most or all of the different receptor types, allowing for the detection of numerous molecules, which is important when wanting to avoid dangerous substances like poisons and toxins.

Activation of the G-protein receptor activates phospholipase C, which in turn increases production of the second messenger inositol triphosphate. Inositol triphosphate causes the release of calcium from intracellular stores. Calcium causes the opening of ion channels, allowing the influx of sodium. These ion changes depolarize the cell and cause ATP-specific channels to open, allowing ATP to flow out of the cell and enter the synapse to act on the afferent taste axon by binding to purinergic receptors on the postsynaptic cell.
Sweet and umami receptors are comprised of G-protein coupled dimers, meaning two separate proteins function together as one. The receptors are encoded by the T1R family of receptor proteins. Sweet receptors are dimers of the T1R2 and T1R3 proteins. Both proteins need to be present and functioning for activation of a sweet taste cell. Like bitter cells, activation of the G-protein receptor uses a second messenger system to release calcium from intracellular stores and increase the influx of sodium. These ion changes depolarize the cell and cause ATP-specific channels to open, allowing ATP to enter the synapse and act on the afferent taste axon.
Sugars like glucose and sucrose are essential for the survival of a species, since they are the main source of cellular energy. Therefore, our ability to detect sweetness plays a central role in regulating how much energy we take into our bodies. Of all the taste modalities, sweet is the strongest driver of food selection.
Umami is the taste of savory deliciousness, such as the taste of rich chicken broth, a perfect medium-rare steak, or aged cheese. The word is derived from the Japanese word umai, which means “delicious.” Umami is signaled when a molecule of glutamate (chemically the same as the neurotransmitter) binds to T1R1/T1R3 receptors.

Umami receptors are comprised of the T1R3 protein, like the sweet receptor, but it is paired with the T1R1 protein. Once the G-protein coupled receptor is activated, the transduction pathway is the same as bitter and sweet taste cells.
Through evolution, we have come to prefer the taste of umami because glutamate is a byproduct of cooking food. Cooking foods changes their chemical properties, thereby improving digestion, reducing toxicity, and increasing absorption of nutrients. Glutamate is one of the byproducts in the process of heating a food, and so it benefits us to appreciate these flavors.
Of the five tastes, only two neurotransmitters are used to communicate information to the central nervous system, so how does our brain know what tastes to perceive? The answer is how the information is encoded. Most taste cells use a labeled line coding method, which means that each cell and the related afferent taste axon only responds to one type of taste. For example, bitter cells only express bitter receptors and are only activated by bitter molecules. These bitter taste cells activate bitter sensory neurons and bitter regions of the taste cortex.

A small portion of taste cells do use population coding as well, meaning more than one tastant can activate the cell, and perception is based on a combination of multiple cells each with a different response. Most information, however, is encoded via labeled line at the level of the taste cell.
The tongue is innervated by three cranial nerves. The front two-thirds of the tongue is innervated by cranial nerve VII (Facial nerve). The back third is innervated by cranial nerve IX (Glossopharyngeal nerve). Finally, the epiglottis and pharynx are innervated by cranial nerve X (Vagus nerve). All three cranial nerves enter the brainstem at the medulla and synapse in the nucleus of the solitary tract. From there, information is sent to the ventral posterior medial nucleus of the thalamus. Thalamic neurons send projections to the gustatory cortex. The gustatory cortex is located deep in the lateral fissure in a region called the insula. Information processing taste stays primarily on the ipsilateral side of the nervous system that is to say, taste information from the left half of the tongue gets represented in the left hemisphere of the brain, and visa versa.. Projections within the brain also exist between the taste regions and the hypothalamus and amygdala.
How do 5 basic tastes turn into the myriad complex taste sensations we experience when eating food? Olfaction plays an important role in the perception of flavor, as do vision and touch. Taste information combines with information from these other sensory systems in the orbitofrontal cortex located in the frontal lobe. This region is believed to be important for the pleasant and rewarding aspects of food. Additionally, as taste is processed in higher-order regions of the CNS, information is combined using population coding mechanisms. 
Olfaction is the ability to sense and perceive volatile chemicals that are suspended in the air. The typical human can distinguish up to 10,000 distinct odors, ranging from the sweet aroma of esters produced by apples and oranges, to the putrid smells of sulfurous compounds produced by skunks and rotten eggs. Because odors can drift along in the air, some chemicals can be detected long before the source is within eyesight: think about smelling a burning bonfire from miles away.

Smells affect our conscious behavior. They can motivate us to approach freshly-baked bread or avoid a rotting animal carcass. These chemicals serve as survival cues: bread gives us energy-rich carbohydrates while a decaying carcass can expose us to disease.

Smell is often used in communication between animals, especially  in reproductive behaviors, territory marking and identification of individuals. Olfaction is one of the oldest functions we possess as animals. While our sense of smell has seemed to take a backseat to other senses relative to other animals (about 2% of the total mouse brain mediates smell, while only a scant 0.01% of the volume of the human brain is dedicated to this function), scientists now appreciate that our olfactory system is simply more specialized. For example, humans use the smells of sweat to clue us into the emotional state of others, and we can even subconsciously detect sickness through body odor.
Your sensation of smell begins when odorant molecules travel through your nostrils and pass through the nasal cavity, an empty, air-filled space just behind the front of the skull.
The odorants dissolve in the mucus covered dorsal-most portion of the nasal cavity, an area called the olfactory epithelium. Embedded within the olfactory epithelium are olfactory receptor neurons, supporting cells, and basal cells.

The axons of the olfactory receptor neurons travel through a sheet of bone called the cribiform plate before going to the olfactory bulb. Collectively, the axons of the olfactory receptor neurons make up Cranial Nerve 1 (Olfactory Nerve).
Also found within the olfactory epithelium and surrounding the olfactory receptor neurons are supporting cells and basal cells. The supporting cells help dispose of dead and dying cells, metabolize pollutants, and may also help to physically maintain the epithelium by producing mucus. The basal cells function to replace the olfactory receptor neurons.
The olfactory receptor neurons begin processing smell. They serve as the sensory neurons for the olfactory system. Olfactory receptor neurons are bipolar neurons,  that have a single dendrite with many cilia that are exposed to the epithelial surface. The cilia stretch into the mucus of the olfactory epithelium and act to increase the surface area of the neurons, providing increased space for odorants to interact with the olfactory receptor neurons. When the odorants dissolve in the mucus they interact with odorant receptor proteins on the cilia of the olfactory receptor neuron.
Their proximity to the air make them the only neurons that are directly exposed to the outside world. Unfortunately, this causes them to encounter all sorts of dangers such as toxins, particulates, and microbes. They are one of the few known populations of neurons where adult neurogenesis regularly occurs, each having a lifespan in the range of 30 days to a year. The average human olfactory system has somewhere between 6-20 million olfactory receptor neurons.
Though taste uses different signaling systems for transduction of each of the different tastes, olfaction uses a single system for transduction. First, odorants bind to odorant receptor proteins (a G-protein- coupled receptor) on the cilia of the olfactory receptor neurons.
It is estimated there are about 1,000 different genes (about 3% of the total human genome) that code for roughly 400 different odorant receptor proteins. Each olfactory receptor neuron expresses only one type of odorant receptor protein. The initial research into the genetics underlying these neurons earned Drs. Linda Buck and Richard Axel a Nobel prize in 2004.

Odorant receptor proteins are transmembrane G protein-coupled receptors that have extracellular binding sites on their surface that bind to odorants. Each receptor differs in their specific binding pockets. Importantly, the receptor does not bind to one specific odorant, but rather binds to a specific molecular feature of the odorant. This means that many odorants can activate more than one odorant receptor protein, ultimately allowing each odorant to generate a unique pattern of activity across the olfactory receptor neurons.

Thus, analyzing the activity of a single olfactory receptor neuron is not sufficient to understand how that odorant alters neural signaling. Rather, the olfactory system uses population coding.
In this example we are looking at three different olfactory receptor neurons that express different types of odorant receptor proteins labeled Cell 1 (‘blue’ odorant receptor), Cell 2 (‘orange’ odorant receptor), and Cell 3 (‘purple’ odorant receptor). These neurons are exposed to four different odorants (vanilla, lavender, mint, and rose), and their neural activity is measured via an electrode.

When looking at the response to the ‘Vanilla” odor, cell 1 shows an increase in the rate of action potentials, cell 2 shows very little activity, and cell 3 shows an increase in action potentials. Whereas the ‘Lavender’ odor only causes a response in cell 2. The ‘Mint’ odor causes very little activity in cell 1, and increased activity in both cell 2 and cell 3. Lastly, the ‘Rose’ odor causes an increase in activity in cell 1 and cell 2, but very little activity in cell 3. These recordings demonstrate that a single odorant can cause changes in activity in more than one type of olfactory receptor neuron, due to the receptor proteins recognizing more than one type of molecular feature of the odorant molecules.
After the odorant binds to the odorant receptor protein, the receptor activates an associated G protein called Golf. This protein complex is 90% similar to the stimulatory G protein Gs , and likewise triggers activation of adenylyl cyclase, elevating the intracellular concentration of cyclic AMP. cAMP binds to cyclic nucleotide-gated cation channels that when opened, allow for the influx of calcium and sodium. The influx of calcium opens calcium-activated chloride channels. Olfactory receptor neurons have high intracellular chloride concentration, so the opening of the chloride channel results in chloride flowing out of the cell. Together, this causes the olfactory receptor neuron to depolarize, leading to membrane depolarization within the dendrite. This change in membrane potential is called a “receptor potential”. If depolarization crosses threshold potential within the olfactory receptor neuron cell body, then the olfactory receptor neuron will fire action potentials down its axons that make up the olfactory nerve toward the olfactory bulb.
Olfactory receptor neurons encode the intensity of smells through the frequency of action potential firing, which changes in accordance with the concentration of odorant molecules. Imagine standing over a fresh-baked pizza and inhaling deeply. Due to the high concentration of odorant molecules in the air, several receptors will be activated, leading to frequent neuronal firing. Now, imagine you are down the block from a pizza restaurant, getting only a slight whiff of those same scents. Here, the concentration of odorants is low, meaning that the Olfactory receptor neurons fire less frequently.
Because odorants are found in the air, they are highly mobile and can easily diffuse away, no longer having the ability to activate odorant receptor proteins. Olfactory signaling can also be terminated through the activity of enzymes located within the mucus of the olfactory epithelium.

Our perception of smells can also fade, even if the odorant is still present in the air. The odorant receptor neurons can adapt to the presence of an odorant, and thus no longer signal its presence.
The axons of the olfactory receptor neurons pass through the skull through a tiny series of holes at the cribriform plate. These primary neurons form synaptic connections onto neurons in the olfactory bulb called mitral cells, forming the beginning of the olfactory nerve (CN I). Like the optic nerve, the olfactory nerve runs along the ventral surface of the brain.
The site of synaptic connectivity between the olfactory receptor neurons and the secondary neurons in the olfactory bulb (mitral cells) is a highly specialized clump of tissue called a glomerulus. The typical human has a little under 2,000 glomeruli, and each glomerulus only receives inputs from olfactory receptor neurons that express the same type of odorant receptor proteins. This means that even through the olfactory receptor neurons that express the same type of odorant receptor protein are spread out throughout the olfactory epithelium, the axons of those neurons all converge within the same glomerulus.
Axons leave the olfactory bulb via the olfactory tracts and project to two different targets.

First, some cells project to the olfactory tubercle, are routed through the medial dorsal nucleus of the thalamus and then to the orbitofrontal cortex. This pathway is responsible for our conscious perception of smell.

Other cells project directly to the olfactory cortex and other related structures found within the temporal lobes, like the hippocampus. This makes the olfactory system the only sensory system that does not have to first pass signals through the thalamus before cortical processing. This pathway may play roles in discriminating odors, and the emotional, motivational, and memory-related aspects of smell.
Like other sensory systems, the structures involved in olfaction can be injured. An injury to the olfactory system can result in hyposmia, a reduced ability to smell, or anosmia, a complete loss of smell.

The most common insult to the olfactory system is simple nasal congestion, a temporary, physical blockage of the entry to the nasal cavity that decreases airflow and, therefore, the number of particles that reach the olfactory epithelium. Congestion can be caused by allergies, the common cold, upper respiratory bacterial or viral infections, or sinus infections.

Hyposmia is also one of the main neurological symptoms of COVID-19. Hyposmia is common among healthy, older adults, affecting about half of the population between 65 and 80 years old. As a person ages, spontaneous calcification causes the holes in the cribriform plate to shrink, which can impinge on and damage olfactory receptor neuron axons. Hyposmia can also be caused by abrupt head injuries. The olfactory receptor neuron axons that project through the holes of the cribriform plate are particularly sensitive to blows to the head. Neurodegenerative disorders, such as Parkinson’s disease and Alzheimer’s disease, contribute to smell deficiency. Usually, hyposmia precedes the major clinically observed symptoms of these disorders, hinting that smell deficiency may serve as an early diagnostic biomarker.

Another olfactory deficit, phantosmia, is when a person perceives “phantom” scents, or in other words, experiences an olfactory hallucination. Phantosmia may be triggered by a temporal lobe seizure or a stroke. It can also be caused by a brain tumor affecting the olfactory nerve (CN I), or the subsequent surgical removal of the tumor, leading to injury. Schizophrenia, a psychiatric condition characterized by auditory hallucinations, may also cause phantosmia.
All somatosensory receptor neurons have their cell bodies located in the dorsal root ganglion, a structure found just outside the dorsal aspect of the spinal cord. The receptor neurons, also called primary afferent fibers, of the somatosensory system are bipolar neurons, meaning they have one process from the cell body that splits into two branches. One travels to the location of the receptor (e.g. the skin for touch) via the spinal nerves, and one travels into the spinal cord at the dorsal horn via the dorsal root. The axon can either synapse in the spinal cord or ascend to the brain in the dorsal column.
Primary afferent axons are divided into four groups based on size and conduction speed. The groups, unfortunately, have different names depending on if the axons come from the skin (Aα, Aβ, Aδ, and C fibers; examples are touch or pain) or the muscles (Group I, II, III and IV fibers; example is proprioception). The fastest axons are the Aα or Group I type; they have the largest diameter and are heavily myelinated. The next fastest myelinated axons are the Aβ or Group II fibers, followed by the Aδ or Group III fibers. Finally, the C fibers have the smallest diameter, are unmyelinated, and are the slowest at conducting action potentials.
Different sensory information is sent via the different types of axons. Proprioceptive information from the skeletal muscles is sent to the spinal cord via Group I fibers. Touch information from the mechanoreceptors travels along Aβ fibers. Aδ fibers carry pain and temperature sensation, and C fibers convey information about pain, temperature, itch, and chemoreception.
The afferent axons from the dorsal root ganglion enter the spinal cord via the spinal nerves. Axons from nearby regions of the body enter the spinal cord together, and this forms regions of skin that are innervated by the same spinal nerve. These regions are called dermatomes. Damage to a spinal nerve will cause dysfunction along the innervated dermatome. The dermatomes and spinal nerves are divided into 4 groups. The seven cervical spinal segments are the most rostral and are located in the neck. The twelve thoracic spinal segments are located along the chest and abdomen. The five lumbar segments are located below the thoracic segments, and the five sacral segments are the most caudal.
Touch can come in many forms: pressure, vibration, stretch, motion, edges, points, etc. Receptors in the skin allow for perception of these different characteristics, and when this information is combined in the central nervous system, we are able to determine the location, strength, duration, movement, shape, and texture of the object interacting with the skin.

Cutaneous (meaning found in the skin) mechanoreceptors are responsible for sensing mechanical changes to the skin.

We can feel different modalities of touch because of the presence of specialized sensory receptors, called mechanoreceptors, located in the skin.

There are four different classes of cutaneous mechanoreceptors. These different mechanoreceptors have slightly different shapes and are therefore capable of detecting different types of stimuli.

Merkel’s discs are located at the border between the dermis and epidermis and are specialized to detect edges and points. They are very densely populated underneath our fingertips. These are the most precise mechanoreceptors with resolution at the level of 0.5 mm, which allow us to detect different distances in bumps while running your fingers across Braille.
Pacinian corpuscles are mechanoreceptors wrapped in several layers of connective tissue. The Pacinian corpuscles are located deep in the dermis of the skin and are responsible for perception of vibrations.
Meissner’s corpuscles are located in the epidermis layer and are highly concentrated at the fingertips. They are stimulated by skin motion/movement.
Ruffini endings are located in the dermis layer of the skin and respond to stretching of the skin.
The somatosensory afferents from the cutaneous mechanoreceptor have their cell bodies located in the dorsal root ganglion (DRG), a clump of somata that are close to the dorsal side of the spinal cord. These touch receptors are the primary neurons and are classified as pseudounipolar neurons based on their morphology. Pseudounipolar neurons don’t have true dendrites; instead each soma sends a single protrusion which branches into two directions. One branch goes towards the skin surface where it terminates as one of the mechanoreceptors. Typically, the terminal of this branch is surrounded by a connective tissue covering. The other branch off the soma travels towards the spinal cord.
On a molecular scale, these mechanoreceptors detect changes at the skin using mechanically-gated ion channels. In previous chapters we discussed ion channels that are gated by voltage changes and channels that are gated by neurotransmitters. In the somatosensory system, we find ion channels that are gated by physical distortion or stretch of the membrane. These transmembrane proteins are specialized for detecting the physical distortion of the channel and can open by stretch of the membrane itself or indirectly through movement of intra- or extracellular proteins that are linked to the channels. They are specialized for detecting the physical distortion of the channel, similar to the channels found in the stereocilia of the hair cells or vestibular cells.

When pressure is applied to these proteins, the cation channel opens and sodium and calcium flow down their electrochemical gradient into the neuron, causing both a depolarization and the initiation of second messenger cascades. This depolarization is referred to as a ‘receptor potential’. If enough stimulus is applied, the depolarization reaches threshold potential for the cell and an action potential is sent toward the spinal cord.
Each cutaneous mechanoreceptor is able to detect somatosensory information in an area of skin called the receptive field. When the receptive field is touched, the mechanoreceptor will be activated. The size of a receptive field can be determined by measuring the rate of action potentials from the nerve that collects somatosensory information from that patch of skin. The smaller the receptive field, the better the brain can distinguish between two different adjacent tactile stimuli.
Additionally, different classes of mechanoreceptors have different sizes of receptive fields: deeper structures, like Pacinian corpuscles, have larger receptive fields compared to receptors found closer to the skin surface that have smaller receptive fields.  Merkel cells and Meissner corpuscles, both of which are located near the skin surface, have small receptive fields and thus collect information from a restricted area of sensory space. Ruffini endings and Pacinian corpuscles, located deeper in the skin layers, have larger receptive fields than the Merkel cells and Meissner corpuscles and thus collect information over a large are of sensory space.
Receptive field sizes are different among the different mechanoreceptors, but they also vary among different body regions. Even within one receptor type (e.g. Meissner corpuscles), receptive fields in regions like the fingers or lips are smaller than in regions like the back or leg. This allows us to have finer spatial resolution with locating and identifying objects using our fingers. The smaller receptive fields in these regions are a result of a higher density of receptors in the skin.
Receptive field sizes are important because they allow us to locate a stimulus on our bodies. Larger receptive fields are not as precise as smaller receptive fields. One measure of receptive field size is two-point discrimination (try it at home!), which determines the minimum distance needed between two stimuli to perceive two separate points on the skin and not one. The hand has a smaller threshold for discerning between two points than does the back, a result of the different sized in receptive fields. In skin areas with a large receptive field, two adjacent stimuli may feel like one.
Skin areas with small receptive fields are better able to distinguish two similarly-spaced points. The hand has a smaller threshold for discerning between two points than does the back, a result of the different sized in receptive fields.

The two-point discrimination threshold for the fingers is very small, which indicates that they have high sensitivity. Body areas with high sensitivity typically have higher density of mechanoreceptors, have receptors that have smaller receptive fields, and have more brain tissue devoted to processing the sensory information that comes from those structures.

The two-point discrimination threshold for areas such as the leg or torso is very large, which indicates that these areas have low sensitivity. Body areas with low sensitive have a lower density of mechanoreceptors, have receptors that have larger receptive fields, and have less brain tissue devoted to sensory information that comes from those structures.
Another important characteristic of the somatic sensory receptors is that of adaptation rate. The class of mechanoreceptors can be divided into two categories based on their electrical properties in response to stimuli: slowly adapting and rapidly-adapting.

Slowly-adapting mechanoreceptors change their action potential firing rate as long as the stimulus is present, while rapidly-adapting mechanoreceptors only change activity at the moment there is a change in stimulus. For example, imagine the stimulus of a coin that is sitting in the palm of your hand. The slowly-adapting sensory neurons may increase their firing rate as long as the coin is in your palm. When the quarter is removed, they return to their baseline firing rate.  Slowly-adapting mechanoreceptors change their action potential firing rate as long as the stimulus is present and are most useful for determining the pressure and shape of a stimulus. Merkel cells and Ruffini endings are both slowly adapting fibers.
Rapidly-adapting mechanoreceptors only change activity at the moment there is a change in stimulus, but not when a stimulus is constant. This firing makes rapidly adapting fibers specialized for detecting movement and vibration.  Considering the coin example from above, a rapidly adapting sensory neuron will change its action potential firing properties only at two timepoints: the moment the coin lands in your hand, and the moment that coin is removed. These neurons signal a change in status.
The receptive fields of the sensory neurons become more complex as information moves up the pathway. We saw in the last lesson that mechanoreceptors have receptive fields that, when touched, activate the neuron. The mechanoreceptors synapse on neurons in the dorsal column, and those neurons have more complex receptive fields. The dorsal column nuclei have receptive fields that are divided into center and surround regions. The center of the receptive field is a result of direct innervation from the mechanoreceptors. If a stimulus touches the skin in the center of a dorsal column neuron’s receptive field, the neuron will increase its firing rate. The center / surround structure is like that of bipolar and ganglion cells in the vision system.
The surround region of the receptive field is a result of indirect communication between the receptor neurons and the dorsal column neurons via inhibitory interneurons. The surround has an inhibitory effect on the dorsal column neuron. If a stimulus touches the skin in the surround of a dorsal column neuron’s receptive field, the neuron will decrease its firing rate.
The center-surround structure of the receptive field is critical for lateral inhibition to occur. Lateral inhibition is the ability of the sensory systems to enhance the perception of edges of stimuli. At a point or an edge of a stimulus, because of the inhibitory interneurons, the perceived stimulus strength will be enhanced compared to the actual stimulus strength.
The pathway from the periphery to the somatosensory cortex consists of three neurons: a first-order sensory neuron, a second-order medulla neuron, and a third-order thalamic neuron.

Specifically, the primary afferent sensory fibers (sensory neurons) have their cell bodies located in the dorsal root ganglion, a structure that lies just outside of the spinal cord. The axons of these first-order neurons enter the ipsilateral dorsal side of the spinal cord. Some axon collaterals terminate in the spinal cord and are important for reflexes.

The main axon branch ascends the spinal cord toward the brain, via the dorsal column, synapsing in the dorsal column nuclei located in the medulla of the brainstem. The axons of sensory neurons in the lower body remain separate from the axons of sensory neurons in the upper body throughout the pathway. These two populations of neurons synapse in different regions of the medulla. The lower body axons synapse in the gracile nucleus, whereas the upper body axons synapse in cuneate nucleus. The second-order neurons within the medulla have axons that cross the midline, or decussate, and ascend via a white matter tract called the medial lemniscus.

The medulla axons synapse in the ventral posterior lateral nucleus of the thalamus. The third-order thalamic neurons then project to the primary somatosensory cortex located in the postcentral gyrus in the parietal lobe.
The pathway from the face and head to the somatosensory cortex also consists of three neurons. Sensory receptors in the face and head send information to the brain via cranial nerve V, the trigeminal nerve. The first-order neurons have their cell bodies in the trigeminal ganglion, located just outside of the brainstem, and they project to the ipsilateral trigeminal nucleus in the pons. The second-order neurons within the pons cross the midline and project up to the ventral posterior medial nucleus of the thalamus. These third-order thalamic neurons then send projections to the face region of the somatosensory cortex.
The primary somatosensory cortex is the postcentral gyrus located in the parietal lobe. It is divided into four regions, each with its own input and function: areas 3a, 3b, 1, and 2. The neurons within these regions are arranged in columns, similar to other areas of the cortex.

Most touch information from mechanoreceptors inputs to region 3b, whereas most proprioceptive information from the muscles inputs to region 3a. These regions then send and receive information from areas 1 and 2. As processing of somatosensory information continues, the stimuli required to activate neurons becomes more complex. For example, area 1 is involved in sensing texture, and area 2 is involved in sensing size and shape of an object. The posterior parietal cortex, an important output region of the somatosensory cortex, lies caudal to the postcentral gyrus; areas 5 and 7 are downstream structures that continue to process touch.
The receptive fields of each higher order neuron increases in size and complexity, but even cortical neurons are associated with a specific region of the body. The mapping of this organization was discovered during brain surgery. In epilepsy surgery, parts of the operation are performed as the person is awake. The famed neurosurgeon Wilder Penfield electrically stimulated a small section of the primary somatosensory cortex (S1), then asked the person what they felt. Patients would respond that they feel sensations in their hand when the medial S1 was activated, the little finger when a more ventral area was activated, and so on. In repeating this process while moving slowly across the span of S1, Penfield mapped out the organization of S1. He discovered that the sensory and motor cortices are organized by the region of the body they represent, so neurons that respond to sensation in the fingers are located close to the neurons that respond to sensation in the hand.

One key observation in doing this process was the volume of brain regions corresponding to different body parts was not necessarily proportional to the volume of skin: for example, a large portion of the cortex was dedicated to sensory information from the lips or the fingertips, while very little was dedicated to the shoulders or trunk. This observation indicates that certain areas of the body are more densely packed (lips, fingertips) with sensory neurons compared to others (shoulders, trunk). Regions with high receptor density in the skin, and, therefore, fine two-point discrimination, have more cortical space devoted to them. This means that the cortical representation of the body is not true to actual physical proportions.
A homunculus is a cartoon representation of what a body would look like if actual body size was proportional to the cortical representation. The hands and lips would be excessively large while the torso, arms, and legs, would be relatively small. Importantly, most homunculus representations are based on the mapping of male brains, but far less research has been done on the mapping of female brains.
The primary somatosensory cortex sends projections to other parietal lobe regions for higher-level processing of touch information.
The secondary somatosensory cortex (SII) is located in the inferior parietal lobe, just above the lateral fissure. This region, like the dorsal stream of visual processing, is responsible for object recognition, discerning texture, shape, and size. The SII also has receptive fields that represent bilateral regions of the body, so both hemispheres will be activated by touch on either side of the body. The SII sends projections to the posterior parietal cortex, the premotor cortex, the amygdala, and the hippocampus.
The posterior parietal cortex recognizes touch characteristics like orientation and movement. It is also important for combining the touch and motor components of actions like grasping. The posterior parietal cortex outputs to the frontal motor cortex.
In adulthood, the brain is plastic, meaning synaptic connections can rearrange under certain conditions. The somatosensory cortex has been studied with regard to its plasticity. Experience-based plasticity was initially proposed by Donald Hebb and is often referred to as Hebbian plasticity. This theory postulates that experience can enhance or reduce the activity of synapses to ultimately alter their function. When a presynaptic neuron repeatedly signals to a postsynaptic neuron, the synapse will undergo plasticity, changing structure to stabilize and strengthen the function of the synapse. Simplistically, the phrase “neurons that fire together, wire together” is often used to describe Hebbian plasticity. Plastic changes can include altering the amount of neurotransmitter release or altering the number of postsynaptic receptors.

Multiple principles of experience-dependent plasticity have been identified to build off Hebb’s original idea. We will focus on five of those principles below.

Use it or lose it. The idea behind this principle is that neural connections that are used consistently are maintained and strengthened. When a synapse is strengthened, it will produce stronger EPSPs that bring the cell membrane potential closer to threshold potential. If neural connections are not used consistently, then those synapses are removed, or lost.
Use it to improve it. The idea behind this principle is that connections that are consistently used continue to improve in function.
Repetition of stimulation. Synaptic strength can be enhanced by repeated stimulation.
Intensity of stimulation. The intensity of the stimulation will alter synaptic strength.
Regional and functional specificity. Experience-dependent plasticity is specific to the region and function that is receiving the experience. This is to say, providing specific experience to one region of the brain will enhance plasticity within that one region, and will not globally enhance plasticity across the entire brain.
Michael Merzenich is a researcher that has enlightened our understanding of cortical plasticity within the somatosensory system. He used microelectrodes to stimulate and record from the somatosensory cortex to create detailed cortical maps, similar to the homunculus that we discussed earlier. Dr. Merzenich completed a number of experiments that demonstrated principles of experience-dependent plasticity, some of which are highlighted below.

In one of his experiment, he demonstrated that amputation or loss of a finger, for example, will lead to the associated cortical space to be functionally remapped by input from neighboring regions of the hand. The cortical neurons do not die, they begin to be activated by a different region of the body.
An additional experiment showed that when two adjacent fingers were sewn together so that they moved as a unit, a new cortical map developed that was specific to the merged fingers. Thus, cortical maps can be removed or created anew.
Likewise, cortical representation can expand with use or practice. Repeated training of certain fingers can lead to an increase in cortical space mapped to those digits.
Pain is a complex experience that has somatosensory, psychological, and affective components. Nociception is a sensory process that provides signals that trigger pain when in the presence of a noxious stimulus. Detection and avoidance of pain is a highly-adaptive behavior that can improve the odds of survival chances of an animal. When we feel pain, we are more likely to protect the injured site to prevent further damage, making the sensation of pain beneficial to our overall well-being.
Pain detection is carried out by nociceptors that are located in the periphery at the surface of the skin. Nociceptors can detect a variety of noxious stimuli, ranging from crush (mechanical), acid (chemical), and high heat (thermal). They are expressed on free nerve endings that innervate the skin. Many pain-detecting neurons respond to more than one type of noxious stimulus and are called polymodal nociceptors.

These free nerve endings are found closest to the surface of the skin when compared to other mechanoreceptors. Similar to other somatosensory mechanoreceptors, the sensory end of the pseudounipolar neurons have their cell soma in the dorsal root ganglion. When a nociceptor is activated, it causes the opening of mechanically-gated ion channels that allow for cation influx, resulting in cell depolarization.

Once depolarization occurs in response to a painful stimulus, action potential propagation depends on the action of voltage-gated sodium and potassium channels. Lidocaine, a common local anesthetic, dulls pain by blocking these voltage-gated sodium channels, preventing signal transmission. A special type of sodium channel, Na1.7, is present only in nociceptor fibers. A mutation in this ion channel that prevents it from functioning can results in the inability to feel pain.

Activation of nociceptors usually occurs in response to tissue damage or the threat of damage. Depending on the type of stimulus, either Aδ fibers or C fibers are activated to transmit information to the CNS. Nociceptors are located throughout the body in skin, muscles, and viscera, but there are no nociceptors in the CNS.

The Aδ fibers have small receptive fields which allows for precise location of pain. They are lightly myelinated, smaller in diameter (~5 μM), and transmit signals slower than the Aβ fibers that transmit touch information, around ~25 m/s. There are 2 types of Aδ fibers. Type Aδ I fibers have a low threshold for mechanical stimulation and activate following intense pressure or an incision on the skin. Type Aδ II fibers have a low threshold for thermal stimulation and activate in extremely hot or extremely cold environments.

Type C fibers tend to be polymodal and are activated by a range of stimuli including mechanical, chemical, and thermal. They have larger receptive fields, which results in a lower ability to locate pain. The unmyelinated C fibers have an even smaller diameter (~1 μm) and slower conduction velocity (~1 m/s) than the Aδ fibers. The C fibers carry upwards of 70% of noxious signals within the body.
The Aδ and C fibers transmit information to the CNS at different speeds because of their different myelination levels. We can often perceive this difference in the form of “first pain” and “second pain”. Think about a time where you were injured, perhaps you hit your thumb with a hammer. Immediately, you might have felt an intense, sharp, and localized pain – first pain, but then a milder, burning or aching pain, that was more widespread that continue longer – second pain. The myelinated Aδ fibers are responsible for first pain transmission whereas the unmyelinated C fibers are responsible for second pain transmission.
Primary afferent pain fibers have their cell bodies located in the dorsal root ganglion, like the fibers of the mechanoreceptors responsible for touch. The axons of these first-order neurons enter the ipsilateral dorsal side of the spinal cord, and then they branch and travel up and down the spinal cord a couple of segments in a white matter region of the spinal cord just posterior to the dorsal horn called Lissauer’s tract. All the branches terminate in the dorsal horn.
The primary pain afferents coming from the periphery release glutamate as their neurotransmitter. These afferents can also release the neuropeptide Substance P following periods of high stimulation.
The nociceptor fibers (first-order sensory neurons) make synaptic contact with second-order neurons in the dorsal horn of the spinal cord. These neurons immediately cross the midline, or decussate, and then ascend to the brain through the anteriolateral aspect of the spinal cord and brainstem via the spinothalamic tract. The axons terminate in the ventral posterior lateral nucleus of the thalamus. The thalamic neurons (third-order neurons) then project to the primary somatosensory cortex located in the postcentral gyrus in the parietal lobe.

Like the touch pathway (Dorsal column medial lemniscus pathway), the pain pathway (spinothalamic pathway) is made up of three neurons that ultimately transmit the sensory information to the appropriate area of the cortex. The first order neuron is the sensory nociceptor neuron, the second order neuron is located within the spinal cord, and the third order neuron is located in the thalamus, that extends out to the primary somatosensory cortex.
Nociceptors in the face and head send info to the brain primarily through cranial nerve V, the trigeminal nerve. The first-order neurons have their cell bodies in the trigeminal ganglion, located just outside of the brainstem. The fibers enter the brainstem and descend to the spinal trigeminal nucleus in the medulla, where they synapse on a second-order neuron. The second-order neurons cross the midline and project up to the ventral posterior medial nucleus of the thalamus. These neurons then send projections to the face region of the somatosensory cortex.
In summary, the touch pathway (Dorsal column medial lemniscus pathway) and the pain pathway (spinothalamic pathway) are made up of three neurons that ultimately transmit the sensory information between the periphery and the appropriate area of the cortex.
Because the sensations of touch and pain decussate at different levels of the CNS as they ascend to the primary somatosensory cortex for processing, damage to only one half of the spinal cord will result in a condition referred to as dissociated sensory loss.

Ipsilateral to and below the damaged half of the spinal cord, individuals will have decreased touch sensation but normal pain sensation. Contralateral to and below the damaged half of the spinal cord, there will be normal touch sensation, but decreased pain sensation. Sensation above the damage will be unchanged.
One of the warning signs that a person is having a heart attack is perception of pain in the shoulders or medial aspect of the left arm. This sensation is called referred pain: the feeling of pain at a site separate from where an injury is located. Referred pain happens when the nervous system is unclear about how to process signals from an internal organ, and the brain interprets those afferent signals as bodily pain. Injury at different internal organs cause different patterns of somatic pain: liver injury may present as pain in the shoulder blades, lung cancer sometimes causes shoulder pain, and kidney stones can cause pain in the lower back, abdomen, and sides. Even the headache-like pain you get from a “brain freeze” from drinking cold liquids too quickly is a form of referred pain.

It is unclear what causes referred pain. The convergence projection theory suggests that the afferent projections from the internal organs and the nociceptive somatosensory neurons of the skin form synapses onto the same population of spinothalamic tract secondary neurons. When these secondary neurons project towards the brain, there is no ability to differentiate the origin of the signal coming from the primary neuron.

The central sensitization theory suggests that the neurons of the spinal cord change in their excitability threshold with prolonged exposure to injurious stimuli. So, when an injured internal organ repeatedly sends signals into the secondary neurons, a host of neurotransmitters cause sensitization of the nociceptive signaling, which are now activated under non-noxious conditions.
In healthy individuals, nociceptors that detect pain send those signals into the spinal cord. But in people experiencing allodynia, noninjurious tactile stimuli, such as strands of hair brushing across your forehead or the feeling of a shirt resting on your shoulders, cause the sensation of pain. Diabetes, physical trauma, or postherpetic neuralgia may cause allodynia. Drugs that modify the action potential firing properties of the afferent somatosensory pathway, such as topical anesthetics (voltage-gated sodium channel inhibitors) or calcium channel antagonists, can help relieve the pain. A related disorder is hyperalgesia, an abnormally heightened perception and increased persistence of pain. When you experience a cut on your finger, and the area surrounding the cut is reddened and painful, that is the area of hyperalgesia. Both allodynia and hyperalgesia can be the result of sensitization, where repeated firing of the neurons increase action potential firing of pain neurons. Sensitization within this system can lead to functional and structural changes wherein weak stimuli that previously did not cause pain will now result in pain perception. Sensitization can occur in first-order, second-order, or third-order neurons within the pain pathway.
Allodynia and hyperalgesia can be symptoms of neuropathic pain, a broad category of pain conditions resulting from damage to the nervous system. People experiencing pain even in the absence of pain-producing stimuli may be diagnosed with chronic pain. Chronic pain may be localized or widespread, affecting large areas of the body at once. Up to 10% of the global population may experience chronic pain, and a variety of risk factors contribute, from advanced age, being male, low socioeconomic status, unhealthy lifestyles, and a history of surgical intervention. Chronic pain can lead to significantly shorter lifespans and may contribute to the opioid misuse epidemic.

A philosophically-opposite condition is called congenital insensitivity to pain (CIP). People with CIP are incapable of perceiving pain, no matter how severe. CIP is a rare genetic condition that is observed from birth. People with CIP have significantly shorter lifespans since they do not sense that their bodies may be injured and may not learn to avoid exposure to damaging stimuli. Some patients may walk for days on a compound fracture of the shin bone, or never even notice that their back is broken. CIP is associated with mutations in the SCN9A gene, which codes for a component of the voltage-gated sodium channels that are expressed in nociceptors.
Individuals can have horrible injuries, yet not experience any pain in the moment. How can this occur?

One theory for how this is accomplished is ‘The Gate Control Theory of pain modulation’ which postulates that there are descending pathways that start in the brain and signal to the spinal cord that acts to inhibit, or “gate”, the pain signals from ascending to the brain and being perceived as pain. One brain area implicated in this pathway is the periaqueductal gray (PAG) matter within the midbrain. Neurons with their cell bodies within the PAG have axons that descend to the Raphe nuclei within the medulla. The raphe nuclei neurons then descend the spinal cord and release serotonin onto the second-order spinal pain neuron. The second-order pain neuron is therefore receiving synapses from both the first-order pain neuron that is transmitting the pain signal from the periphery and the raphe nuclei neuron carrying the descending signal from the CNS. The serotonin released by the raphe nuclei neuron acts to inhibit activity of the second-order pain neuron, thereby inhibiting the pain signal from ascending to the brain. In what situations do the PAG neurons ‘gate’ the pain signals from ascending to the brain and being perceived as pain? That answer is less clear, though we do understand that the gating of the pain signal eventually stops and the pain is able to be perceived.
The experience of pain can be altered through drugs that interact with the brain. An analgesic decreases pain without a loss of consciousness, whereas central anesthetics cause a loss of consciousness and completely eliminate all incoming sensory experiences, including pain and somatosensory information.

Opioids are drugs that are very effective at short-term pain relief. They are derived from the poppy plant and include opium, morphine, codeine, heroin, and analogues of those substances. Opioids bind strongly to several types of opioid receptors (all G-protein-coupled receptors) that are located throughout the brain, with especially high receptor density in areas such as the PAG, raphe nuclei, and in the spinal cord. Antagonists for opioid receptors block the effects of opioids and include drugs like naloxone and naltrexone.

The brain also makes its own endogenous opioids including endorphins, enkephalins, and dynorphins, that bind to these same receptors within the brain. Endogenous opioids are involved in various functions within the brain including nociception, respiration, cardiovascular, neuroendocrine, food intake, learning and memory, and many others. When opioids (either exogenous or endogenous) bind to their receptors, they modulate incoming pain information and provide temporary pain relief. Opioids are known to have effects on mood and can produce euphoric feelings. Unfortunately, they also have several side effects, most notably drug tolerance and dependence.
Individuals that have undergone amputation of a limb can experience ‘phantom limbs’, which give the sensory experience that the amputated limb is still present. In these cases, the sensory neurons can no longer provide sensory or pain information from the amputated limb, yet somatosensory and pain perception persists. Some individuals that experience phantom limbs can also experience phantom limb pain, where pain is experienced in a limb that has been removed.

Many physicians believed that phantom limbs were caused by irritation of nerve endings that remained in the limb stump after amputation. However, the research by the neuroscientist Dr. V.S. Ramachandran demonstrated that cortical plasticity played a major role in producing phantom limbs. Specifically, Dr. Ramachandran believed that cortical plasticity within the somatosensory cortex was responsible for the sensation of phantom limbs. He hypothesized that adjacent somatosensory maps within the cortex blurred together following amputation, causing the brain to rewire in the absence of incoming sensory information.

The following case study demonstrated this somatosensory reorganization following amputation. Dr. Ramachandran worked with an individual named Tom Sorenson that had lost an arm in a car accident. Tom was experiencing an itch on his phantom arm that he could not scratch. Due to the fact that the cortical maps for the face and the arm are adjacent to each other within the somatosensory cortex, Ramachandran methodically used a swab to stroke different areas of Tom’s face. Tom reported that in certain areas of his face, he could also feel the swab on his phantom limb. Functional brain scans confirmed that the maps for the face and the arm had blurred together.

Ramachandran believes that phantom limb pain stems from a “learned paralysis” that occurs when an individual sends out a motor command to move a phantom limb but receives no proprioceptive or visual confirmation that the phantom limb has moved. After this experience is repeated, the brain wires in such a way that it learns that the phantom limb does not move, leading to feelings of paralysis and pain associated with the phantom limb. To treat this “learned paralysis” in the phantom, Ramachandran developed mirror box therapy. In mirror box therapy, an amputee uses a mirror to produce a reflection of the intact limb opposite the amputated limb. By looking at this reflection, the individual experiences visual feedback that the amputated limb is intact and can now move. Looking at the movement of the “phantom” limb in the mirror, provides powerful input to the nervous system and acts to alleviate the feelings of paralysis and pain associated with the phantom limb, and effectively “unlearn” the paralysis and feelings of pain.
The motor system refers to the nerve cells that are used to control our body. The key roles of the motor system are to plan, control, and execute voluntary (deliberate) movements, and to control involuntary (subconscious or automatic) functions, such as digesting food. The motor system is sometimes described as a top-down process: in a voluntary movement, neural activity in the frontal lobe sends commands down to motor neurons located in the brainstem or spinal cord, which in turn activate muscle groups. In reality, motor control is more of a loop, rapidly communicating between the sensory cortex and motor cortex. Sensory information about limb position, posture, and objects in contact with the skin inform the descending motor plan. Simultaneously, the motor plan provides predictions about upcoming movement.

There are multiple levels of control. Within the spinal cord, simple reflexes can function without higher input from the brain. Slightly more complex spinal control occurs when central pattern generators function during repetitive movements like walking. The motor and premotor cortices in the brain are responsible for the planning and execution of voluntary movements. And finally, the basal ganglia and cerebellum modulate the responses of the neurons in the motor cortex to help with coordination, motor learning, and balance.

This lesson explores the lowest level of control at the level of the spinal cord.
Muscle fibers are innervated by alpha motor neurons. Alpha motor neurons are also called lower motor neurons because they are not located in higher brain areas. These cells are the only cells that directly command muscle contraction. The cell bodies of the alpha motor neurons are located in the central nervous system in the ventral horn of the spinal cord. Their axons leave the spinal cord via the ventral roots and travel to the muscle via efferent peripheral spinal nerves.
Like the sensory systems, the motor system is also organized in a topographic fashion, referred to as ‘somatotopic organization’. Within the spinal cord, alpha motor neurons that innervate muscles in the arms and legs are located in the lateral portion of the ventral horn, whereas alpha motor neurons that innervate muscles in the trunk are located in the medial portion.
The structure of the spinal cord is reviewed in Chapter 26. Examining cross sections of the spinal cord at different levels reveals that there is a non-uniform distribution of lower motor neurons. This is determined by the size of the ventral horn at the different levels of the spinal cord. At the cervical enlargement the larger ventral horns are due to the presence of more lower motor neurons that function in movement of the arms. At the lumbar enlargement the larger ventral horns are due to the presence of more lower motor neurons that function in movement of the legs.
The lower motor neurons communicate with muscle fibers (muscle cells) at the neuromuscular junction (NMJ). The NMJ is similar to other chemical synapses, however the postsynaptic cell is a muscle cell separated by about 30 nm. The presynaptic cell is the motor neuron and the postsynaptic site is the sarcolemma, the cell membrane of the long cylindrical muscle fibers (muscle cells). The neuromuscular junction is one of the largest synapses in the body and one of the most well-studied because of its peripheral location.

The neuromuscular junction is located midway down the length of the muscle fiber. The muscle fiber will contract in response to depolarization traveling down the sarcolemma of the muscle fiber. The synapse is located midway down the length of the muscle fiber so that the postsynaptic signal can travel in both directions down the long muscle fiber and quickly activate a contraction along the entire cell.

Acetylcholine is the neurotransmitter released at the neuromuscular junction (NMJ), and it acts upon ligand-gated, non-selective cation channels called nicotinic acetylcholine receptors that are present in postjunctional folds of the muscle fiber. Nicotinic acetylcholine receptors allow the influx of sodium ions into the muscle cell. The depolarization will cause nearby voltage-gated channels to open and fire an action potential in the muscle fiber. In a healthy system, an action potential in the motor neurons always causes an action potential in the muscle cell. The action potential leads to contraction of the muscle fiber.
To review, an action potential traveling down the motor neuron (presynaptic cell) will cause the release of acetylcholine into the synapse. Acetylcholine binds to postsynaptic nicotinic acetylcholine receptors that are located in the folded sarcolemma (increasing surface area), causing depolarization of muscle fibers and ultimately muscle contraction.

Acetylcholinesterase, an enzyme that breaks down acetylcholine and terminates its action, is present in the synaptic cleft of the neuromuscular junction. Muscle contraction must be tightly controlled. Thus, the actions of acetylcholinesterase are very important to cease muscle contraction quickly.

Myasthenia gravis (MG) is an autoimmune disorder characterized by muscle weakness, resulting in difficulty with speech, trouble with movement and swallowing, drooping eyelids, and double vision. Each year, an estimated 20 out of a million people get diagnosed with MG.

The muscle weakness seen in MG results from immune system-mediated destruction of the nicotinic acetylcholine receptors expressed at the NMJ. Thus, when the lower motor neuron releases acetylcholine, the muscle cells are unable to detect this release, so they fail to contract appropriately.

One therapeutic strategy involves inhibition of acetylcholinesterase, the enzyme that degrades acetylcholine. This causes the synaptic acetylcholine to remain in the synapse longer, increasing the chance that receptors get activated. Alternatively, autoimmune diseases like MG can be improved with immunosuppressant therapy. With successful treatment, MG usually does not result in changes in lifespan.
Importantly, there are many more muscles cells than there are motor neurons. One alpha motor neuron can innervate multiple fibers within one muscle due to the branching of motor neuron axons. Each axon terminal synapses (innervates) a single muscle fiber. A motor neuron and all the fibers innervated by it are called a motor unit. The muscle fibers within one motor unit are often spread throughout the muscle to spread the contraction throughout the full muscle. Further, motor units in a muscle usually contract asynchronously to help protect the muscle from fatigue. A graded contraction of the muscle is produced by activating varying numbers of motor units.

Motor units differ in size. Small motor units are motor units that innervate fewer muscle fibers and thus control fine movements. Small motor units are located in the eyes and fingers, both of which function in fine and precise movements. Large motor units innervate many muscle fibers and are typically found in weight-bearing muscles like the thighs.

The group of motor neurons that innervate all the fibers of one muscle is called a motor pool.
In addition to the size of the motor unit, the types of muscle fibers that are innervated by motor units can also differ. There are three different types of motor units:

Slow motor units. Slow motor units are slow to contract and generate less force but can work for a long time. They are used in endurance exercise like jogging.
Fast fatigue-resistant motor units. Fast fatigue-resistant motor units are quick to contract (though not as fast the fast fatigable motor units). These motor units generate more force that then slow motor units, but are much more resistant to fatigue than the fast fatigable motor units.
Fast fatigable motor units. Fast fatigable motor units are quickest to contract and generate the most force. These motor units are more prone to fatigue due to decreased number of mitochondria within the muscles. Fast fatigable motor units generate a lot of force quickly, but also tire quickly. They are used mostly in high intensity exercise like lifting weights and sprinting.

When an action potential is triggered in a muscle it causes a muscle twitch (contraction) that is followed by a period of relaxation. A muscle twitch shows an increase in tension after a short delay (latent period). During the contraction period, the muscle tension increased, and then has a long relaxation period, causing the muscle tension to be increased long after the initial stimulus.
When a stimulus occurs during the long relaxation period following a muscle twitch, the newly generated muscle twitch will summate to increase the strength of the overall muscle contraction. Shortening the time between stimuli will result in unfused tetanus and if stimuli are very close together will result in fused tetanus. Therefore, a higher rate of action potentials in the alpha motor neuron will generate more muscle contraction.
In addition to the rate of action potentials changing the force of the muscle contraction, muscle recruitment can also increase the strength of contraction within a muscle. When generating motor activity, the smallest motor units will be activated to contract first due to their size and increased excitability to move the load. Increasingly larger motor units are recruited to lift heavier loads. Recruitment of motor units allows for us to generate appropriate muscle tension to move a given load. For example, if you need to pick up a pencil, then we do not need to use the same force as if we were trying to pick up a 20-pound weight. Only smaller motor units would be activated to pick up the pencil, and increasingly larger motor units would be recruited to lift the heavier load of the 20-pound weight.
The alpha motor neurons that directly cause muscle contraction receive inputs from three different sources.

Sensory cells from the dorsal root ganglion that provide sensory information from the muscles through proprioception.
Upper motor neurons from the motor cortex in the brain and brain stem that are responsible for initiating voluntary movement.
Interneurons in the spinal cord. These represent the largest input to the alpha motor neurons and can either provide excitation or inhibition to the alpha motor neuron.
Raise your arms above your head. Even without seeing your arms, your nervous system has mechanisms that inform you about the location and position of your body parts, including how much your joints are bent. This sense is called proprioception and is critically important for coordinated movement and motor reflexes that contribute to those tiny, rapid adjustments that are made while maintaining balance. Proprioceptive information ascends through the spinal cord and into the brain via the dorsal column-medial lemniscus tract. Proprioception is also processed in the primary somatosensory cortex.

Proprioception refers to the “body sense” that informs us about how our bodies are positioned and moving in space. Proprioceptors are receptors that provide proprioception information.

There are two main types of proprioceptors:

Muscle spindles measure muscle stretch (muscle length) and transmit this sensory information via 1a sensory afferent fibers. Muscle spindles are nested within and arranged parallel to the extrafusal muscle fibers.
Golgi Tendon Organs measure muscle tension and transmit this sensory information via 1b sensory afferent fibers. Golgi tendon organs are located between the extrafusal muscle fibers and their points of attachment at the bone.
Muscle spindles are fibrous capsules that are located within muscles. Intrafusal muscle fibers are special muscle fibers that are located within the fibrous capsule of the muscle spindle. The intrafusal muscle fibers are innervated by gamma motor neurons that will cause them to contract.

Extrafusal muscle fibers, however, make up the bulk of the muscle and are located outside of the muscle spindle. The extrafusal muscle fibers are stimulated to contract by the alpha motor neurons.
Group 1a sensory afferent axons, which have a large diameter and are heavily myelinated, wrap around the intrafusal fibers contained within the muscle spindle. These sensory afferent fibers will signal when the intrafusal fibers of the muscle spindle are experiencing stretch and communicate information about muscle length.

Within the spinal cord, a single sensory 1a afferent axon synapses on every alpha motor neuron within the motor pool that innervates the muscle that contains the muscle spindle. This allows for a fast and powerful contraction of the muscle in response to a change in muscle stretch.
When the muscle experiences a stretch and the extrafusal fibers are stretched, the muscle spindle and the intrafusal fibers are also stretched (due to being within the muscle and surrounded by the extrafusal fibers). When the muscle spindle stretches, the 1a sensory axon will start to fire action potentials. The sensory axon synapses with an alpha motor neuron that will then cause the extrafusal muscle fibers to contract. As the extrafusal fibers contract and the muscle shortens, the muscle spindle goes slack, and the 1a axon will no longer fire action potentials as it is no longer being stretched. The gamma motor neuron is then activated that innervates the intrafusal muscle fibers, causing the intrafusal fibers to contract, allowing the muscle spindle to sense stretch again.  Therefore, the gamma motor neuron is critical for allowing the muscle spindle to continue providing information about muscle stretch even when the muscle has experienced contraction.
The Golgi tendon organ is a proprioceptor that measures muscle tension, or the force of contraction. They also contribute to our detection of weight, as we lift something heavy for example. Golgi tendon organs are located in the tendon that connects the muscle to bone. The tendon is made up of collagen fibrils and the Group 1b sensory axons are intertwined within the collagen fibrils. When the muscle experiences an increase in tension, the collagen fibrils surrounding the 1b sensory axon physically squeeze the 1b axon, opening mechanically-gated ion channels within the 1b sensory axon.
The purpose of the Golgi tendon organ is to allow for an optimal range of tension for the muscle and to protect the muscle from injury due to being overloaded. This is accomplished through a negative feedback loop controlled by the Golgi tendon organ. When the muscle experiences an increase in muscle tension, the 1b sensory axon starts to fire action potentials. The sensory neuron synapses onto an inhibitory interneuron within the spinal cord, which when active will release GABA onto the alpha motor neuron that innervates the same muscle that experienced the increase in muscle tension to begin with. When GABA binds to the alpha motor neuron, it will decrease firing of the alpha motor neuron, leading to a decrease in contraction of the muscle. This is an example of negative feedback as the increased muscle tension ultimately leads to physiological changes that decrease muscle tension.
Reflexes are involuntary motor responses that are performed automatically and independent of brain signals (although some can be suppressed voluntarily, with extra effort). Reflexes involve very simple circuits, sometimes consisting of only two populations of neurons: Sensory information comes in from the periphery, synapsing onto motor neurons in the brainstem or spinal cord. Reflexes can take place as quickly as 1/100th of a second!
When a muscle is stretched, this stretches the associated muscle spindle, which activates a 1a sensory afferent neuron that has its cell body located in the dorsal root ganglion. The sensory axon enters the dorsal side of the spinal cord where it makes two synapses:

A direct synapse onto a motor neuron in the spinal cord gray matter. The axon of the motor neuron exits the spinal cord and innervates the stretched muscle, causing it to contract.
A synapse onto an inhibitory interneuron that then synapses onto a separate motor neuron that innervates the antagonistic muscle.
The myotatic reflex, also called the patellar, or knee-jerk reflex, is an example of a stretch reflex and occurs in response to activation of the muscle spindle stretch receptors. This reflex is commonly tested at a doctor’s visit when the doctor taps your knee with a little hammer. This usually results in the lower leg kicking up slightly. The synaptic communication for this reflex takes place completely within the spinal cord and requires no input from the brain.

The knee is tapped on the tendon that connects to the quadriceps muscle. The tapping of the tendon stretches the tendon and as a result causes the quadriceps muscle to stretch, activating the stretch receptors. Sensory information travels to the dorsal horn of the spinal cord where it synapses on alpha motor neurons that innervate the quadriceps muscle. Activation of the motor neurons contracts the quadriceps, extending the lower leg. This is called a monosynaptic communication because there is only one synapse between the sensory input and the motor output. The reflexive kick is controlled at the level of the spinal cord and cannot be intentionally suppressed by descending motor pathways no matter how hard you concentrate.
The sensory neurons also synapse on interneurons within the spinal cord that are inhibitory (this means that these neurons make and release GABA). These inhibitory interneurons then synapse on alpha motor neurons that innervate the hamstring, the antagonistic flexor muscle to the quadriceps. When these motor neurons are inhibited, the hamstring muscle relaxes, allowing the contraction of the quadriceps to occur with more ease. This is called reciprocal inhibition.

A similar process can be seen in the withdrawal reflex. In this case, instead of an extension, the muscles lead to muscle flexion in response to a stimulus. If, for example, you step on something painful, the reflex will be to lift the injured foot. The sensory information that initiates this reflex is activation of pain receptors, or nociceptors. Like with the stretch reflex, the sensory information enters the spinal cord at the dorsal horn. Unlike the stretch reflex, the withdrawal reflex is a polysynaptic reflex, meaning interneurons are present between the sensory neurons and the motor neurons. Excitatory interneurons communicate with the alpha motor neurons of the flexor muscle, whereas inhibitory interneurons communicate with the alpha motor neurons of the extensor muscle. The behavioral response is flexing of the leg upward (the opposite action of the stretch reflex).

Running in parallel to the withdrawal reflex is the crossed-extensor reflex. If you step on something sharp and lift that leg, your other leg needs to be able to support your weight shift, or you would fall. This is accomplished by interneurons that cross the midline of the spinal cord and communicate with motor neurons on the contralateral side of the body. The painful sensory information that initiated the withdrawal reflex also initiates the crossed-extensor reflex. In addition to the ipsilateral interneurons active in the withdrawal reflex, the sensory axons also synapse on excitatory interneurons that cross the midline. These interneurons then synapse on excitatory interneurons that activate the alpha motor neurons of the extensor muscle and inhibitory interneurons that inhibit the alpha motor neurons of the flexor muscle (the opposite configuration to the withdrawal reflex). This leads to the leg extending, providing a stable base for the weight shift.

Central pattern generators (CPGs) are networks of cells that are capable of producing intrinsic motor responses even in the absence of sensory or brain inputs. These motor responses are usually well-rehearsed, repetitive, and happen at the unconscious level, meaning that certain behavioral outputs can be performed independently of signals upstream in the motor cortex.

CPGs have been observed in several organisms, ranging from insects, crayfish, birds, and mammals including humans, hinting that their evolution was highly adaptive for survival. Imagine how difficult it would be to survive if every breath required a conscious thought! The CPG is not a standalone driver of motor activity, however. The circuits receive signals from higher brain areas which can modify their characteristics. Imagine that you want to consciously hold your breath, or intentionally walk in some unusual or goofy way. In both cases, the descending signals from the brain are able to override the output motor command pattern that the CPG normally produces. Once you stop intentionally changing your motor behavior, the muscles return to their normal activity in response to CPG output.
Many earlier studies of spinal cord CPGs were conducted in different animal groups with unique locomotor patterns. Mollusks have crawling activity that is rhythmic, fish swim by sending alternative patterns of muscle activity through their body, and birds fly by rhythmic flapping of their wings.

In mammals, spinal CPGs were demonstrated in cats with a thoracic-level spinal cord transection. Following this surgery, the signals from the brain were unable to be communicated down to the hind legs, eliminating voluntary movement. They exhibited weakened muscular power, but were still able to stand for short times. If their front paws were put onto a stable platform while their hindlegs were put on a moving treadmill, the cat would involuntarily walk to keep up.

Humans also have CPGs for movement. One remarkable study looked at 37-year-old man who had injured his spinal cord in a football accident as a young man. His injury was at the level of C5, resulting in complete paralysis and a loss of sensation from the neck down. Over the following years, he gradually recovered a small amount of function. Fine manipulation skills and bladder bowel control never recovered, and he had not walked unassisted for ten years, experiencing tremendous weakness after taking a few steps. Just days after beginning a physical therapy regimen consisting of assisted upright walking, upon lying down, the man reported alternating muscle flexion and relaxation of the hips, knees, and ankles similar to the pattern of activity seen in locomotion. He was unable to voluntarily stop these motions, and could only get some rest by turning to the side. This muscle activity was smooth and rhythmic, as would be seen in a healthy person walking.
Some example motor responses driven by CPGs include diaphragm movement (respiration), alternating leg swinging and foot flexing (walking), and the progressive contraction of up to 25 pairs of muscles in the tongue and mouth (swallowing). Some CPGs are located in the brain stem (respiration) and others throughout the spinal cord (locomotion). Locomotion is one example of a basic, rhythmic movement that requires coordination of a number of muscle groups to work properly.
Activity of extensor and flexor muscles in both legs must be coordinated to allow smooth locomotion without falling. These rhythmical movements are controlled at the level of the spinal cord by circuits called central pattern generators. The spinal cord has circuitry that, in the case of walking, moves the legs in opposite patterns. When one leg is lifting up to move forward, the other leg is stable, touching the ground.
The control of this system has multiple levels. Neurons themselves may have pacemaker properties that allow for a continuous cycle of depolarization and repolarization. These neurons are then located within multi-cell circuits involving a collection of excitatory and inhibitory interneurons that results in reciprocal inhibition of contralateral muscles. Additional networks of spinal interneurons would cause reciprocal inhibition of ipsilateral antagonistic muscles.
Although the spinal cord is able to control these movements on its own, there is input from both the brainstem and sensory neurons which can have an effect on modulating the pattern of neuronal activity in the spinal cord. For example, when an animal needs to slow down, speed up, or turn away from a danger, for example, those inputs can alter the spinal cord circuit.

All voluntary (or non-reflexive) movements begin as signals in the brain. Specifically, the neurons involved in motor control are primarily found in the frontal lobe of the telencephalon, which includes areas such as primary motor cortex (or M1), premotor cortex, and supplemental motor areas. The posterior parietal cortex also contributes to movement. Through this section, we will walk through the brain processes leading to voluntary motor action.

There are a number of steps that must take place for voluntary movement to occur. Assessment of the surrounding environment and the body’s location in space, followed by determining what action is appropriate, and then initiating that action.

For example, after work, you sit down on the couch to watch one episode of your favorite show. As the end credits appear, you realize it is now time to head to your study space and start working on class. To do this, you need to leave the couch, grab your computer from the table, get your coffee from the kitchen and head to a different room. All of these voluntary movements take a great deal of processing by the brain. You must assess your surrounding environment and your body’s location in it, determine which actions need to be completed, and then actually initiate those actions. In this chapter we will focus on how the planning of voluntary movement occurs.

Cortical Anatomy
Much of the cortex is actually involved in the planning of voluntary movement. Sensory information, particularly the dorsal stream of the visual and somatosensory pathways, are processed in the posterior parietal lobe where visual, tactile, and proprioceptive information are integrated. The posterior parietal cortex is largely concerned with integrating somatosensory with visual information and determining an appropriate motor action. For example, if you were planning to get up from your seat to walk across the room, the posterior parietal cortex would take in the somatosensory proprioceptive information about how your body is positioned, and the visual information from the objects in the room to avoid running into them (recall the dorsal stream pathway).

With respect to motor control, the prefrontal cortex (PFC), located in the front of the brain in the frontal lobe initiates the long-term planning or cognitive aspects of movements. For example, consider the motor actions related to brushing your teeth. PFC signals are more akin to “brushing is good for my hygiene and health”, rather than “move my arm and open my mouth.” PFC also helps determine if some motor action is appropriate for the specific situation. Think of a behavioral test where you are given two clickers, one to hold in each hand. You are told that when the experimenter shows you a green item, you should click with the right button. After repeating this behavior multiple times, you are told to switch – now, when you see a green item, you need to click the left button. In this experiment, PFC is responsible for deciding which motor pattern (left button or right button press) is appropriate in response to the stimulus. PFC also works to weigh the consequences of motor actions and makes updates about future motor actions in similar or different circumstances. The exact same motor action produces different results depending on the specific situation, and PFC contributes to evaluating and predicting outcomes.

The premotor area lies just anterior to the primary motor cortex (M1) (M1 is just anterior to the central sulcus). The premotor area helps plan and organize movement and makes decisions about which actions should be used for a situation. The premotor area modulates motor output, and generally activates prior to motor activity.
The premotor regions do send some axons directly to lower motor neurons in the spinal cord using the same pathways as the motor cortex (see Execution of Movement chapter). However, the premotor cortex also plays an important role in the planning of movement. Two experimental designs have demonstrated this role. Monkeys were trained on a panel that had one set of lights in a row on top and one set of buttons that could also light up in a row on the bottom. The monkeys would watch for a top row light to turn on. This would indicate that within a few seconds, the button directly below would light up. When the button turned on, the monkeys were supposed to push the button.

Therefore, there were two light triggers in the experiment. The first required no motor movement from the monkey but did give the monkey information about where a motor movement would be needed in the near future. The second required the monkey to move to push the button. When brain activity was measured during this study, neurons in the premotor cortex became active when the first light trigger turned on, well before any movement actually took place (Weinrich and Wise, 1928).
In another experiment, people were trained to move their fingers in a specific pattern. Cerebral blood flow was then measured when they repeated the finger pattern and when they only imagined repeating the finger pattern. When the movement was only imagined and not actually executed, the premotor regions along with parts of the prefrontal cortex were activated (Roland, et al, 1980).
These studies show that the premotor cortex is active prior to the execution of movement, indicating that it plays an important role in the planning of movement. The posterior parietal, prefrontal, and premotor regions, though, also communicate with a subcortical region called the basal ganglia to fully construct the movement plan. The basal ganglia are covered in a future chapter.
There is debate about the existence of a special population of cells in the premotor area called mirror neurons. These are cells that are active during a movement, but also when that same movement is observed in another animal or person. Proponents argue that these neurons are involved in learning behaviors and for understanding the behaviors of others.

Once the plan for movement has been created, the primary motor cortex is responsible for the execution of that action. The primary motor cortex lies just anterior to the primary somatosensory cortex in the precentral gyrus located in the frontal lobe.

Primary motor cortex (M1) is a major motor control center, required for deliberate, voluntary movements, movements made in response to a “command.” Furthermore, motor cortex cells influence motor neurons, neurons located in the spinal cord that ultimately communicate with muscles or glands. This connection is so strong that the motor cortex cells are also called upper motor neurons. In this terminology, a lower motor neuron is found at the brain stem or spinal cord, and fires whenever the upper motor neuron sends a signal.
Like the somatosensory cortex, the motor cortex is organized by a somatotopic map. In the 1930s, neurosurgeon Wilder Penfield conducted several brain operations to treat patients with severe epilepsy. However, since the brain has no pain receptors, he was able to remove a portion of the skull under local anesthesia while the patients were awake and responding to his questions. During surgery, the goal was to electrically stimulate portions of the cortex to determine the origin of the seizures, and to ensure that areas critical to speech and hand movement were left untouched so that the patient would not have major impairments following surgery. This is currently done in neuro-oncology to reduce the loss of critical motor function and overall morbidity. Penfield progressively moved across different brain areas of M1 while using an electrode to stimulate patches of the cortex.

He had two major observations. First, stimulation caused contralateral activity: that is, stimulating the left side of the brain affects the muscle activity of the right side of the body. Secondly, by systematically moving across M1, he observed that different populations of neurons are responsible for communicating with specific muscle groups. For instance, dorsal M1 activates hip and trunk muscles, while more lateral M1 activates muscles of the face. Penfield discovered that within the motor cortex, different muscle groups are laid out in a rough topography, meaning that neurons that control the thumb are near other neurons that control the thumb, and near other populations of neurons that control the index finger. A graphical representation of this map is called the “motor homunculus,” in which body parts with larger representations in the brain are shown with larger size (much like the sensory homunculus).

Interestingly, the motor cortex does not map onto the body in such an exact way as does the somatosensory system. It is believed that upper motor neurons in the motor cortex control multiple lower motor neurons in the spinal cord that innervate multiple muscles. This results in activation of an upper motor neuron causing excitation or inhibition in different neurons at once, indicating that the primary motor cortex is responsible for movements and not simply activation of one muscle. Stimulation of motor neurons in monkeys can lead to complex motions like bringing the hand to the mouth or moving into a defensive position (Graziano et al, 2005).
The motor cortex controls movement by using population coding mechanisms. Upper motor neurons are broadly tuned to a certain movement in a certain direction, meaning firing rate is highest when moving in one direction, but firing also occurs when moving in nearby directions. For example, when a monkey is trained to move its hand toward the left, neurons “tuned” toward left movement will be active immediately before and during the movement. Neurons tuned to other directions will also be active but at lower rates (Georgopoulos, et al, 1982). This means that the firing rate of one specific neuron does not give enough information to know direction of movement. It is the combined firing rates of an entire population of neurons that indicates direction.

There are multiple descending tracts within the spinal cord that send information from the brain to the motor neurons in the ventral horn. The lateral tracts are responsible for carrying information about voluntary movement of the arms and legs. The ventromedial pathways are responsible for carrying information about posture and balance.

The largest of the lateral pathways is the corticospinal tract. This pathway sends information directly from the motor and premotor cortices down to the motor neurons in the spinal cord. Cortical axons travel through the brainstem and then cross the midline at the base of the medulla; like the somatosensory system, the right side of the cortex processes information for the left side of the body and vice versa. In the spinal cord, the axons travel through the lateral column and synapse in the ventral horn on motor neurons that typically innervate distal muscles.

The corticobulbar tract is another lateral tract and sends motor information to cranial nerves for motor control of the face. This path travels ipsilateral from the cortex into the brainstem where it branches off at the appropriate cranial nerve level in either the pons or the medulla and then innervates cranial nerve neurons bilaterally.

There are four ventromedial pathways that travel in the spinal cord as well. These tracts begin in the brainstem and descend through the ventromedial columns. They receive input from motor areas of the cortex as well as integrating information from multiple sensory regions. The ventromedial pathways control posture and locomotion.

The vestibulospinal tract is important for head balance as we move. This tract begins in the vestibular nucleus. The vestibular nucleus processes information from the vestibular apparatus (semicircular canals). The axons of the vestibular nucleus project down the cervical spinal cord to control neck and back muscles and guide head movements and also project to the lumbar spinal cord to maintain an upright posture.
The tectospinal tract is responsible for moving the head in response to visual stimuli. This tract begins in the superior colliculus (of the tectum). The axons of the superior colliculus decussate and project into the cervical regions of the spinal cord to control muscles of the neck, upper trunk, and shoulders.
The two reticulospinal tracts play a role in managing anti-gravity reflexes needed for posture and standing. These tracts begin in the reticular formation.
The basal ganglia are a group of subcortical nuclei, meaning groups of neurons that lie below the cerebral cortex. The basal ganglia is comprised of the striatum, which consists of the caudate nucleus and the putamen, the globus pallidus, the subthalamic nucleus, and the substantia nigra The basal ganglia are intimately involved with various aspects of movement, such as voluntary motor activity, habit learning, and the selection of actions.

For voluntary motor behavior, the basal ganglia are involved in the initiation or suppression of behavior and can regulate movement through modulating activity in the thalamus and cortex. Despite being major structures involved in motor functions, none of the components of the basal ganglia directly send projections down the spinal cord. Rather, they communicate mostly within themselves before signaling through the motor cortex. While the connections between basal ganglia structures have been largely mapped out, the specific functions of each individual structure in isolation is not entirely clear.

Diseases of the basal ganglia include movement disorders such as Parkinson’s disease, dystonia, Huntington’s disease, and Tourette’s, as well as complex psychiatric disorders including addiction and obsessive-compulsive disorder (OCD).
As we discuss the motor circuitry of the basal ganglia, it is important to understand that it is a loop. Activity from the cortex feeds into the basal ganglia, then through the thalamus, and then back to the cortex. The function of this loop of structures is to ultimately select and initiate willed movements.

The structures of the basal ganglia are briefly defined below.

Striatum: The striatum is made up of two components, the caudate nucleus and putamen. On a cellular level, the majority of neurons in the striatum are GABAergic cells.

Globus Pallidus: In dissection, the globus pallidus appears as a pale globe. It is subdivided into two components with functionally different connections. The globus pallidus internal segment (GPi) is located more medially and is movement promoting. On the other hand, the globus pallidus external segment (GPe) is located more laterally and is movement inhibiting. The output of the globus pallidus is only via inhibitory projections that are tonically active. This means that in the absence of any input, globus pallidus neurons will still inhibit their targets.

Subthalamic nucleus: The subthalamic nucleus is an output of the globus pallidus external segment. The output of the subthalamic nucleus are glutamatergic signals into the globus pallidus internal segment.

Substantia Nigra: The substantia nigra is a midbrain structure that appears darker in dissection due to heavy expression of neuromelanin across cells in these areas. It is the largest midbrain structure. The substantia nigra contains several dopamine expressing neurons that project into the striatum. Of clinical significance, these neurons experience selective neurodegeneration in Parkinson’s disease.
The dorsal striatum receives both glutamatergic and dopaminergic inputs. The majority of information processed by the basal ganglia enters through the striatum, with projections coming from both cortical and limbic structures such as thalamus and amygdala. This input into the striatum is glutamatergic and therefore, excitatory. The striatum also receives dopaminergic projections from another basal ganglia structure, the substantia nigra, a communication route called the nigrostriatal pathway.

Dopamine plays an important role in basal ganglia function. Parkinson’s disease results when dopamine neurons in the substantia nigra degenerate and no longer send appropriate inputs to the striatum. Dopamine projections can have either excitatory or inhibitory effects in the striatum, depending on the type of metabotropic dopamine receptor the striatal neuron expresses. Dopamine action at a neuron that expresses the D1 receptor is excitatory. Dopamine action at a neuron that expresses the D2 receptor is inhibitory.
The primary output region of the basal ganglia is the internal segment of the globus pallidus (GPi). This region sends inhibitory GABAergic projections to nuclei in the thalamus. This inhibitory output has a tonic, constant firing rate, which allows the basal ganglia output to both increase and decrease depending on the situation. The thalamus then projects back out to the cerebral cortex, primarily to motor areas.
There are multiple connections within the basal ganglia structures as well. For motor control, there are two main circuits: the direct pathway and the indirect pathway. These circuits have opposing actions when activated by cortical neurons. The circuits are also modulated by dopamine release by the substantia nigra into the striatum. It is believed that the different control mechanisms allow a finely tuned balance between the direct and indirect circuits, which allows for refined control of movement.

The direct pathway begins with excitatory input from the cortex to the striatum (caudate and putamen). The striatum then sends inhibitory projections to the internal segment of the globus pallidus (GPi). The GPi then sends inhibitory output to the thalamus. The direct pathway initiates and facilitates voluntary movement.
To make a movement, there needs to be activation of the direct pathway.

When input from either the cortex or substantia nigra increases in intensity, the direct pathway is activated. The neurons in the striatum involved in the direct pathway express the D1 metabotropic dopamine receptor, and the activation of this receptor is excitatory. Therefore, projections from both the cortex and the substantia nigra activate the neurons in the striatum. The striatal neurons are inhibitory and release GABA onto the internal segment of the globus pallidus (GPi). As described above, the neurons in the GPi are inhibitory, releasing GABA onto the thalamus. Activation of the striatum neurons causes the release of GABA onto neurons in the GPi, inhibiting the GPi neurons. Inhibiting the GPi neurons releases their typical inhibition on the thalamus. Inhibition of an inhibitory region is called disinhibition. Therefore, the activation of the direct pathway results in increased output from the thalamus because it is disinhibited. Increased thalamic activity leads to increased cortical activity, and increased movement.

When at rest (not moving), there is not an increase in either glutamatergic or dopaminergic input into the striatum. As a result, there is no change in striatal activity to modulate activity of the GPi. The GPi will continue to tonically inhibit the thalamus, keeping cortical activity low and decreasing movement.
The indirect pathway is a little more complex. Like the direct pathway, input into the basal ganglia arises from the cortex and substantia nigra, but there are more internal connections within the basal ganglia than what occurs in the direct pathway. Inhibitory neurons in the striatum involved in the indirect pathway project to the external segment of the globus pallidus (GPe). GABA-ergic neurons in the GPe project to the subthalamic nucleus, which then sends excitatory output to the GPi, which outputs to the thalamus.
The indirect pathway is activated by excitatory cortical input, activating the inhibitory striatal neurons. This leads to inhibition of the GPe neurons, resulting in disinhibition of the excitatory neurons in the subthalamic nucleus. The excitatory output from the subthalamic nucleus to the GPi increases inhibition of the thalamus, leading to decreased thalamic output to the cortex.
The indirect pathway can be inhibited by dopamine release from the substantia nigra. The neurons in the striatum involved in the indirect pathway express the D2 metabotropic dopamine receptor. The activation of this receptor is inhibitory. If the indirect pathway is inhibited by dopamine projections from the substantia nigra, the inhibitory striatal neurons are inhibited. This leads to disinhibiton of the GPe neurons, resulting in inhibition of the excitatory neurons in the subthalamic nucleus. This decreased excitatory output to the GPi decreases inhibition of the thalamus, leading to increased thalamic output to the cortex.
To put it all together, there is input to the striatum from two different locations: cortex (glutamate) and substantia nigra (dopamine).

Cortical activation of the direct pathway leads to increased thalamic output.
Cortical activation of the indirect pathway leads to decreased thalamic output.
Substantia nigra activation (via D1) of the direct pathway leads to increased thalamic output.
Substantia nigra inhibition (via D2) of the indirect pathway leads to increased thalamic output.
It is the combination of these pathways that allows for precise control of motor movement, balancing the excitatory direct pathway with the inhibitory indirect pathway.
There are multiple circuits that pass through the basal ganglia:

The motor circuit, which plays a role in voluntary movement.
The oculomotor circuit, which plays a role in eye movement.
The associative circuit, which plays a role in executive functions like behavioral inhibition (preventing impulsive behaviors) planning and problem solving, and mediating socially appropriate behaviors.
The limbic or emotional circuit, which plays a role in the processing of emotion and reward.
Although the circuits each use different circuits within the basal ganglia, the general loop is the same: cortical input to the striatum leads to internal processing within the basal ganglia structures. Basal ganglia output projects from the pallidum to the thalamus, which then projects back to the cortex. It is important to recognize that the basal ganglia plays an important role in a number of functions. For example, medications that are used to treat Parkinson’s can sometimes lead to the presentation of impulse control disorders, a result of dopaminergic changes in the limbic loop through the basal ganglia.
Neurodegenerative diseases cause neurons to lose either their function or structure over time, potentially leading to cell death in either the central or peripheral nervous system. These diseases can be devastating because there are no known ways to reverse the neurodegeneration. There are multiple diseases that are classified as neurodegenerative diseases and affect millions of people worldwide. We will focus on the two most prevalent neurodegenerative diseases: The motor disease Parkinson’s disease that affects the basal ganglia, and Alzheimer’s disease.
Parkinson’s disease is a neurodegenerative movement disorder that causes bradykinesia (slowness of movement), akinesia (difficulty initiating movement), a resting tremor, muscle rigidity, and changes to posture and locomotion. Although most symptoms are motor, there are mild cognitive and psychiatric changes, such as apathy, anhedonia, mood disturbances, or depression.
Advanced age is the primary risk factor, as an estimated 2% of people over the age of 60 develop Parkinson’s disease. It is also shows a sex difference with men being diagnosed more than women. Other environmental factors contribute to risk, such as repeated traumatic brain injury (suspected in Muhammad Ali) or occupational exposure to heavy metals, insecticides, or other neurotoxins. A small percentage of cases are early onset (21 – 50 years old; Michael J. Fox was diagnosed at 30), and have a strong genetic component. The disease causes significant decreases in life expectancy and quality of life.
A loss of dopaminergic neurons within the substantia nigra (a midbrain structure) contributes to basal ganglia circuitry disruption in Parkinson’s disease. This loss of substantia nigra cells can be visualized postmortem without the use of histology due to the natural black pigmentation of the substantia nigra cells.
When the substantia nigra cells die, they are no longer able to release dopamine at the striatum appropriately. When less dopamine is released into the striatum, the two populations of striatal neurons are affected differently dependent on the type of dopamine receptor that they express. Recall the basal ganglia circuitry from the previous chapter.
Within the direct pathway, striatal cells (within the caudate) express excitatory D1 receptors that project  directly to the globus pallidus internal segment. In the direct pathway, typically, dopamine binds to D1 receptors on striatal neurons, increasing caudate activity. These striatal neurons release GABA onto the globus pallidus internal segment (GPi) neurons, causing the GPi neurons to be less active. When the Gpi neurons are less active, they release less GABA onto the thalamic neurons, increasing thalamic neuron activity and the excitatory projections to the motor cortex, thus increasing movement.

In Parkinson’s disease, there is decreased release of dopamine onto the striatal caudate neurons that express D1 receptors, making them less active. Now that the striatal neurons are not as active, they release less GABA onto GPi neurons, disinhibiting them. The GPi is now more active, releasing more GABA onto thalamic neurons. In response, the thalamic neurons are less active and send less excitatory messages to the cortex, thus causing a decrease in movement overall.
In the indirect pathway, dopamine typically binds to inhibitory D2 receptors on striatal (putamen) neurons, inhibiting striatal neuron activity. These striatal neurons then release less GABA onto the globus pallidus external segment neurons (GPe), causing the GPe neurons to be more active. When the GPe neurons are more active, they release more GABA onto the subthalamic nucleus neurons, decreasing subthalamic neuron activity and the excitatory projections to the GPi.  Decreasing activation of the GPi causes the GPi to release less GABA onto the thalamus, which then causes more activation of the motor cortex,  thus increasing movement.

In Parkinson’s disease, there is decreased release of dopamine onto the striatal neurons that express D2 receptors, making them more active. Now that the striatal neurons are more active, they release more GABA onto GPe neurons. This inhibits the GPe neurons, causing them to release less GABA onto subthalamic nucleus neurons, disinhibiting the subthalamic nucleus. Increasing the excitatory inputs from the subthalamic nucleus onto the GPi will cause the GPi to release more GABA onto the thalamus. In response, the thalamic neurons are less active and send less excitatory messages to the cortex, thus causing a decrease in movement overall.
Parkinson’s disease is considered idiopathic because there is not a single known cause. Unfortunately, there are not measurable biomarkers (blood tests, brain scans) to diagnose Parkinson’s disease. Rather, diagnosis of individuals is typically done by a neurologist and a detailed exam. This can be further confirmed by giving medications that are used to treat Parkinson’s disease and determining if symptoms decrease.

A diagnosis of Parkinson’s disease is confirmed post-mortem through:

The loss of dopaminergic substantia nigra cells.
Presence of Lewy bodies.
Lewy bodies are intracellular alpha-nuclein protein aggregates that are believed to potentially displace healthy neurons and lead to the neurodegeneration observed in the disease.
Dopamine cannot be administered as a treatment to those with Parkinson’s disease to replace the loss of dopamine from the substantia nigra due to the inability of dopamine to cross the blood-brain-barrier. Instead, the major drug treatment for the motor symptoms of Parkinson’s disease has been administration of the drug levodopa (L-DOPA). L-DOPA is an intermediate in the synthesis of dopamine. Typically, it is converted into dopamine through the activity of DOPA decarboxylase. It is typically co-administered with other drugs to help prolong its effects. Unfortunately, there are many side effects of L-DOPA including nausea, joint stiffness, dyskinesias (involuntary movements and tics), and psychosis.

In a medical intervention called deep brain stimulation (DBS), a surgeon implants permanently indwelling electrodes directly into brain tissue. These electrodes are controlled by an external battery pack that delivers preprogrammed stimulation protocols. DBS in the STN is used to alleviate the symptoms of Parkinson’s disease.
As we age, the human brain is subject to degradation over our lifetime. This normal aging results in moderate cell loss and a gradual loss of myelination and synapses. These structural changes result in normal age-related functional losses (slower processing time or forgetting where you put your keys).
Alzheimer’s disease was first described In 1907 by Dr. Alois Alzheimer. He had described one of his patients, a 50-year old woman named Auguste Deter, whose symptoms included profound cognitive impairment, memory deficits, and delusions. After Deter’s death, post-mortem analysis of her brain revealed anomalies: degenerating neurons that contained atypical tangles and deposits scattered between cells.

Alzheimer’s disease (AD) is not a natural result of the aging process, but there is an increased risk of AD as we age. It is an irreversible, slowly progressing neurodegenerative condition that leads to deficits in thinking, behavior, and memory loss. AD is a devastating disease that accounts for 60-80% of all cases of dementia and is the sixth leading cause of death in the United States. As for prevalence, approximately 10% of people older than 65 and nearly a third older of people older than 85 has AD.
Specifically, declarative memory is the first form of memory loss observed in AD patients. As the disease progresses, procedural memory loss becomes more apparent. In addition to memory loss, AD symptoms include problems with language, disorientation, mood swings, loss of motivation, lack of self care, behavioral problems, loss of bodily functions, and dementia.

AD is divided into two categories, familial and sporadic. Familial AD is diagnosed when a person is in their 50s or 60s, and is strongly influenced by genetic risk factors. This form of AD only makes up about 10% of cases. Sporadic AD is by far more common than familial AD, and is believed to be caused by a combination of old age and environmental factors in addition to genetic risk factors. Several genetic risk factors are linked to AD risk. Apolipoprotein epsilon4 (ApoE4) is the greatest genetic risk factor identified, where individuals who are homozygous for the e4 polymorphism have a 12-times higher risk of developing AD than people with the more common e3 variant. Additionally, mutations in genes like amyloid-precursor protein (APP), presenilin-1 (PSEN1) presenilin-2 (PSEN2), and triggering receptors expressed on myeloid cells 2 (TREM2) are all associated with higher risk of developing AD.
In AD, brain atrophy is observed across the brain, especially in later progression of the disease, however two structures that see the most atrophy are the hippocampus and cortex. One of the main structures affected in Alzheimer’s disease is the hippocampus, which is located curled up inside the temporal lobes. The hippocampus is a critical structure in learning and memory, especially in spatial memory and in consolidation of short-term memory into long-term memory.

The prefrontal cortex is also heavily affected in AD. The prefrontal cortex is the most anterior portion of the frontal lobe and functions in intellect, cognition, recall, problem solving, planning, and personality.
Pathologically, AD is characterized by the extracellular accumulation of amyloidbeta plaques (Aβ) that build up in the space between neurons and intracellular hyperphosphorylated neurofibrillary tau tangles (NFT).
The amyloid cascade hypothesis, originally proposed in 1992, has become the leading theory in the field describing how AD develops. The hypothesis suggests that the main driving factor of AD is the deposition of Aβ in the brain, and this in turn leads to neurodegeneration via cell death, abnormal protein buildup, and neuroinflammation.

Aβ is produced from the cleavage of amyloid-precursor protein (APP), an integral membrane protein normally expressed by neurons that typically functions as a cell surface receptor and is important in neuronal adhesion, neurite growth, and axogenesis. In AD, the extracellular soluble portion of APP is cleaved by the enzyme beta-secretase and then the enzyme gamma secretase cleaves the APP anchor, leaving Aβ protein that is no longer held within the membrane. Aβ is likely to clump together in unpredictable ways within the extracellular space, leading to the formation of Aβ plaques (pronounced “A beta”). These plaques can cause neuronal death and lead to the cognitive deficits observed in AD patients.
Two major genetic risk factors for AD, presenilin 1 and 2, are mutations of the gamma secretase that leads to increased APP cleavage. Therapies are being developed to target and control the Aβ protein to mitigate AD symptoms. Recently an antibody-based drug has been approved by the FDA. This groundbreaking drug is unique from those traditionally prescribed because it directly targets Aβ. However, the amyloid-cascade hypothesis does not tell the whole story. For one, there are patients who carry a heavy Aβ load but present no clinical symptoms of AD. More so, in mouse models with APP mutations, they develop significant Aβ plaques, but have no accumulation of tau (see below) and no significant neurodegeneration. Additionally, there have been several drugs targeting Aβ that have failed in human trials.
While these amyloid plaques seem to be the primary driving factor of AD, hyperphosphorylated tau and neurofibrillary tangles (NFTs) are also potential culprits in disease progression. NFTs are an intracellular pathological marker of AD and correlate strongly with cognitive deficits in AD. Tau protein is the major microtubule-associate protein (MAP) of mature neurons and helps to function to maintain cellular morphology. Excess phosphorylation of this protein causes tau to accumulate inside the cell, leading to neuronal dysfunction and cell death. The presence of Aβ increases the levels of the tau, and vice versa, adding to the complexity and difficulty of treating AD. Tau pathology is also observed in other neurodegenerative diseases such as frontotemporal lobe dementia and Parkinson’s disease.
Although most discussion of AD revolves around plaques and tangles, it is well known that a cacophony of pathological markers are also seen in AD, including neuroinflammation, oxidative stress, blood-brain barrier dysfunction, heavy metal dysregulation, mitochondrial impairment, and many more.
An early hypothesis proposed to explain the neuronal loss and memory deficits observed in AD is centered around changes in the signaling of acetylcholine. Early post-mortem analyses discovered that people with AD have profound atrophy of the basal forebrain, an area which contains a large density of cholinergic neurons. Further, patients with Alzheimer’s disease also show decreased levels of choline acetyltransferase, reduced choline uptake in cells, and reduced release of acetylcholine. The cholinergic hypothesis suggests that it is this loss of cholinergic neurons and the loss of acetylcholine signaling that is the main pathological driver of AD. The theory is supported by the idea that acetylcholine plays an important role in learning and memory.
To this day, only post-mortem analysis can conclusively diagnose someone with AD. As expected, this raises many issues in terms of treating these patients. Currently, physicians diagnose a patient with AD based on the symptoms they presented with. However, new techniques to make more accurate diagnoses are emerging, including identifying the presence of biomarkers from blood samples, certain functional characteristics as observed in PET or fMRI imaging, and possibly even through eye exams.

Mild cognitive disorder/impairment represents a modest level of cognitive decline that interferes with the ability to complete everyday activities. Whereas major cognitive disorder/impairment is considered a major impairment and includes different dementias and Alzheimer’s disease.
Most of the FDA approved drugs for AD are acetylcholinesterase (AChE) inhibitors, drugs that act to increase levels of acetylcholine. The other approved FDA drug is an NMDA receptor antagonist. This drug is prescribed because it is hypothesized that AD may involve glutamate excitotoxicity, where excess binding of glutamate can increase intracellular  Ca2+ levels leading to Ca2+ poisoning and neuron death.

Unfortunately, these compounds show only short-term benefits for cognitive function, and these therapeutic effects subside over time. The different drugs are prescribed during different stages of AD, have modest effects and have unwanted side effects.
Motivated behaviors are voluntary behaviors that individuals find rewarding or pleasurable. Motivation varies in intensity which will correlate to the probability of performing the associated behavior. Certain behaviors or stimuli, like food or sex, are naturally rewarding because they are necessary for the survival of a species; they are adaptive, and the nervous system has evolved to make these behaviors pleasurable. Rewarding stimuli increases brain activation in brain regions that comprise the reward circuit.
Homeostasis is maintenance of the body’s internal environment within a physiological range. The hypothalamus is important in regulating many homeostatic processes by responding to sensory input when a deviation from homeostatic set point is detected.
The hypothalamus is located ventrally on the brain and surrounds the third ventricle. Sensory neurons within the hypothalamus measure changes in parameters that need to be regulated within the body, such as temperature, water balance, and feeding. When that parameter is sensed to be outside the normal physiological range, these hypothalamic neurons will initiate a three component process that will act to bring that parameter back within range (restore homeostasis): humoral response, visceromotor response, and somatic motor response.
In the humoral response, neurosecretory cells within the hypothalamus regulate release of pituitary hormones into circulation. The word ‘humoral’ comes from the word ‘humor’ which is an older word that refers to different fluids within the body. In the case of the humoral response, the bodily fluid is in reference to the blood where the hormones are being released.
The hypothalamus contains two types of neurons that secrete hormones into the pituitary: parvocellular neurosecretory cells and magnocellular neurosecretory cells. Magnocellular neurosecretory cells, the larger type of neurosecretory cell compared to parvocellular neurons, send axons from the hypothalamus down to the pituitary stalk where they terminate on capillaries of the general circulation located within the posterior pituitary. Therefore, the hormones that are released by the posterior pituitary gland are actually made within the hypothalamus. For this reason, the posterior pituitary is considered neural tissue, rather than endocrine tissue.
The magnocellular neurons synthesize and release oxytocin and vasopressin, two neuropeptides, into the blood. Oxytocin, often referred to as the love hormone, promotes social bonding. It is released during reproduction and also causes uterine contractions during labor and the milk letdown reflex after birth. Vasopressin, also called antidiuretic hormone, plays a role in regulating salt concentration in the blood by acting on the kidneys to promote water retention and decrease urine production. Vasopressin has also been shown to be involved in bonding, parenting, territoriality, and mate guarding in some animals.

Parvocellular cells are smaller than the magnocellular neurons (parvus means “small” in Latin). These neurons release hypophysiotropic hormones into a specialized capillary system that lies between the hypothalamus and the anterior pituitary gland called the hypophyseal portal circulation. The hypophysiotropic hormones cause anterior pituitary cells to make and release their own hormones. The anterior pituitary gland is therefore endocrine tissue because the cells make their own hormones. There are multiple hormones that are made and released by the anterior pituitary gland. They act on multiple target tissues throughout the body, including the gonads, thyroid glands, adrenal glands, and mammary glands.
The visceromotor response involves hypothalamic neurons that adjust sympathetic and parasympathetic activity to regulate internal organs.
The somatic motor response involves hypothalamic neurons that trigger an appropriate behavioral response.

Using a drop in temperature as an example, the humoral response will cause the release of hormones into circulation that will allow you to metabolize energy in a different way that will allow for more generation of heat. The visceromotor response would increase sympathetic nervous system activity to ensure that internal organs stay warm. Lastly, the somatic motor response would cause a behavioral change that would result in getting warmer (e.g. getting a coat, moving closer to the fire, or getting out of the cold outside).
We obtain energy from our diet and consumption of glucose, which serves as our energy source within the body. The body depends on access to glucose for normal function and survival. To ensure access to glucose when needed, our body stores glucose within the body in fat stores. We are motivated to eat and maintain these body fat stores.
Body fat stores are regulated after we eat a meal. When we consume more glucose than we can use, the excess glucose is stored within the body as fat stores. Over time, this repeated pattern leads to increased adiposity and can lead to obesity. If energy demands exceed the consumption of glucose, then glucose must be broken down from fat stores and fat is lost. Over time, this leads to decreased adiposity and starvation.
The body tries to defend fat stores and body weight around a particular set point. When rodents have restricted access to calories they experience a decrease in body weight, however when food is freely available again, they gain weight back to their weight prior to calorie restriction. Conversely, animals that are force fed to consume more calories than normal will gain weight, but will lose that gained weight when they are free to regulate their own feeding.

To maintain a balance of fat stores and expended energy, we regulate our feeding behavior. There are both short-term and long-term mechanisms that contribute to feeding regulation and maintenance of fat stores.
The level of fat within the body must somehow be communicated to the brain in a way that ultimately controls feeding behavior. The discovery of genetically obese mice by Dr. Douglas Coleman and colleagues helped determine the source of this signal. The DNA of the genetically obese mice found that these animals were missing both copies of the ob gene. These mice are referred to as ob / ob mice.
It was theorized that the ob gene must produce a hormone that typically signals that fat reserves are sufficient. Without this gene, and thus without this hormone, the obese mice were not receiving the appropriate signal to stop eating, causing them to over eat and increase fat stores. It was determined that the ob gene codes for the hormone leptin, which is secreted by fat cells. The ob mice had sufficient levels of fat, but did not have the hormone leptin released by the fat cells that would typically decrease feeding behavior. In fact, when ob mice are treated with leptin, they no longer over eat and restore a normal body weight.

More leptin is secreted when fat levels are high. Leptin acts to decrease appetite and increase energy expenditure, which will ultimately decrease levels of fat, and maintain normal fat stores levels in the body. Though it may seem that leptin administration would be an effective treatment for obesity, leptin treatment is only effective for individuals with an identified leptin deficiency. Those without a leptin deficiency have increased levels of leptin due to increased fat stores, but ultimately have neurons with decreased sensitivity to leptin levels.
Two areas of the hypothalamus have been historically described with regard to their role in feeding behavior through lesion studies. If the lateral hypothalamus is bilaterally lesioned, it results in lateral hypothalamic syndrome and anorexia, whereas bilateral lesions of the ventromedial hypothalamus results in ventromedial hypothalamic syndrome and overeating/obesity. Though it follows that the lateral hypothalamus causes feeding behavior to increase and the ventromedial hypothalamus causes feeding behavior to decrease, leptin signaling within these structures underlies these behavioral changes.
The neurons within the arcuate nucleus of the hypothalamus have receptors that detect levels of circulating leptin. The arcuate nucleus neurons produce peptide neurotransmitters called αMSH (alpha-melanocyte-stimulating hormone) and CART (cocaine- and amphetamine-regulated transcript). Note, that the names of peptides are typically derived from the first identified function of the peptide, but that additional functions are later discovered, which can lead to the names of the peptides being somewhat confusing.
Changes in leptin levels will lead to the humoral, visceromotor, and somatic motor hypothalamic responses.

When fat levels are increased, leptin levels are also increased. In the humoral hypothalamic response, leptin binds to neurons in the arcuate nucleus. This population of arcuate neurons project to the paraventricular nucleus (PVN) and release αMSH and CART onto the PVN neurons. In response to the binding of αMSH and CART, the PVN neurons cause the release of the hypophysiotropic hormones. The anterior pituitary gland will then release thyroid stimulating hormone (TSH) and adrenocorticotropic hormone (ACTH), which will both act to raise the metabolic rate within the body.
When leptin levels are high, leptin will also bind to a separate population of arcuate neurons that project to the brainstem and control the hypothalamic visceromotor response. These arcuate neurons release αMSH and CART onto brainstem neurons that will act to increase sympathetic nervous system activity, raising the metabolic rate and increasing body temperature.
Lastly, when leptin levels are high, leptin binds to a third population of arcuate neurons that project to the lateral hypothalamus and control the hypothalamic somatic motor response. These arcuate neurons release αMSH and CART onto lateral hypothalamus neurons. αMSH and CART inhibit the lateral hypothalamus, inhibiting feeding behavior.
Overall, the increase in metabolic rate, increase in body temperature, and decreased feeding will all ultimately lead to a decrease in body fat and thus a decrease in leptin levels, bringing fat and leptin levels back within the physiological setpoint range. αMSH, CART, and Leptin are all examples of anorexigenic, or satiety, signals. Collectively, anorexigenic signals decrease feeding behavior and decrease body weight in response to increased adiposity.
When fat levels are decreased, leptin levels are also decreased. When leptin levels drop, an entirely different set of neurons within the arcuate nucleus are activated that release the neuropeptides neuropeptide Y (NPY) and agouti-related peptide (AgRP).
In the humoral hypothalamic response, the drop in leptin activates neurons in the arcuate nucleus. This population of arcuate neurons project to the paraventricular nucleus (PVN) and release NPY and AgRP onto the PVN neurons. These neuropeptides inhibit the PVN, thereby inhibiting release of the hypophysiotropic hormones, and ultimately inhibiting release of TSH and ACTH. As a result, metabolic activity in the body is decreased.
When leptin levels are low, arcuate neurons are activated that project to the brainstem and control the hypothalamic visceromotor response. These arcuate neurons release NPY and AgRP onto brainstem neurons that will act to increase parasympathetic nervous system activity, decreasing the metabolic rate and decreasing body temperature.
Lastly, when leptin levels are low, the drop in leptin activates a population of arcuate neurons that project to the lateral hypothalamus and control the hypothalamic somatic motor response. These arcuate neurons release NPY and AgRP onto lateral hypothalamus neurons. NPY and AgRP stimulate the lateral hypothalamus, stimulating feeding behavior.
Overall, the decrease in metabolic rate, decrease in body temperature, and increased feeding brought about by the three hypothalamic responses will all ultimately lead to an increase in body fat and thus an increase in leptin levels, bringing fat and leptin levels back within the physiological setpoint range.

NPY and AgRP are examples of orexigenic signals. Orexigenic signals increase feeding behavior and increase body weight in response to changes in adiposity. AgRP and αMSH are considered antagonistic neurotransmitters because they both bind to the MC4 receptor on hypothalamic neurons, but exert opposite effects on feeding behavior.
Having a sense of reward is a valuable adaptive trait. Consider two similar organisms living in the distant geologic past, both involved in Darwin’s struggle to pass their genetic material to the following generation. One of these creatures gets an internal rewarding sensation whenever it drinks water while thirsty, eats high-caloric-content food, or successfully reproduces. As can be expected, this organism is highly motivated to seek out those rewarding stimuli in the world. It is are more likely to crave sugary foods to maximize daily caloric intake necessary for activity and growth. The other creature does not experience pleasure from its actions, resulting in little motivation to seek out calories or to reproduce, for example. It stands to reason that the first of these two creatures has an evolutionary advantage to survive. As can be expected, the regions of the brain that are concerned with reward are highly conserved through evolution.
For us humans, our reward signaling neural circuitry starts with the ventral tegmental area (VTA). Located in the midbrain, the VTA contains neurons that synthesize the neurotransmitter dopamine (DA). This population of DA cells is similar to the cells in the substantia nigra, the midbrain neurons that are lost in Parkinson’s disease.
There are two primary pathways from the VTA that are important for reward.

The mesolimbic pathway consists of dopamine-producing neurons that release dopamine onto the cells in the nucleus accumbens (NAc; also sometimes called the ventral striatum). This seems to be the major pathway by which reward is mediated by the brain. Using microdialysis, it is possible to measure the dopamine concentration in the NAc during performance of some behavioral tasks. In studies with rats, engaging in rewarding activities such as eating or sex results in increased release of dopamine in the NAc. Similarly we see that release of dopamine into the human NAc is enhanced when we engage in activities we enjoy: binge eating sugary stuff, having sex, even playing video games. Notably, many drugs of abuse such as cocaine or amphetamine can induce a similar overflow of dopamine release when an animal is exposed to the drug.

The second area that receives VTA innervation is the prefrontal cortex (PFC), and this projection is called the mesocortical pathway. We think of the PFC as being involved in the conscious, decision making and inhibition of action.
One of the earliest experiments demonstrating functional evidence of a “reward circuit” was conducted at McGill University in the early 1950’s. Drs. James Olds and Peter Milner carried out surgery on anesthetized rats to implant metal electrodes into different areas of the brain. After recovery, the rats were placed into an operant conditioning chamber, also called a Skinner box. These special cages are equipped with a device which the subject can physically manipulate. For example, the cage may have a lever which the animal can push, or a hole into which they can poke their nose.

In the case of Olds and Milner’s experiments, a lever press led to activation of the implanted electrodes, resulting in neuronal activation. They had found that when the electrode was implanted into brain areas such as the corpus callosum or the hippocampus, the rats did not spend significant time pressing on the lever. However, the rats which had the electrodes implanted in the medial forebrain bundle that is located in the VTA to NAc pathway, responded frequently on the lever. One such rat pressed the lever almost 2000 times in less than an hour, averaging nearly one response every two seconds! Electrical activation of reward centers is so desirable, rats will choose electrical stimulation over food even to the point of starvation. This experimental paradigm is also called intracranial-self stimulation (ICSS). Treatment with drugs that block the receptors for dopamine reduce the self-stimulating behavior, indicating that dopamine is the critical neurotransmitter involved in making the stimulation of these brain regions rewarding.
And while the original studies were conducted on rats, clinicians soon after tested their model in humans, with similar indwelling electrodes in different brain regions. Unsurprisingly, humans also have areas of the brain that are responsible for encoding reward, and when given the chance to electrically activate those areas, they do so extensively. When the experimenters brought in a tray of delicious food to the test chamber, the hungry patients—who hadn’t eaten for upwards of seven hours—simply looked at the meal, but couldn’t pull themselves away from the stimulation button long enough to eat. Artificial stimulation of these reward centers of the brain was more valuable to the patients than nutrition.

However, continued research suggests the connection between dopamine release and reward may not be as simple as the self-stimulation studies imply. It appears that it is not the reward itself that increases dopamine, but the predicted expectation of the reward . Dopamine signaling increases during anticipation of a predicted reward. If the level of reward is more than predicted, reward learning occurs, and dopamine signaling and motivation to repeat that behavior increases. If the level of reward is less than predicted, then dopamine signaling decreases as does motivation to repeat the behavior.
Natural rewards that increase survival and fitness of a species activate the reward circuit. These behaviors and stimuli include certain food (like those containing high sugar or fat levels), social bonding, parental bonding, and sex. Most drugs of abuse also activate the reward circuit and dopamine signaling, which plays a critical role in the formation of addiction. For example, cocaine blocks dopamine reuptake into presynaptic VTA terminals; heroin and nicotine increase dopamine release from the VTA. These alterations increase dopamine effect on neurons in the nucleus accumbens.
Here we will examine an additional rewarding behavior. Rodents, such as rats, are used as a model for studying sexual behavior and reward.
When in the presence of a sexually receptive female rat, a male rat will engage in male sexual behavior, called mounting behavior. Mounting behavior is controlled by the medial preoptic area (mPOA) of the hypothalamus in males.

Female rats display their own sexual behavior called lordosis. Lordosis behavior is displayed as an arched-back posture that is controlled by the ventromedial hypothalamus (VMH). Female rats also have the ability to pace their sexual interactions by controlling the timing of the sexual interaction. The female rat will run around the cage and choose when they will stop and allow the male to engage in mounting behavior.

Steroid hormones such as testosterone, estrogen, and progesterone regulate activity of the mPOA and VMH.
When considering sexual behavior as a model for motivated behaviors, it is important that we understand why an animal engages in sexual behavior.

A modified operant chamber was constructed by Everitt and colleagues (1990) that helped to answer this question. A male rat was trained to press a lever within the chamber that when pressed would open a door and allow for access to a sexually-receptive female rat, with whom the male could engage in a sexual bout. Males easily learned this paradigm and consistently pressed the lever to gain access to the female (Everitt, 1990).

When the mPOA was lesioned in the male rats and they were tested in this same operant chamber, the male rats still pressed the lever to gain access to the female rat, even though they no longer had the ability to perform sexual mounting behavior. However, when the nucleus accumbens was lesioned and the mPOA remained intact, the male rats no longer pressed the lever. They had lost the motivation associated with the prospect of sexual experience, thus demonstrating that the nucleus accumbens, and the reward pathway drive the motivation for sexual behavior in rodents, not the brain structure that controls sexual behavior. It follows that in female rats, the motivation to engage in sexual behavior is dependent on activity of the nucleus accumbens, and not on activity within the VMH.
Measuring extracellular dopamine concentrations outside the nucleus accumbens through microdialysis techniques has demonstrated that extracellular dopamine increases during many different behaviors considered to be rewarding, including male and female sexual behavior.
Conditioned place preference (CPP) is a behavioral test that can be used as way of measuring the reward associated with different stimuli. CPP is commonly used as a way to measure reward associated with different drugs of abuse, but the paradigm can also be used to measure the rewarding aspects of natural rewards, such as sexual behavior. In a CPP paradigm, a CPP appartus is used that typically has two distinct testing chambers that have different colors or patterns on the walls, and different tactile surfaces on the floor of the chamber. Additionally, there is a neutral compartment between the two testing chambers. As an example, one testing chamber might have white walls and hard bedding on the floor, whereas the other testing chamber has gray walls and soft bedding.
An experimental male animal can be placed in the neutral central compartment and then given 10 minutes to explore the entirety of the apparatus. The amount of time that the animal spends in each chamber is recorded as a pre-test measurement. Next, the chambers are sectioned off from each other and the experimental male animal is placed with a sexually-receptive female animal in the gray chamber with soft bedding.  The experimental male then has a 10-minute sexual experience within the gray chamber. After the sexual experience, they are also placed alone in the white chamber with hard bedding. This is repeated for several weeks, such that the animals learn to associate sexual experience with the gray chamber environment and learn to associate nothing with the white chamber environment. Lastly, the experimental animal is placed alone in the central neutral compartment and again permitted to access the entire apparatus. The amount of time spent in each of the chambers is recorded as a post-test measurement.

By comparing the time spending in the conditioning chamber during the pre-test to the time spent in the conditioning chamber during the post-test, it can be determined if the animal spends significantly more time in the chamber that was paired with the sexual experience. Researchers interpret a significantly increased time spent in the conditioning compartment as a measurement of the reward that the animal feels being in that environment. If no significant difference is observed between the pre-test and post-test times in the conditioning compartment, then the testing substance or behavior is not considered to be rewarding to the animal.

Using this paradigm, administration of a dopamine antagonist to animals prior to the conditioning sessions prevents the formation of a conditioned place preference, indicating that dopamine within the reward pathway underlies the reward associated with sexual behavior.
In the United States, more than 59 million people aged 12 and over have used illegal drugs or misused prescription drugs within the last year. Use of some of these drugs carry significant health risks, and their use has led to hundreds of thousands of deaths, making drug use one of the highest preventable causes of mortality. For some people, drug use turns into a substance use disorder, or addiction. Importantly, many more individuals misuse drugs than are drug-dependent.
Substance use disorder, typically referred to as addiction has many different facets.

The American Society of Addiction Medicine defines drug addiction as “a primary, chronic disease of brain reward, motivation, memory and related circuitry. Dysfunction in these circuits leads to characteristic biological , psychological, social and spiritual manifestations. This is reflected in an individual pathologically pursuing reward and/or relief by substance use and other behaviors.”
One of the major challenges with understanding substance use disorder and other brain disorders is related to the difficulty of making an accurate diagnosis as almost everything in biology exists on a spectrum. To help establish a diagnosis, the American Psychiatric Association (APA) has put together a series of criteria for psychiatrists to diagnose these complex conditions. The guidelines are compiled in a book called the Diagnostic and Statistical Manual of Mental Disorders. They are currently on the fifth revision of the text, referred to as the DSM-5. It’s an imperfect set of criteria, but it is a start towards understanding these remarkably complicated conditions.
According to DSM-5, a substance use disorder may be an appropriate diagnosis when at least two of the following characteristics occur within a 12-month period of time and cause significant impairment or distress:

The quantity of the substance used or the amount of time spent using is often greater than intended;
Efforts to control use of the substance are unsuccessful due to a persistent desire for the substance;
Considerable time is spent using the substance, recovering from its effects, or attempting to obtain the substance;
A strong desire, craving, or urge to use the substance is present;
Substance use interferes with major role obligations at work, school, or home;
Use of the substance continues despite harmful social or interpersonal effects caused or made worse by substance use;
Participation in social, work, or leisure activities is avoided or reduced due to substance use;
Substance use occurs in situations where substance use may be physically hazardous;
Continued substance use occurs even when the substance is causing physical or psychological problems or making these problems worse;
Tolerance for the substance develops, including a need for increasing quantities of the substance to achieve intoxication or desired effects or a noticeable decrease in effects when using the same amount of the substance;
After heavy or sustained use of a substance, reduction in or abstinence from the substance results in withdrawal symptoms or precipitates resumption of use of the substance or similar substances to relieve or avoid withdrawal symptoms.
Substance use disorder is prevalent worldwide. On top of the direct health risks associated with compulsive drug use, drug addiction has a tremendous financial burden: Alcohol, tobacco, and illicit drugs cost the US more than $740 billion dollars in lost productivity, health care costs, and legal related fees and fines.

In the early 1900s, US laws regulating the manufacturing, distribution, possession, and use of drugs were complicated. Certain substances were banned, but regulation of the substances was left largely to individual states. It wasn’t until 1970 when a nationwide proposed regulatory measure would combine all of the current federal mandates regarding misused drugs into a single bill, and Richard Nixon signed the Controlled Substances Act (CSA) into law. Under the terms of the CSA, the Drug Enforcement Agency and the Food and Drug Administration would be responsible for developing regulations about a wide variety of chemical substances. For each drug, they would be tasked with evaluating the health-related properties of the drug and its impact on health, including toxicity, harm, and addiction potential.

Despite a dramatic increase in the cost of drug enforcement that followed the signing of the Controlled Substances Act, the rate of drug addiction in the United States has remained unchanged.
Drugs are defined as chemical substances that come from outside the body; drugs are exogenous substances that can influence a person’s physical or mental state. Keeping in mind the impact on health and addiction potential, drugs are classified into one of five categories, rated Schedule I through Schedule V.

Drugs put into Schedule I are substances that were perceived to have the highest addiction potential, most severe health risks, and no medical applications. On the other end of the spectrum are Schedule V substances, drugs with low addiction potential, few health risks, and legitimate uses within the clinical setting. Substances classified under Schedule I include heroin, for example, while a Schedule V substance might be an antiepileptic drug like Lyrica. Today, the list of controlled substances contains more than 400 chemicals. Interesting, neither tobacco or alcohol is regulated under the terms of the Controlled Substances Act, despite these drugs being among the most misused in the US with tremendous health risks, high addiction potential, and little medical application. There are probably thousands and thousands of psychoactive substances, chemicals that can act on the nervous system which can induce a change in behavior or mind state.

Some major abused drugs are described below.
According to the 2015 National Survey on Drug Use and Health, alcohol is the most widely used substance among these drugs, with more than 85% of adults reporting having used alcohol at some point in their lives. Chemically speaking, many substances are classified as “alcohols”, but the most common misused is ethyl alcohol or ethanol. Ethanol is an easily-obtained substance with a highly intoxicating effect. The overwhelming majority of ethanol use is recreational. The World Health Organization reports that alcohol use is the leading risk factor for premature death among males aged 15-59 globally, making it one of the overall top causes of preventable death. Acute exposure to ethanol has effects that differ depending on dosage.

At low concentrations, ethanol can induce an elevation in mood, decreased anxiety, increased risk taking, slowing of reflexes, and impaired judgment. At high concentrations, ethanol can cause memory deficits, loss of consciousness, analgesia and areflexia, and possible death through respiratory depression. Chronic exposure to low levels of alcohol has some pro-health benefits such as decreased risk of death by cardiovascular events, but in general, these benefits are outweighed by negative health outcomes.
Nicotine is the main psychoactive ingredient of tobacco products. Nicotine is an alkaloid compound that is synthesized in nature by a variety of plants, with the tobacco plant having the highest nicotine content. Other plants of the Solanaceae family (Nightshade family), such as eggplants and tomatoes, also contains nicotine, as it was probably an anti-herbivory evolutionary adaptation. The most common routes of administration for nicotine include inhalation (cigarettes, cigars, vape), transbuccal (chew, dip, snuff), or transdermal (in the case of the nicotine replacement therapeutic strategy: the nicotine patch). Nicotine is a highly addictive substance, often rated as addictive as cocaine or heroin. It is currently the leading cause of preventable death in the US, causing nearly one out of every five deaths.

When a person smokes a cigarette, they experience a rapid rush or a high within tens of seconds. Chronic smoking greatly increases the risk of developing lung, throat, and mouth cancers, coronary heart disease, or stroke. Cigarette smoking over the past several decades has seen a sharp decline, in part due to the success of anti-smoking campaigns in changing public opinion toward smoking, and government-led changes in legislation resulting in stricter marketing laws, especially in regards to targeted advertising aimed at youth. In the mid 1970’s, almost 30% of 12th graders reported smoking cigarettes daily, and that number has decreased to only 4% in 2018. On the other hand, the rising popularity of vape among teenagers has encouraged nicotine consumption through an alternate route of administration: Teen e-cigarette users are more than 3 times more likely to start smoking cigarettes compared to non e-cigarette users.
Cannabis is a drug that is derived from the flowering buds or other parts of the Cannabis sativa plant. The most common route of administration is inhalation, or smoking. As cannabis becomes decriminalized or outright legalized across the US, oral preparations are becoming more commonplace. The effects of cannabis are often felt within minutes, and can include a sense of euphoria, relaxation, distortion in the sense of perception, and potentially a lightness (high) or a heaviness of body (stoned). Cannabis is currently classified as a Schedule I drug federally, but as of 2022, 23 states/territories have legalized recreational use of cannabis, and only 12 states do not permit cannabis for medicinal use.

The stigma surrounding the “evils” of cannabis use are largely a remnant of a morality propaganda campaign driven by the publishing of such “educational” films as Reefer Madness in 1936. Much of our current medical understanding of cannabis is that it is far less harmful than once believed, although it does have a negative impact on the developing brain, as significant adolescent exposure to cannabis increases the likelihood of developing psychiatric conditions such as schizophrenia later in life.
Opioids are a class of drugs, either natural or synthetic, that can bind to and activate the body’s endogenous complement of opioid receptors. The most well known natural opioid is opium, but the other popular drugs of this class include the street drug heroin or the medicinal substances morphine or fentanyl. Derived from the poppy plant, evidence of human use of opioids for both medical and recreational use dates back more than 5000 years to ancient Sumer. The body naturally produces opioid substances, endorphin being the most well known. Activation of opioid receptors, either by endogenously produced opioids or exogenous opioids, induce a potent analgesia, dampening the sensation of pain. Opioid drugs are the current gold standard for pain relief. They also cause sedation and feelings of euphoria.

Heroin and morphine are frequently taken via intravenous injection, but many prescription opioids, particularly for long-term pain conditions, are consumed orally. Over the past 20 years, there has been a dramatic increase in the number of opioid-overdose-related deaths. The most recent spike in deaths is due to overdose on synthetic opioids such as the extremely potent painkiller fentanyl, which saw a 10-fold increase between 2013 and 2017. The so-called opioid epidemic kills an estimated 130 individuals from the United States each day.
Cocaine is a psychostimulant that is derived from the coca plant. The most common routes of administration are insufflation (powder cocaine), inhalation (crack cocaine), but it can also be solubilized and injected or taken via transbuccal and oral administration by chewing the leaves of the plant. Cocaine is considered to be a potent sympathomimetic, meaning the substance activates the sympathetic nervous system. Therefore, the physiology of a person on cocaine will be similar to an activated “fight-or-flight” response: elevated heart rate and blood pressure, dilated pupils, and increased respiration. Cocaine is a Schedule II substance. Although it has a very high addiction and harm potential, it has a handful of medicinal applications as well. For example, it is a potent local anesthetic and vasoconstrictor, so it is often used in surgery, especially in facial or nose surgeries.
Psychedelics are the class of drugs formerly called hallucinogens. They can be either natural, such as psilocybin which is derived from mushrooms, or man-made, in the case of lysergic acid diethylamide (LSD). Psychedelics can cause a person to experience visual distortions, synesthesia, an altered sense of self (ego dissolution), or sometimes a sudden connection with nature or a higher power. Although psychedelics have been used for centuries in religious ceremonies, they have had a troubled history in the US. The adoption of LSD (acid) by the counterculture movement during the 1970’s, secret CIA funded research, and some loosely regulated research ethics in the clinical setting all led to notoriously negative press regarding the substance, tainted the general public opinion about this class of drugs. Since 2010, there has been a growing body of evidence supporting the notion that psychedelics can serve a therapeutic purpose, most notably in treating psychiatric conditions such as post traumatic stress disorder, terminal illness-related depression, and drug addiction.

Comparing different drugs based on their potential for drug dependence and the amount of physical harm that they cause reveals that drugs such as heroin are classified as more dangerous.
The mesolimbic dopamine pathway within the brain underlies reward (discussed in Chapter 49). As a reminder, our reward signaling neural circuitry starts with the ventral tegmental area (VTA). Located in the midbrain, the VTA contains neurons that synthesize the neurotransmitter dopamine (DA). These VTA DA neurons send their axonal projections predominantly into two main areas.

The mesolimbic pathway consists of dopamine producing neurons that release dopamine onto the cells in the nucleus accumbens (NAc), serving as the major pathway by which reward is mediated by the brain. A separate group of dopaminergic neurons in the VTA project to the prefrontal cortex in the mesocortical pathway. Drugs of abuse act on this pathway, causing drugs to cause heightened feelings of reward, making it more likely that individuals engage with these substances.
The nucleus accumbens can be subdivided into two portions called the nucleus accumbens shell and nucleus accumbens core, each with their own circuitry and functions. The nucleus accumbens shell functions in the “wanting” involved in drug addiction, as well as reward and reinforcement. The nucleus accumbens core, however, functions in the motor functions related to reward and reinforcement.
Using microdialysis, it is possible to measure the dopamine concentration in the NAc during performance of some behavioral tasks. In studies with rats, engaging in rewarding activities such as eating or sex results in increased release of dopamine in the NAc. Similarly we see that release of dopamine into the human NAc is enhanced when we engage in activities we enjoy: binge eating sugary stuff, having sex, even playing video games. Notably, many drugs of abuse such as cocaine or amphetamine can induce a similar overflow of dopamine release when an animal is exposed to the drug.

Many drugs of abuse cause a sensitized increased in dopamine release, meaning that there is an increase in dopamine release. Sensitization is a phenomenon in which there is an increased effect of the drug with chronic exposure. The increased dopamine release at the nucleus accumbens causes an increase in dopaminergic signaling, which can then lead to structural plasticity.

Repeated administrations of multiple drugs of abuse causes cellular plasticity within the nucleus accumbens and other structures within the reward pathway, by increasing dendritic spine density. Dendritic spines are small protrusions off the main dendritic shaft of neurons. They serve as the excitatory synaptic inputs for these cells, increasing excitability. Notably, though the increase in dendritic spine density is observed following administration of multiple drugs of abuse, it is not a universal structural change as opiates do not produce the same dendritic spine increase.
Cocaine acts on a molecular level by functioning as a dopamine reuptake inhibitor, preventing the transporter protein from clearing the neurotransmitters such as dopamine out of the synapse. This leads to increased concentrations of dopamine in the nucleus accumbens and prefrontal cortex. This increased dopamine results in a greater likelihood that the postsynaptic receptors get activated.
Amphetamine acts similarly to cocaine at the synapse, blocking the dopamine transporter and preventing reuptake into the presynaptic cell. Amphetamine can also mimic dopamine at the dopaminergic synapses, binding to dopaminergic receptors.
Opioids being to GABAergic neurons, causing them to hyperpolarize and suppress release of GABA onto dopaminergic VTA neurons, disinhibiting the VTA neurons and increasing dopamine release onto downstream targets.
Although the cannabis plant contains several chemical substances, the main psychoactive ingredient is delta-9-tetrohydrocannabinol, or THC for short. THC, once it enters the bloodstream, is capable of activating receptors that our body uses endogenously, called the cannabinoid receptors (CB receptors). THC inhibits activity of GABAergic neurons that synapse on the dopaminergic VTA neurons, disinhibiting the VTA neurons and increasing dopaminergic signaling.
Pharmacologically, nicotine has specificity as an agonist at nicotinic acetylcholine receptors (nAChRs), excitatory ionotropic receptors that are expressed widely across the body. When nicotine binds to VTA neurons,it activates the cells and causes an increase in dopamine release. Nicotine can also increase glutamatergic activation originating from the prefrontal cortex onto VTA neurons. Collectively, this acts to increase activity of VTA neurons and increase release of dopamine at downstream targets.
Ethanol is a tiny molecule with properties similar to water, meaning that ethanol can diffuse easily through cell membranes. Whereas other chemical substances often have highly specific molecular or protein targets, ethanol has several. Ethanol activates dopamine neurons within the ventral tegmental area, causing an increase in dopamine release at the nucleus accumbens. Further, alcohol acts to inhibit GABAergic neurons within the VTA, disinhibiting the dopamine neurons and increasing their signaling.
Pharmacologically speaking, tolerance can be defined as a decrease in the action of a drug due to repeat exposure. This phenomenon happens as a result of homeostatic adaptations that the body undergoes when it has been exposed to a substance for a prolonged period of time. In a person who is tolerant, they must take progressively higher doses of the drug to experience a desired effect. For a drug naive person, someone with no experience with the drug, a low dose of drug may have a strong effect. However, for a person who has become tolerant to the effects of the drug, that same low dose will produce a small drug effect.

There are different forms of tolerance that a person can experience. In metabolic tolerance, there is a decrease in the amount of the drug that gets to the site of action. The body becomes more efficient at eliminating the substance. Since exogenous substances usually get degraded by enzymatic reactions, an increase in the activity or number of enzymes will decrease the amount of the substance that is capable of acting.

The most common example of metabolic tolerance is seen in frequent alcohol use. The main psychoactive substance found in alcoholic beverages like beer, wine, or liquor is ethanol. Our liver, which filters circulating blood, contains enzymes which break down chemicals in the blood. Specifically, the standard degradation process of ethanol uses two enzymes. The first of which, called alcohol dehydrogenase, oxidizes molecules of ethanol into the toxic byproduct acetaldehyde. The second step uses the enzyme acetaldehyde dehydrogenase to convert the acetaldehyde into acetic acid, a generally harmless compound (the same chemical structure as vinegar) that is used by the body in a biochemical reaction that drives the citric acid cycle. Because most alcohol is taken via oral consumption, ethanol is subject to first-pass metabolism before reaching systemic circulation.

However, after prolonged exposure to alcohol, the body undergoes homeostatic compensatory changes. The two liver enzymes responsible for degradation of ethanol increase in either function or amount. When these metabolic enzymes become upregulated, the circulating ethanol in the bloodstream becomes broken down more rapidly and more efficiently, resulting in a decrease in the amount of ethanol that reaches general circulation, and consequently, the brain. This explains why people who have never drank alcohol (low amounts/function of enzymes) may experience a stronger drug effect compared to someone who drinks regularly. It also accounts for why there is some genetic variation between a person’s sensitivity to alcohol’s intoxicating effect, as enzyme efficiency is partially encoded by genetics.

Another way by which tolerance can manifest itself is through changes at the level of the molecular components of cells. This type of tolerance is called cellular tolerance. This tolerance leads to a decreased sensitivity to the substance. Cellular tolerance can be characterized by a decrease in receptor expression after chronic exposure to an agonist. When the opioid etorphine is present in the body, it activates the opioid receptors. Frequent exposure to etorphine causes a molecular change in the receptors, which leads to internalization, the process by which cell surface-expressed receptors become taken into the cell. Since etorphine is only able to activate receptors on the surface, these internalized receptors diminish the strength of the etorphine signal, which manifests as tolerance. By downregulating the number of receptors that are expressed on the surface, the cell reacts to the environment by becoming less responsive in the face of drug.

Sometimes, the body physiologically prepares for the drug effect before the drug is even present. The way it does this is to initiate an opposite somatic effect from what the drug is expected to do. This “reverse” effect is likely a protective mechanism to minimize the drug effect, and these anticipatory bodily changes can be precipitated by drug-associated cues. For example, heroin causes analgesia. Cues that predict administration of the drug, such as preparation for an intravenous injection or being in a physical environment where drug is frequently administered, can cause the reverse physiological effect, hyperalgesia. Because of this, a person may need to take more drug to overcome the anticipatory changes. This unconscious form of learning leads to a form of tolerance that is dependent on Pavolvian cues; this is called conditional tolerance. If not accounted for, conditioned tolerance can have potentially lethal side effects. A clinical description (Siegel, 2001) of a patient with pancreatic cancer describes one such “failure” of tolerance. Bedridden and suffering from tremendous pain, a man was regularly given morphine in his bedroom, dark and filled with humming apparatus for his medical care. As expected, he developed a tolerance towards the morphine, requiring higher and higher doses in order to inhibit pain. One day, he went into the brightly lit living room to receive his normal dose of painkiller. Soon after, he died from opioid overdose.
Sensitization is a phenomenon related to tolerance, but the polar opposite: instead of a drug effect being lessened after chronic exposure, a sensitized person experiences an increase in drug effect. Nicotine as well as many psychostimulants such as cocaine or amphetamine can produce psychomotor sensitization after repeated dosings. Psychomotor sensitization can be measured through crossovers (how often the animal runs across the midline of the cage). Animals displaying sensitization will show significantly more crossovers compared to non-sensitized animals. This sensitization can be long-lasting, remaining for up to one year following the last dose of drug.
“Why do some people transition from user to addict?” Many people are able to use the most addictive substances such as cocaine or heroin casually without ever becoming an addict. For these people, their drug use pattern can remain recreational, even though they may use the substance frequently and report a great sense of satisfaction when they use the drug. On the other hand, there are some people who have a very high propensity to quickly becoming a pathological addict. One of the big challenges in drug abuse research is to understand the differences between these two populations. What factors, either environmental or genetic, are protective and prevent the transition from casual drug user to compulsive drug addict? And what are some ways we can use this knowledge to help addicts find ways to break their pattern of harmful compulsive drug seeking and drug use? One possible way to get at the answer is to create animal models of drug dependence and try to determine the nature of the underlying biological changes that contribute to the addiction-like pattern. Do some cellular circuits change permanently? Are certain genes or proteins upregulated or downregulated? Can pharmacological or behavioral interventions change drug-taking or drug-seeking behavior?
One of the most instructive non-human animal models of drug use disorder is called self-administration. In a self-administration experiment, the subject (usually a monkey, rat, or mouse) gets a surgical implantation of an indwelling intravenous tube that is connected to a pump. Then, the subject is put into an operant conditioning chamber. When they press the lever or poke their nose into a hole, the pump triggers, resulting in an infusion of drug directly into the bloodstream. This experimental paradigm closely mimics human drug seeking behavior. For example, rats and mice will very quickly learn to press on the levers for intravenous infusions of cocaine and morphine. Many of them will give themselves drugs even despite severe adverse consequences, such as enduring foot shock—arguably similar to human behavioral patterns where addicts may do all kinds of behaviors for access to drugs. Monkeys, if given the option to self administer for cocaine, must be restricted in the amount of drug they receive: if given unrestricted access, they give themselves so much cocaine that they have seizures and die.
A second experimental test created to study drug abuse is called conditioned place preference (CPP) (also discussed in Chapter 50). A CPP test works on the principle that animals learn to associate certain environments with positive feelings, and will prefer to spend significantly more time in those environments. To conduct CPP, a three-room testing chamber is used. This experimental chamber has two large rooms, each with characteristics that are unique to that room. For example, one room may have mesh flooring with dark-colored walls, while the other room may have woodchip flooring with light-colored walls. The two rooms are connected by a smaller, neutral room, and the rooms can be isolated from another by means of a dividing door. To conduct CPP, an animal will be given the drug of interest, then placed into one of the two rooms, where they are free to explore the room, but cannot leave. As a control, at a different time, they will be injected with an innocuous solution and placed into the other room. On test day, the animal will be put into the neutral middle room, and given the opportunity to move freely between the two chambers. If the animal developed positive associations with the room where they experienced the drug effect, then they will choose to spend significantly more time in that room. On the other hand, if they experienced negatived conditioned place feelings associated with that room, they will avoid being in the room. Whereas self-administration assesses “drug seeking”, CPP measures “drug liking”.
Below are three major biology-driven hypotheses that have been proposed to explain drug addiction. It’s important to note that none of them tell the complete story—otherwise drug addiction will have already been cured! Also, these theories are not mutually exclusive from one another. A likely answer to curing addiction probably incorporates some combination of these approaches in addition to societal policy changes.
What drives addicts to behave in the way they do? One of the earlier theories put forward to explain addiction is the hedonia hypothesis proposed in the late 1970s by Roy Wise. The hedonia hypothesis hinges on the assumption that dopamine is the “pleasure neurotransmitter”, and that any substance or behavior that increases dopamine will be desirable. The theory is supported by some behavioral data. For example, using microdialysis, it was found that dopamine release by the mesolimbic pathway increases in the presence of many drugs of abuse. Additionally, administration of dopamine antagonists are able to block some drug taking behavior. This dopamine-centric approach to drug use disorder was so influential that pharmaceutical companies, while developing novel antidepressants, quickly dismissed drugs that increased dopamine out of fear of the risk of addiction potential.

Despite the attractiveness of the straightforward “pleasure neurotransmitter” model, the dopamine hypothesis does not give us the whole picture. For one, dopamine release at the mesolimbic pathway is only notable for psychostimulant drugs, such as cocaine and methamphetamine. But there are plenty of stimulants that still produce the significant overflow of dopamine without causing any rewarding sensation. Furthermore, if dopamine is the signal that mediates the positive hedonic feelings, one might predict that by blocking dopamine receptors chronically, you can also prevent long-term cocaine addiction, but this therapeutic strategy isn’t very useful. Many of the most popular misconceptions about dopamine that you frequently see in the media take this early hypothesis as the truth. It even was featured as the cover of a 1997 Time magazine. That same year in an interview with the original proponent of the hedonia hypothesis published in Science, Roy Wise agreed with recent results that his model was incomplete.
A more recent theory to explain drug addiction is a model developed by researchers Terry Robinson and Kent Berridge from the University of Michigan. Under their model of drug use, initially a person takes a drug because they like the positive, euphoria-producing side effects of the substance. But after chronic exposure to the substance, the person becomes fixated on obtaining the drug rather than how the drug makes them feel. At this point, they continue to use the drug even though they no longer enjoy the drug to the same degree that they once did. Instead of “liking” the drug, the addict fixates on “wanting” the drug. The incentive sensitization model suggests that the drug-exposed brain develops an increased sensitivity to drugs, but also more importantly, drug related cues.

Pavlovian learning takes place when an addict takes a drug. Each drug has an associated set of cues, and reexposure to those cues can trigger relapse. Over repeated pairings, those cues trigger a progressively stronger response. Their model accounts for why it is difficult to remain abstinent from an addictive drug for long durations of time. Despite a decrease in drug seeking behaviors, many addicts eventually relapse, or return to the previous destructive pattern of drug use. One phenomenon that makes staying drug free difficult is the observation that prolonged abstinence can increase the intensity of drug cravings. This is called incubation of craving, and is seen with several different classes of drugs, notably, nicotine.
Much of our current understanding of addiction is based on the principles that repeated drug use leads to biological changes in the brain that resemble aberrant learning. This model for drug addiction is called the Brain Disease Model of Addiction. Genetics has a strong influence on the likelihood that someone develops a disease, and addiction is no different. Inherent risk-taking behaviors, magnitude of a drug effect, and risk of relapse are all modified by genetics. One of the major implications of this model is that compulsive drug use and seeking is not a choice that a person makes. Addicts are not the way they are because of some poor moral guidance or a weakness of willpower. Addicts compulsively seek drug because of some underlying circuitry of their brain that makes cessation difficult.

One substantial accomplishment of this model is that public policy has adjusted to increase access to mental health resources for addicts to help cover the financial challenges of recovery programs (Mental Health Parity and Addiction Equity Act of 2008), and to improve the outcomes of nonviolent drug offenders as they reintegrate with society outside of prisons. This model is not without fault, however. The major criticism of this framework to explain compulsive drug use is that most people stop their addictive use patterns by themselves spontaneously without any treatment. Another harm of the Brain Disease Model of Addiction is that it puts heavy emphasis on biochemical therapies rather than on a public policy approach to drug addiction treatment. Lastly, this model has not produced a successful therapeutic strategy to help with addiction.
Sexual differentiation is the process by which a person develops into either a male or a female. For the purpose of this chapter, the content will be based on a male/female binary to introduce the basic concepts of reproductive development. However, it is important to recognize that in real life, chromosomal sex, physical sex, and gender exist on a continuum and cannot always be simplified into a two-structure system.

Gender is a cultural variable with behaviors and attributes that are associated with being masculine or feminine and is determined by interactions between genes, hormones, life experiences, and cultural expectations.

During development, the body and the brain undergo either: A) feminization and de-masculinization or B) masculinization and de-feminization. In most cases, the differentiated brain will lead to behaviors that correspond to the differentiated gonads.
In humans, DNA is organized into 46 chromosomes. One set of 23 chromosomes comes from the mother and the other set comes from the father. Twenty-two pairs are called autosomal chromosomes. These chromosome are similar in length and have the same genes present at the same location regardless of if they are received from the mother or father. However, for all genes, the allele, or version, present for each gene may be different from each parent. The last pair of chromosomes is responsible for determining if an individual becomes a male or female; these are called the sex chromosomes. In humans, the sex chromosomes are named either X or Y.
Fertilization occurs when a sperm cell from the father fuses with an egg cell from the mother. All egg cells contain one X sex chromosome. Sperm cells contain either one X or one Y chromosome, which means chromosomal sex in humans is determined by the sperm. If a sperm carrying an X chromosome fertilizes an egg, the resulting fetus will be XX and a female, whereas if a sperm carrying a Y chromosome fertilizes an egg, the resulting fetus will be XY and a male.
The presence of the Y chromosome signals for the formation of testes in the fetus. The Y chromosome is much smaller than the X chromosome (50 genes vs ~800 genes). There is a gene on the Y chromosome called the sex-determining region (SRY) of the Y chromosome. The SRY gene is required for masculinization of the embryonic gonads. Other genes on the Y chromosome are also important in sex determination and in male physiology, however we will focus on the SRY gene.

The SRY gene encodes for a protein called the testis-determining factor (TDF), which causes the embryonic gonads to differentiate into the testes. The testes then begin secreting both testosterone and a hormone called the Müllerian inhibiting substance (MIS). Testosterone causes Wolffian ducts to develop into the vas deferens, seminal vesicles, and epididymis. MIS causes the Müllerian ducts to degenerate. The presence of testosterone also results in the development of the prostate gland and penis.

Because XY males only have one copy of the X chromosome, they are more at risk for X-linked diseases.
In females, when the SRY gene and secreted hormones are absent, the gonads differentiate into the ovaries, the Müllerian ducts develop into the fallopian tubes, uterus, and vagina, and the Wolffian ducts degenerate.
There are a number of disorders that result from chromosomal abnormalities. In Klinefelter Syndrome, individuals have an XXY genotype. Due to the presence of a Y chromosome, individuals with Klinefelter Syndrome have a “male” appearance. The additional X chromosome causes the individual to have less body hair, small testes, wide hips, long arms and legs, more breast tissue, and a female pubic hair pattern. The additional X chromosome causes many individuals with Klinefelter’s Syndrome to be infertile.

In Jacobs Syndrome, also called XYY Syndrome, individuals have an XYY genotype. Again, due to the presence of a Y chromosome, these individuals typically have a “male” appearance. Individuals may also be taller than average and have an increased risk of learning disabilities. Psychological studies indicate that individuals with XYY Syndrome may have difficulty with impulse control and emotional regulation. Historically, increased testosterone is correlated to increased aggressive behavior in incarcerated males with XYY Syndrome.

In Trisomy X, also called XXX Syndrome, individuals have an XXX genotype. These individuals have a “female” appearance. Fewer than 10% of individuals that have XXX Syndrome are aware that they have it. Symptoms include learning disabilities, wide-spaced eyes, and increased height. Individuals have an increased risk for early menopause.

In Turner Syndrome, individuals have an XO genotype. The “O” indicates the absence of a chromosome, therefore rather than 2 sex chromosomes, individuals with Turner Syndrome only have 1 X chromosome. The lack of Y chromosome leads to these individuals having a “female” appearance. Other symptoms associated with Turner Syndrome include short stature, webbed neck, low-set ears, and a receding jaw. Due to only having one X chromosome, ovaries typically do not form, or form abnormally, and breasts do not develop. Hormone therapy is necessary for the development of a menstrual period and breasts. There is not a corresponding YO genotype, because at least one X chromosome is necessary for life.
Control of gonadal hormone release relies on activation of the hypothalamic-pituitary-gonadal (HPG) axis. Gonadal hormones are important for development of the body and brain, changes during puberty, and the activation of some behavior in adulthood like reproductive behavior and aggression.
As a refresher, the hypothalamus, which is located inferior to the thalamus, integrates information from many regions of the central nervous system and maintains homeostasis in the body. The hypothalamic regulation of gonadal hormones and sex behavior is managed via hormone release by the pituitary gland.
Gonadal hormone release relies on anterior pituitary function. In the hypothalamus, the parvocellular neurosecretory cells release a hormone called gonadotropin-releasing hormone (GnRH) into the hypophyseal portal circulation. When GnRH reaches the anterior pituitary, it causes the endocrine cells of the pituitary to release luteinizing hormone (LH) and follicle-stimulating hormone (FSH) into the general circulation.
The LH and FSH travel through the circulatory system and can act on the gonads, either the testes in males or ovaries in females. In response to the pituitary hormones, the testes release testosterone, an androgen, and the ovaries release estradiol, an estrogen, into the blood stream. After puberty, the LH and FSH are also critical for the maturation of sperm and egg cells.
Sex steroid hormones are produced by the gonads (ovaries or testes). All sex steroid hormones are originally generated from cholesterol. Males typically have higher concentrations of androgen sex steroid hormones, such as testosterone and 5-alpha-dihydrotestosterone (DHT). Androgens are primarily released from the testes. Females typically have higher concentrations of estrogens (such as estradiol) and progesterone that are primarily released from the ovaries. Importantly, males also have estrogens and progesterone, and females have androgens. The only difference is the relative concentration between males and females.

In the synthesis pathway, enzymes are responsible for converting one hormone into another hormone. The enzyme 5-α reductase converts testosterone into DHT. DHT is important for masculinization of the body structures. Through just one chemical reaction, the enzyme aromatase converts testosterone into estradiol.
Once the gonadal hormones are synthesized and enter the circulation, they are able to act on cells that express either androgen receptors or estrogen receptors. Testosterone and estradiol are steroid hormones that can affect target cells through two different mechanisms:

Classical mechanism: Steroid hormones like testosterone and estradiol are able to pass through the phospholipid membrane of a neuron because they are lipophilic. Some neurons express receptors for these hormones. Androgen receptors bind androgens like testosterone while estrogen receptors bind estrogens like estradiol. When a hormone binds to a receptor in the neuron, the hormone-receptor complex dimerizes and moves into the nucleus where it can bind to specific promoter sites on the DNA and act as a transcription factor to turn on or off certain genes (genomic effects).
Rapid mechanism: Sex steroid hormones can also bind to membrane-bound receptors and can exert more rapid effects within the cell.
The testes secrete testosterone during the prenatal critical period. The effect of this testosterone is to masculinize and defeminize the brain, body, and behavior, and this is accomplished through the transcription of a specific set of genes. However, many of those genes are not transcribed by the action of androgen receptors interacting with the DNA. Instead, when testosterone enters the cell, it does not always bind to androgen receptors. Some neurons also express the enzymes 5-α reductase and aromatase that break testosterone down into its metabolites: DHT and estradiol.
In some mammals, like rodents, this conversion of testosterone to estradiol through the actions of the enzyme aromatase is the main process by which neurons and the brain are masculinized. The estrogen receptors cause the transcription of masculinizing genes. Therefore, somewhat surprisingly, even though estrogen is typically thought of as a ‘female’ hormone, its actions during development are responsible for much of the masculinization that occurs in the brain in some animals.

The brain is by default “female” during development, and requires the testosterone secreted by the testes and converted into estradiol for “male” development. It should be noted, though, that estrogen does not appear to have these same masculinizing effects during human development.
In addition to differentiating the reproductive duct system, the presence or absence of gonadal steroid hormones during development also differentiates the rest of the body, including the brain. Testosterone causes the brain, body, and behavior of the individual to be masculinized and defeminized. The quiescent ovaries do not release hormones which causes the brain, body, and behavior of the individual to be feminized and demasculinized.
In the brain, gonadal hormones bind to receptors to alter neuronal function and overall behavior. In many species, males and females have different roles in sexual reproduction when it comes to finding a mate, copulation, birth, nursing, and nurturing offspring. It follows that there are differences in structure and function between male and female brains.

A sexual dimorphism is a distinct difference in the size or appearance of a structure between the sexes of an animal. In rodents, a sexual dimorphism has been described in the sexually dimorphic nucleus of the preoptic area (SDN-POA) within the hypothalamus. The SDN-POA is generally 5-8 times larger in male rodents than it is in female rodents.
Are there sexual dimorphisms in the human brain? This answer is not clear. There may be differences in structures, but the differences are small and controversial. A set of nuclei within the human brain has been studied with regard to sexual dimorphisms called the interstitial nuclei of the anterior hypothalamus (INAH). Within this collection of nuclei, INAH-1, INAH-2, and INAH-3 have been reported to be larger in men than in women, with INAH-3 having the largest difference. The function of INAH in sexual behavior is still not well-understood. Importantly, there is a large degree of variability between human brains. This means that even when a sexual dimorphism is observed, it is being observed “on average” across many brains. Within this comparison group, there will be brains that do not show a sexual dimorphism or potentially show the exact opposite difference in size.
The hormonal effects of secreted testosterone on the brain must take place during a specific time in development, called a critical period. Organizational effects of hormones lead to major, generally irreversible, aspects of cell and tissue differentiation. Organizational effects take place during critical periods like prenatal development and puberty.

In adulthood, the same hormones trigger physiological or behavioral responses called activational effects that are reversible and short-lived.
The early role of testosterone is an organizational effect and results in a permanent change in the nervous system and therefore behavior. The androgens released by the testes enter cells of the SDN-POA and are converted into estradiol through the actions of the enzyme aromatase. The estradiol within the SDN-POA acts to masculinize the structure of the SDN-POA by preventing cell death, causing the SDN-POA to be larger in males than in females. Due to the female ovaries being inactive during development (do not secrete estradiol), the female SDN-POA has a smaller, feminized structure due to the normal cell death that occurs during development. If testosterone is experimentally administered to a female during the organizational critical period, the SDN-POA will be masculinized and larger, however if the testosterone is experimentally administered to a female after the organizational critical period, the structure of the SDN-POA will remain small and feminized.
Clearly, the presence of hormones during the organizational critical period is critical for the masculinization of the rodent brain. Below are examples of conditions in humans that demonstrate the organizational effects of gonadal steroid hormones on both the brain and body.

Androgen Insensitivity Syndrome (AIS) (also known as Testicular Feminization Syndrome) affects the development of the reproductive organs. Individuals with this syndrome do not have functional androgen receptors. Therefore, circulating androgens cannot bind to androgen receptors which affects the development of secondary sexual characteristics, causing these individuals to have a feminized appearance. They have an XY genotype but have genitalia that look female at birth, with the presence of a vagina, but do not have ovaries or a uterus.  As a result, they do not menstruate and cannot become pregnant. Due to the presence of the Y chromosome, individuals with AIS have undescended, but typically functional testes. Many XY individuals that have AIS only discover their syndrome during puberty when they do not experience their first menses. Upon understanding their biology, many still prefer to call themselves women, dress like women, and choose men as their sexual partners.

Congenital Adrenal Hyperplasia (CAH) affects individuals with an XX genotype. During development, the adrenal glands of these individuals produce an excess of androgens. The higher circulating androgen levels results in masculinization of the external genitalia to varying degrees resulting in intersex conditions with ambiguous genitalia structure. These individuals still have ovaries and do not have testes (due to the lack of Y chromosome). In many cases, these individuals are treated medically with hormones and raised as female.

Lastly, a group of individuals in the Dominican Republic referred to as the “Guevedoces” are XY genotypic individuals that are born with a feminized appearance and undescended testes that are assigned a female sex at birth. These individuals have a deficiency in the activity of the enzyme 5-α-reductase. 5-α-reductase is typically responsible for converting testosterone into dihydrotestosterone (DHT), the hormone that is responsible for the development of male external genitalia. However, at puberty there is a surge in testosterone in these individuals that overcomes the 5-α-reductase enzyme deficiency, allowing in the growth of male sex organs. This causes these individuals that were raised as females to start growing a penis. “Guevedoces” literally translates to “penis at 12 years” in Spanish. This phenomenon has also been observed in a small population with Papua New Guinea. Culturally, this has major implications in gender roles for these individuals as only 2 genders are typically recognized, though they are described as a third sex.
Activational effects of gonadal steroid hormones occur during adulthood and are short-lived and reversible. Examples of activational effects of gonadal steroid hormones include sexual behavior patterns and ovulation. Removal of the activating hormone will cause the behavior to stop, but replacement later will cause the response to begin again because the brain has previously been organized to produce those behaviors when hormones are present. Interestingly, maternal and paternal behavior have both been shown to change the brain in various ways such as changes in dendritic branching and somatosensory maps through experiential plasticity.

The role of activational hormones can be demonstrated by adult castration in male rats. Healthy males with intact testes will show sexual behavior when placed with a female rat. Castration, the removal of the testes, will cause males to stop showing sexual behavior because the activating hormone, testosterone, is no longer present. However, if the castrated males receive testosterone replacement, they will resume showing sexual behavior. The sexual behavior brain circuit was organized during development by exposure to gonadal hormones, and in adulthood that circuit can be activated by testosterone. The adult behavior can only be seen when the activating hormone is present.
Long-term attachment, which includes pair bonding with a sexual partner and parental bonding with offspring, are naturally rewarding behaviors in some species of mammals.
Much of the research on social attachment and mammalian pair bonding has been done using voles as the animal model. Voles are useful because there are closely related species that display considerably different reproductive behavior. The prairie vole (Microtus ochrogaster) that is indigenous to central North America is an atypical rodent that displays highly social behavior, has monogamous relationships after mating, and will cohabitate and share parental duties such as mutual resource collections, nest building, and care for their young. The montane vole, on the other hand, has a slightly different geographical location and is a non-social species. They do not form pair bonds and only the female cares for the young.

An experimental test called the partner preference paradigm can be used to assess vole monogamy. Here, a three-chamber testing apparatus is used where a test vole is placed in a central chamber. In the other two chambers are voles who have been harnessed into their rooms, unable to leave. The test vole is then free to move between any of the three chambers. When a prairie vole has mated with one of the harnessed voles, they will choose to spend more time with their “partner” vole compared to the novel “stranger” vole, whereas a montane vole will choose to spend most of their time alone and spend very little time with any other animal. Differences in brain and behavior can be studied between these species to determine why they display these different reproductive behaviors.
Not only do mated prairie voles prefer the company of their partner, they also demonstrate behaviors similar to some human romantic relationships. For example, mated prairie voles living together display selective aggression against a stranger, “intruder” voles, a behavior called “mate-guarding”. They also spend significant time mutually caring for their young, their pair bonding can be modified by psychoactive substance use, and they show increased anxiety when they are separated from their partner vole.
Comparing between monogamous and promiscuous species has allowed researchers to identify several neurotransmitter signals that are implicated in pair bonding. Oxytocin and vasopressin seem to play important roles in vole pair bonding, as inhibition of either of these signals decrease partner preference. Additionally, differences in dopamine receptor levels and corticotropin releasing factors are observed between vole species.
The hypothalamus is a critical region for the formation of social bonds. Magnocellular neurosecretory cells, the larger type of neurosecretory cell compared to parvocellular neurons, send axons from the hypothalamus down to pituitary stalk where they terminate on capillaries of the general circulation located within the posterior pituitary. Therefore, unlike the control of stress and gonadal hormones, where the hypothalamic neurons release hormones onto anterior pituitary endocrine cells, release of hormones from the posterior pituitary comes directly from hypothalamic neurons.
The magnocellular neurons synthesize and release oxytocin and vasopressin, two neuropeptides, into the blood. Oxytocin, often referred to as the love hormone, promotes social bonding. It is released during reproduction and also causes uterine contractions during labor and the milk letdown reflex after birth. Vasopressin, also called antidiuretic hormone, plays a role in regulating salt concentration in the blood by acting on the kidneys to promote water retention and decrease urine production. Further, it constricts blood vessels, raising blood pressure. Vasopressin has also been shown to be involved in bonding, parenting, territoriality, and mate-guarding in some animals. Biochemically, vasopressin is very similar to oxytocin, as they are both nine amino acid peptides differing by only two residues.
In the social prairie voles, oxytocin and vasopressin are released by the hypothalamus in response to mating and act on regions of the reward and limbic systems. Specifically, there are increases in oxytocin release in female prairie voles following mating. Female prairie voles express higher levels of oxytocin receptors in the nucleus accumbens compared to montane voles. Oxytocin binding to oxytocin receptors within the nucleus accumbens is necessary for females to form pair bonds and may reinforce the association of reward with a partner. This is supported by experimental evidence that when oxytocin is administered to females, there is an increase in pair bond formation. Female montane voles have decreased oxytocin receptors within the nucleus accumbens, and thus do not form pair bonds. Oxytocin does not have the same effects in male prairie voles.

Male prairie voles have an increase in vasopressin release following mating. The male prairie voles express higher levels of vasopressin receptors in the ventral pallidum compared to montane voles. When vasopressin is given to males, it increases pair bond formation, and when a vasopressin antagonist is administered prior to mating, pair bond formation is prevented. Vasopressin has no effect on female prairie voles. The nucleus accumbens and ventral pallidum are both located in the basal ganglia and are involved in the limbic loop, which is responsible for processing of emotions, rewards, and motivation.

An interesting experiment was done that overexpressed vasopressin receptors in the ventral pallidum of male montane voles. The simple manipulation of this one protein completely changed the behavior of the monogamous montane voles such that they now behaved like prairie voles by forming pair bonds and helping to take care of young.
Oxytocin, vasopressin, and the reward system also appear to be important for bonding in humans. When presented with pictures of either their own children or partners, subjects in an fMRI show increased activation in regions like the ventral tegmental area and striatum compared to when viewing pictures of friends. These regions are also known to express oxytocin and vasopressin receptors, and the hormones are released during times of bond formation, like breastfeeding and intercourse.
Love can be thought of as an intensely strong attachment towards a person (romantic love, lust), a thing (passion project), or concept (patriotism as a love for country, or altruism as a love for fellow humans). However, it is very difficult to put a strict biological definition on these varied concepts of love. This section focuses on interpersonal love, of which there are several unique forms, each resulting in different behavioral outcomes. For example, romantic love drives physical attraction, lust, and sexual activity. Parental love, on the other hand, encourages self-sacrifice and hyper-attentiveness towards a newborn. Some behaviors are shared between the two forms of love, such as respect.
Romantic love drives much of human behavior and has been documented thoroughly in the arts all the way from Homer’s Iliad, through Shakespeare’s Romeo and Juliet, up to modern Taylor Swift.

The majority of human societies have embraced social monogamy, the romantic relationship characterized by a pair of people who share resources, parenting duties, and exhibit preferential mating. Outside of humans however, only 9% of mammalian species form socially monogamous pairs, while at least 75% of bird species maintain socially monogamous relationships (which may explain the origin of the phrase “love birds”).

Dr. Helen Fisher, an anthropologist and a leader in the field of love research, suggests that love can be divided into three closely interconnected components. These three are guided in part by different signaling pathways, and lead to somewhat different behavioral outcomes.

Lust (or libido) refers to a very strong desire for sexual gratification. These behaviors are largely driven by the actions of the sex hormones testosterone, estradiol, and progesterone, released downstream of activation of the HPG axis. Both testosterone and estradiol contribute to sex-seeking behaviors in men and women, where increasing testosterone levels drive up sexual desire. The amygdala also plays a significant role in mediating lust, and lesions may either result in hypersexuality (Kluver-Bucy syndrome) or a decrease in response to socially-derived sex cues.

Attraction is characterized by high energy-investment and preoccupation towards a small number of people. From an evolutionary perspective, attraction may have developed to discriminate between multiple reproductive partners, allowing the focusing of limited resources towards fewer partners. In Fisher’s theory, attraction is strongly related to the action of dopamine and norepinephrine. In humans, the reward circuitry is involved in feelings of love. Using fMRI, Fisher presented pictures of a patient’s romantic partner to them and identified increases in the blood flow to dopaminergic midbrain areas such as the ventral tegmental area and the striatum. This finding compares with imaging studies that observed increases in blood flow to insula, premotor, and hypothalamus as well as striatum in response to highly erotic, sexual imagery. These studies suggest that romantic love and lust have different driving neural structures underlying these behaviors. Norepinephrine functions to increase attention, alertness, and energy, which accounts for the exhilarated feeling you may feel when spending time with a potential partner.

Attachment is the long-term association with an individual accompanied by feelings of comfort and emotional stability. Attachment also contributes to behaviors that maximize offspring survivability, such as sharing parenthood responsibilities and protectiveness towards offspring. The major neurochemical drivers of this form of love are oxytocin and vasopressin.
Parental love refers to instinctive affection towards one’s offspring. Parental love behaviors include nurturing (collecting and sharing resources), protecting (promoting aggression against “intruders”), and preparing one’s young for their adult life (risk assessment training). In evolutionary theory, parental love serves to improve the odds of passing of one’s genes through the following generation. Most large mammals (humans included) are K-selected species, which benefit most from a small number of high-quality offspring that require substantial parental investment, as opposed to large numbers of offspring with little investment.

An extension of parental love is familial love or kinship, the protection and preferential support of one’s extended genetic relations. Because blood relatives share common genes, increasing the survivability of these family members has benefits for passing genes to the next generation. In the words of the geneticist Jack Haldane, “I’d gladly give my life for two brothers or eight cousins.”

Many behaviors related to mammalian motherhood are accompanied by changes in neural activity. Nursing, for instance, is feeding behavior that is regulated through a positive feedback cycle. Offspring suckling activates the mother’s somatosensory afferents. Through a series of oxytocin-dependent circuits across the hypothalamus, suckling ultimately increases lactation through the milk letdown reflex. Auditory sensory inputs, such as the sounds of a crying baby, can also trigger this reflex. Sometimes, just thinking about the baby can induce letdown. Some changes are dependent on neural plasticity. For example, after childbirth, the auditory areas of rodents rewire to become more sensitive to high frequency sounds. This adaptation allows the mothers to better detect the ultrasonic vocalizations that are emitted by offspring when they are distressed or hungry. Olfactory areas also change in order to become more sensitive to the particular odorants given off by their young, allowing them to better identify their offspring. In humans, these olfactory changes result in decreased aversion towards traditionally aversive stimuli (urine or fecal matter) when they originate from their children.
Sleep is such an important part of our lives that a lack of it strongly correlates with negative outcomes on nearly every measure of health. People who sleep less than approximately 7 hours a night are at a greater risk for heart disease, stroke, asthma, arthritis, depression, and diabetes. Nearly 20% of all car crashes, both fatal and nonfatal, are attributed to drowsy driving. The cancer research branch of the World Health Organization has determined that disruption of regular sleep is “probably carcinogenic to humans”, putting it in the same risk category as the infectious agents malaria and human papillomavirus (HPV), as well as the biochemical weapon mustard gas. Sexual health is affected by sleep deprivation as well, as men with the worst sleeping habits have significantly lower sperm counts, decreased circulating testosterone, and even testicular shrinkage.

Despite all that we know about the benefits of sleep, sleep is often the first time commitment to get cut, often getting squeezed as people stay awake later while waking up sooner. Consider that the CDC estimates that more than a third of American adults fail to get enough sleep each night. Almost 70% of college students fail to get the recommended amount of nightly sleep, and half of all college students report experiencing daytime sleepiness as a result.

The current medical recommendation is 7-9 hours of sleep each night. But why is sleep so important? It is possible to study sleep using a combination of techniques; the output of sleep studies are visualized on a polysomnogram (pahle-SOM-nuh-gram; somn- is the prefix referring to sleep). Several physiological measures are taken in a polysomnogram, including heart rate, blood pressure and oxygenation level, respiratory depth and pattern, muscle activity, eye movement, and one of major interest to neuroscientists: brain wave activity. While everyone knows what sleep is, it is useful to try to more precisely define sleep as a biological function.

Sleep is characterized by a decrease in physical activity, a decoupling from external inputs, and changes in brain wave activity.

Compared to waking behavior, a person’s physical activity is greatly decreased when they sleep. While asleep, people are relatively inactive and as a result, the body uses about 10% less energy. This is not to say that people do not completely cease all movement during sleep. It is very common to readjust posture many times in the middle of the night. Some people may grind their teeth together or talk in their sleep, sometimes carrying on full conversations by themselves! About 15% of people have experienced somnambulism, or sleepwalking: full on wake-like behaviors, such as navigating down a flight of stairs or preparing a sandwich, performed entirely in the absence of intent of memory recall. Despite these rare occurrences of physical activity, the average movement of the person over a night’s rest is still less than their average activity when awake.

When we sleep, our conscious brains are “distanced” from the outside world. Sleep causes a heightened threshold for detection of stimuli, so we do not receive the same magnitude of inputs from our sensory systems as when we’re awake. This is why someone else might have to talk loudly or even shake you physically to wake you up.

Lastly, sleep was once thought to be a period of time characterized by low brain activity. After all, the person looks like they are not moving. Shouldn’t brain activity be reflective of that decreased state of activity? With the advancement of EEG technology in 1924, and the rise of sleep laboratories in the 1970s, scientists who studied brain activity noticed that, at different times throughout the night, the brain of a sleeping person was very similar in activity to the brain of an awake person!
Electroencephalography (EEG) is used to measure brain rhythms through recording electrical activity at the scalp, making it a non-invasive and painless tool to detect brain activity. EEG detects the general activity of the cortex by measuring small (~10 uV) fluctuations in voltage. This technique does not measure electrical activity of a single neuron, but rather measures the electrical activity of a large population of neurons, on the order of thousands of cells, in order to generate a signal that is large enough to detect.

An EEG reading depicts differences in both amplitude and frequency over time. An increase in amplitude on an EEG indicates a higher degree of synchronous activity of cortical neurons, whereas the frequency of an EEG indicates how often neural synchrony occurs. EEG is used to measure patterns of brain activity during different behavioral states and is used in both research and in the diagnosis of various neurological conditions such as sleep disorders and epilepsy.
Though EEG is used to measure brain rhythms, the function of these rhythms is unknown, but they have been correlated to different behavioral states such as wakefulness, sleep, attentiveness, and various pathologies. Brain rhythms generated through synchronous neuron activity can be created through two different mechanisms.

Cells within the thalamus have been demonstrated to have pacemaker properties that allow it to generate rhythmical cortical activity.
Collections of cells can also generate intrinsic rhythms through their collective activity.
Each night when we go to sleep, our brains undergo a very stereotyped pattern of activity changes. At times, neurons in the cortex exhibit synchronized patterns of firing. And at other times, cortical activity looks very similar to an awake brain. We can divide sleep roughly into two different phases depending on one of the first physiological measures that sleep scientists studied: eye movement. A study published in 1953 used a device to detect eye movement while a person was asleep. Interestingly, they noticed that at some points in the night, usually first occurring around three hours after falling asleep, the patient’s eyes would dart rapidly and jerkily back and forth, a pattern of activity that the University of Chicago researchers called rapid eye movement (REM). This first period of REM activity lasted for about 20 minutes, after which the eyes would stop moving again. This activity pattern repeated every hour or two for the rest of the night. They used eye movement to separate sleep into two phases: REM sleep, and nonREM sleep (NREM sleep).

In addition to eye movement, they observed and measured other physiological behaviors. Respiration rate and heart rate both increased during the REM phase of sleep and dipped during NREM sleep. They also (rudely) woke up patients throughout the two phases of sleep and found that patients were more likely to recall dreams with visual imagery if their REM sleep was interrupted. Those woken during NREM sleep were less likely to recall dreams, hinting that dreaming is more likely to happen during REM sleep. While eye movement could differentiate between two phases of sleep, EEG could further subdivide NREM sleep. Using EEG, scientists discovered three distinct NREM phases based on neuron activity patterns: NREM1, NREM2, and NREM3 sleep.

Currently, readings collected via EEG are considered to be the gold standard for measuring the stages of sleep. But before we describe EEG traces while asleep, we should describe the EEG of a person who is awake. Usually, the awake EEG is dominated by high-frequency waves that increase with attention and mental activity.

NREM1 is the earliest stage of sleep. It’s also described as relaxed wakefulness, drowsiness, or light sleep. During NREM1, mostly alpha waves are present and a person’s muscles are still somewhat active. Their eyelids may open and close every so often, and they may still respond to questions. Basically, the deeper into NREM1 sleep a person becomes, more waves with lower and lower frequencies start to emerge. NREM1 transitions into NREM2, which mostly has theta waves.

Lastly, NREM3 occurs, which is also called deep sleep. At this phase of the night, a person’s physiological activity drops to its lowest point of the night: heart rate, respiration, blood pressure, and metabolism all reach minimum during NREM3. In this stage of sleep, many of the cortical neurons fire in synchronicity with one another, and the subsequent change in potentials cause large amplitude deflections in the EEG, called delta waves.

The EEG trace of a person in REM sleep is quite the opposite of what is seen in deep sleep. Instead of large amplitude events at a low frequency, the REM brain has a lot of low amplitude events at a high frequency. In fact, the brain in REM sleep has a pattern of activity that is more similar to a person who is awake than asleep! Because of this asynchronous firing activity, REM sleep is sometimes also called paradoxical sleep.
To illustrate the stages of sleep that a person experiences each night, we can use a hypnogram. These charts plot time on the x-axis and stage of sleep on the y-axis. Awake is represented at the top, and deep sleep is at the bottom. For an average night’s rest, neural activity will fluctuate through the four phases relatively predictably. When a person first falls asleep, they will move from NREM1 down through NREM2 then NREM3, before coming back out of deep sleep progressively back to NREM1. After NREM1, they may enter REM sleep before transitioning back through the stages to NREM3 again. This cycle of activity repeats roughly every one and a half hours. People spend a larger percentage of each cycle in deep sleep and very little time in REM sleep early in the night. On the other hand, in the last few cycles before waking up from a full night’s rest, people spend a larger percentage of each cycle in REM sleep, and almost no time in deep sleep.
All organisms that we know of experience some type of sleep. But we still haven’t figured out exactly why animals sleep. Here, we will discuss three theories that have been proposed to explain sleep. None of these theories alone fully explains the complex phenomenon of sleep, and they are not mutually exclusive. The most likely reason we sleep is probably some combination of the following three theories.
The recuperation theory of sleep is centered around the idea that being awake is stressful and exerts a physically demanding toll on the body. The body therefore needs a period of time when energy usage decreases and the body’s natural repair systems can work without disruption. Sleep is how the body “wipes the slate clean” and resets. Evidence for the recuperation theory comes from experiments tailored around the idea of looking at what happens when a person doesn’t get sufficient sleep.

As anyone who has ever pulled an all-nighter can attest, a single night of sleep deprivation often leads to significant psychological changes, including anxiety, irritability, and mood swings. Staying awake even longer than 24 hours can cause more severe changes in mind state, such as temporary psychosis, hallucinations, or delusions.

While the support for the recuperation theory is generally true for almost all people, there are about 1% of people who seemingly gain the restorative benefits of sleep, even with fewer than 6 hours of sleep each night. They may wake up at 4:30 in the morning feeling completely refreshed. And yet, despite getting so little sleep, these short sleepers have similar health outcomes with respect to body mass index and psychiatric measures such as depression and overall optimism. Something about the circadian rhythms of these short sleepers allows them to “maximize” their sleep efficiency. Many have very short sleep latencies, meaning they fall asleep within minutes after lying down—as quickly as someone with narcolepsy. They also spend a larger percentage of their night in deep sleep and REM sleep while minimizing NREM1 and NREM2.
The evolutionary adaptation theory is the idea that animal sleep patterns are different across species for reasons that most efficiently benefit each animal. Over millions of years of evolution, individuals with the most ideal sleep patterns have an advantage, and their sleep habits will be selected for in the following generation. For example, consider humans. As an animal highly dependent on light and the visual system for navigation and accurate performance of tasks, the dark is a very dangerous time to be active. The risks of wandering off a cliff, running head-first into a tree while escaping a predator, or eating a wrong-colored poisonous berry would all be elevated in the dark. We benefit from behaviors that minimize those risks, such as inactivity until the sun rises. During this inactive period, sleeping decreases our metabolism and our body’s need for energy.

Humans are just one animal that has an evolutionarily fine-tuned sleep pattern. If you look across the animal kingdom, you’ll find all varieties of sleep behaviors that are best fitted to the needs of the individual species. In the wild, for example, dolphins are generally prey. They evolved with the ability to put one half of their brain to “sleep” at a time, allowing the “awake” half to keep an eye out for potential predators. Small prey animals, like squirrels, are faced with the threat of being attacked at night. For them, remaining very still, quiet, and hidden improves their survival. Tigers, the top alpha predators in any ecological niche, have almost no predators to hide from, allowing them the luxury of sleeping up to 20 hours a day.

This evolutionary adaptation theory argument has a major weakness, however. In almost all animals, sleep represents a period of time when an organism’s ability to use their sensory organs to detect the hallmark signs of an approaching predator, like the flurry of feathers from a hungry owl or the soft padding of a wolf footsteps, decreases drastically. For an animal that can’t hide very effectively, sleep represents a period of vulnerability, as they would be unable to sense incoming threats.
The brain plasticity theory suggests that the brain needs some period of time for critical changes to occur. During sleep, circuits in the brain undergo consolidation processes that are important for memory formation. For example, academic performance and examination grades worsen as a person’s nightly sleep decreases. Both the REM and NREM3 phases of sleep are important for different types of memories and studies suggest that declarative memory, pieces of information about facts, benefits more from slow-wave sleep while procedural memory, the learning of motor skills, is enhanced by REM sleep.

Although the exact mechanisms about how sleep improves memory are unknown, we theorize that brain activity during sleep helps move memories held in “temporary” areas into areas of stable, long-term storage. The evidence in support of this theory starts with looking at the brains of newborns. When you were first born, during those first few weeks of life, you slept close to nearly 70% of the day, almost 17 hours! At this point in your life, your brain starts to experience all sorts of new sensations: your eyes detect visible light for the first time, the skin feels the air blow past it, and the ears sense new frequencies and combinations of sound waves. As a result of these stimuli, scientists hypothesize that your brain undergoes as many learning events as rapidly as possible. This rapid learning helps you remember what you learned each day so you can respond to your environment as you grow up.
Almost everyone has experienced difficulty sleeping at some point in their lives, often as a result of stress or anxiety. For example, it might be difficult to fall asleep the night before a big interview, or you may wake periodically in the hours before an important early morning flight. There is no strict definition for insomnia. The major clinical symptoms are self-reported measures, such as a dissatisfaction with nightly sleep or a change in daytime behavior, such as sleepiness, difficulty concentrating, or altered mood states. The lack of clear diagnostic criteria makes estimating prevalence difficult, but some guesses put the number of people with insomnia close to one third of the US population. Common triggers for insomnia include heightened anxiety, stress, or advanced age. It may also be downstream of other diseases, such as Parkinson’s disease, diabetes, depression, or chronic pain conditions. Lifestyle can also be a major risk factor for insomnia, as jet lag and working late-night shifts can disrupt sleep patterns.

We can describe insomnia as acting at two stages. Onset insomnia is defined as a difficulty with initially falling asleep. People with onset insomnia will frequently lie in bed for a long time before finally drifting off. Maintenance insomnia, however, is a difficulty with remaining asleep. People with maintenance insomnia experience many waking events throughout the middle of the night, or they may wake up very early in the morning and be unable to get back to sleep. The two are not exclusive, and people may experience both forms of insomnia in a single night.

The most effective treatments for insomnia begin at the level of behavioral changes. Improving sleep habits, such as minimizing arousal states before bedtime, developing a reliable pattern of sleep-wake timing, eliminating caffeine intake in the afternoon and evening, and increasing daytime physical activity can decrease insomnia. Prescription medications are less preferred for insomnia treatment, since these drugs are more effective at inducing unconsciousness rather than biological sleep. These drugs can also have adverse psychological side effects such as mood swings and depression, and those adverse effects may be more severe than insomnia itself. Prolonged use of prescription sleep medications can lead to a “rebound effect”, causing a person to experience even worse insomnia when they are unable to get sleep drugs. This is called iatrogenic insomnia, and can lead to a cycle of dependence.
Unlike the previous two sleep disorders, which result in a deficit of sleep, narcolepsy can be thought of as an “excess” of sleep. More accurately, narcolepsy is inappropriate sleep, and it manifests as frequent sleep attacks throughout the day, each event lasting for seconds or minutes at a time. An estimated 1 in 2000 people experience narcolepsy. One of the life-threatening symptoms that appears in narcolepsy is cataplexy, which is the sudden weakening of muscle tone that accompanies a sleep attack. A cataplectic attack may cause someone to physically fall over during a narcoleptic incident. Cataplexy often happens during high emotional states, such as excitement. As with other sleep disorders, changes in lifestyle can improve the course of narcolepsy. Introducing short daily naps can be helpful, as can general good sleep habits (minimal digital device usage before sleep, regular sleep-wake timing, and physical activity). Drugs such as amphetamines (Modafinil) can be used in the daytime to stimulate activity in the CNS and can be prescribed to treat severe cases of narcolepsy. Some antidepressant drugs can be used to treat cataplexy.

The exact cause of narcolepsy has not yet been identified. However, there are many clues that point to a dysregulation of the signaling molecule orexin produced by cells in the lateral hypothalamus. These neurons die off in people with narcolepsy, but the cause of why the neurons die is unknown. Also, having a genetic predisposition to narcolepsy does not guarantee that a person will experience the symptoms, indicating that there is some combination of genetic and environmental factors that lead to narcolepsy.
While many cases of sleeplessness last a day or two, and some cases are clinically significant and treatable with behavioral changes, a very small fraction of cases of insomnia are incurable and deadly. In people with fatal familial insomnia (FFI), they experience severe insomnia. Some patients stay awake for up to six months at a time. As a result of either the disease or the sleep deprivation, they experience altered mood states, hallucinations, dementia, and eventually death, usually within two years after a diagnosis is made. The cause of FFI is unknown. There is a strong genetic component associated with it, as it appears frequently within certain family trees. But, there have also been a few cases of sporadic FFI, people with no apparent family members with the disease. One observation in common among people with FFI is significant damage to the thalamus, as a result of misshapen proteins called prions, a similar disease-causing agent that is responsible for mad cow disease.
One very rare sleep disorder called REM sleep behavior disorder (RBD) can cause people to carry out complex, highly coordinated motor actions while they are sleeping, sometimes acting out their dreams as if they were reality. People with RBD are at risk of injuring themselves or others. Their sleep actions may be in response to a violent nightmare, causing them to jump out of bed, kick or punch the air, run through the house, or throw things. One of the most shocking instances of parasomnia-induced sleepwalking was the 1987 case of Kenneth James Parks, a Canadian man who, in his sleep, drove 23 km to the house of his in-laws and stabbed both of them with a kitchen knife. After his arrest, scientists discovered that his brain activity was highly abnormal during sleep. As a result of the medical examination, the Supreme Court of Canada acquitted him of murder in 1992.
Almost every living organism that we know of on Earth exhibits some sort of cyclic pattern of activity that closely matches the rising and setting of the sun.
Our sleep and wake cycles are associated with the day/night cycle. Previously, we discussed the retinal ganglion cells that transmit signals from the rods and cones of the retina into the brain for processing within the lateral geniculate nucleus and primary visual cortex. A separate population of retinal ganglion cells do not process signals from the rods and cones, but rather serve as photoreceptors and are directly sensitive to light, communicating whether or not it is daytime.

These cells send their axonal projections separately from the optic nerve that sends most visual information. Rather, they project through a pathway called the retinohypothalamic tract, synapsing on a clump of cells in the hypothalamus called the suprachiasmatic nucleus (SCN). In turn, these cells of the SCN have projections to a gland in the brain called the pineal gland, so named for its pinecone-like shape. The pineal gland converts the amino acid tryptophan into melatonin, an endogenous hormone, which is then secreted into the bloodstream. Melatonin helps the brain regulate the sleep-wake cycle with increased melatonin levels helping to signal the body to prepare for sleep.

The production of melatonin is heavily dependent on exposure to sunlight. In the daytime, the SCN tonically inhibits activity of the pineal gland, resulting in low production of melatonin. But when daylight starts to decrease, the retinohypothalamic tract sends a weaker excitatory signal onto the SCN, which allows increased pineal gland activity. Light exposure is the main environmental influence that decreases melatonin levels.
Not all wavelengths of light are equally potent at dampening melatonin production. The shorter wavelengths of light, down in the violet-blue range, are much more efficient at activating the retinohypothalamic tract compared to longer, yellow-red wavelengths. Increased retinohypothalamic tract activation leads to decreased melatonin production, which can delay the onset of sleep. Fluorescent or LED lighting and digital devices, such as computer screens and cell phone screens, use blue wavelengths of light. Therefore, the best advice to optimize your sleep habits is to eliminate exposure to all digital devices about one hour before your intended bedtime.
The discovery of 24-hour patterns of behaviors began in 1729 with the French scientist Jean-Jacque d’Ortous de Mairan, who documented the movement of the Mimosa pudica plant. This unique organism was chosen since the plant exhibits heliotropism, light-seeking movements. In particular, this plant opened up the leaves in the daytime to capture sunlight, then closed at night, minimizing predation. When the plants were put into a dark room with no exposure to sunlight, to his surprise they still opened and closed their leaves in time with the clock. Mairan concluded that the plant did not change its behavior in response to light, but rather in response to some internal 24-hour clock. His work laid the foundations for future chronobiologists, scientists who study day-night dependent periodic phenomena in living beings.
Any behavior or physiological measure that intrinsically cycles on a 24-hour pattern is said to be a circadian rhythm. The word circadian comes from the Latin words ‘circa’ meaning “around”, and ‘diem’ meaning “day”. Compare this with an ultradian rhythm, any cycle that is faster than 24 hours, such as the cycling between deep sleep and REM sleep every 90 minutes. Alternatively, compare with infradian rhythms, patterns that are longer than 24 hours, like the 4-week-long human menstrual cycle.

Although we mostly think of the circadian rhythm in the context of sleep and wake, many other physiological measures fluctuate reliably throughout the day. Body temperature dips late in the evening, putting the body into a low-energy state that helps promote sleep. Withdrawal reflexes peak around midnight, hunger-driving hormone production rises before lunch and dinner, attention is usually highest in the morning—all manner of behaviors that rise and fall depending on the time of day can be said to be a part of a circadian rhythm.
Luckily, a person’s circadian rhythm is not permanent. Anyone who has traveled overseas to a different time zone for more than a few days has experienced that uncomfortable sensation called jet lag, where a person experiences psychological symptoms such as difficulty concentrating and mood swings, and physical symptoms like daytime fatigue, insomnia, and gastrointestinal distress (nausea, constipation, or diarrhea). Jet lag happens when there’s a mismatch between the internal environment and the signals that the brain receives from the outside world.

If you flew east from Chicago to Cairo, for example, your circadian clock will be off by 7 hours. When your internal “Chicago” clock is telling you to start getting sleepy around 11 PM, the sun will be rising in Cairo, as the locals are starting to wake up. You may be eating when you’re not hungry or laying down in bed when you’re not sleepy, and this mismatch contributes to jet lag. However, with a few days of adjustment, you will be able to overcome jet lag. You will start sleeping as the sun sets, you will get hungry at the same time as the Egyptians, and your physiological measures will start to align with your time zone.

This adjustment is only possible because our circadian rhythms are entrainable, meaning they are able to change and fit the surroundings. Our circadian rhythms entrain in response to zeitgebers, the German word for “time givers”: environmental cues, such as increased light exposure when the sun comes up, or social cues, such as increased sensory input from heightened activity of the people around you. A rise in the neurohormone melatonin is an important signal that contributes to helping the brain entrain, which is why taking a melatonin supplement late at night when in a new time zone may help someone get over jet lag more quickly.
If sunlight is a trigger that helps a person entrain their circadian rhythm to new environments, what would happen if a person is completely isolated from sunlight? In other words, what does a free-running circadian rhythm look like? One of the early documented case studies addressing this curiosity was conducted by a French cave explorer named Michel Siffre. In 1972, Siffre (voluntarily) spent six months deep in a Texan cave to evaluate what would happen to a person completely isolated from zeitgebers. At the end of the experiment, he found his circadian cycle was much longer than 24 hours, and very unpredictable—some of his so-called days would consist of being awake for 36 hours and asleep for 12.

A more rigorous scientific study, conducted in a group of people living in an underground bunker with unchanging lighting conditions for several days estimates the typical free-running circadian cycle to be close to 26 hours. In other words, a person absent from external cues begin to fall asleep and awaken 2 hours later each day. Free-running circadian disruption is a potential issue for scientists aboard the International Space Station, who experience about 16 sunsets and sunrises per day, since the orbiting space vessel completes one trip around the earth every 90 minutes. In order to minimize the negative effects of jet lag on the researchers aboard, NASA has the inside of the vessel set to an artificial 24-hour cycle. Bright blue LEDs illuminate the cockpit in the “daytime,” while dim, red-shifted wavelengths are used in the evening to induce sleepiness.
At the airport, you can observe people experiencing a wide range of emotions: Sadness at seeing family members off, fear and anxiety for those about to fly for the first time, love when a long-distance relationship is reunited, and anger over unpredictable cancellations. Emotions are complex neurophysiological states that contribute to an internal feeling and guide behavior. Some emotions are pleasant (joy), some are negative (disgust), and some are a mix of both (nostalgia). Some are short-lasting (surprise) while others may persist over years (vengefulness). However, beyond this statement, it becomes very difficult to put a clear-cut definition on “emotion”. The difficulty with defining emotion arises because of the fluid nature of emotions: they exist on a spectrum, multiple emotions are experienced simultaneously, each emotion is perceived by different people in unique ways, and everyone has a slightly different interpretation and understanding of an emotion.

The field of affective neuroscience seeks to understand the neural mechanisms that underlie emotion. The field has expanded with the help of functional imaging methods like EEG and fMRI, where changes in brain activity can be measured and quantified as a person experiences different emotion-provoking stimuli. Affective neuroscientists work to develop biology supported therapies for disorders such as depression, PTSD, and addiction, which are dysregulations of the emotions of sadness, fear, and desire, respectively.
Although best known for his theory on evolution, naturalist Charles Darwin published prolifically about other topics in biology, ranging from botany, coral reefs, and even a treatise on psychology. In this 1872 text, called The Expression of Emotions in Man and Animals, Darwin suggested that similar emotional responding is found across different cultures, and to some extent, even in nonhumans. In his view, the main purpose of emotive expression is to communicate survival cues between individuals: a relaxed expression conveys safety, while a fearful expression promotes alertness, since danger may be nearby. Darwin also suggested that we gain survival information from non-human behaviors, for example, a hissing snake or a snarling lion is an immediate threat that should cause fear or other avoidance behaviors.
Moving forward into more modern times, the American psychologist Paul Ekman expanded on Darwin’s theory, distilling down the range of human emotions to belonging in one of seven basic categories of emotions: anger, contempt, disgust, fear, happiness, sadness, and surprise. If the purpose of emotion was to communicate pro-survival cues, then Ekman theorized that all humans, regardless of culture, would use similar facial expressions.

To test this hypothesis, Ekman visited a remote village in Papua New Guinea, where he studied a population that is isolated from any other known cultures. As predicted, these people made the same facial responses in reaction to various emotional circumstances. In 1972, Ekman published his theory of universal facial expressions.

Part of Ekman’s research led their team to develop a series of photographs of actors portraying six major emotions. This Ekman 60 faces (EK-60F) test has since been used to assess facial emotions with fascinating results: People with major depressive disorder or borderline personality disorder have a lessened ability to detect happiness in others, seeing emotional faces results in a similar emotion in the viewer, and people with dementia or Parkinson’s disease identify emotions as being less intense. Ekman’s research led them to develop the Facial Action Coding System (FACS), a system that uses facial anatomy to differentiate the features that are characteristic of different expressions. For example, a feature of a happy face is the flexing of the zygomaticus major and orbicularis oculi muscles, which produces an upward turn of the corners of the mouth and a rising of the cheeks. Other facial features, such as head movement, eye movement, and larger physical movements are also scored, and are also used to help identify emotions. The FACS can be used to formally describe why some smiles appear as genuine (a Duchenne smile, with simultaneous muscle action) while others look fake or forced (a non-Duchenne smile, characterized by the turn of the corners of the mouth without much change to the top part of the face).
One of the older theories about the origin of emotion is based on the most common sense interpretation of cause and effect. For example, imagine some noticeable emotional stimulus, such as encountering a hungry lion on the sidewalk. The logical cause and effect explanation suggests that seeing the lion prompts the emotion of fear, which then causes the sympathetic nervous system “fight-or-flight” response (elevated heart rate and blood pressure, increased respiration, and cellular mobilization of energy). In the 1880s, psychologist William James and physician Carl Lange independently developed a new theory about the origin of emotion. According to the James-Lange theory of emotion, and contrary to a common sense understanding of the origin of emotion, the body’s physiological changes precede the onset of an emotional response. For example, imagine encountering that same hungry lion on the sidewalk. The James-Lange theory tells us that the perception of the threat of being eaten causes the sympathetic nervous system response, and that these physiological changes trigger the onset of fear.

Soon after, in the 1920s and 1930s, two physiologists named Walter Cannon and his doctoral student Philip Bard criticized the James Lange theory. In one experiment, they surgically removed the entire sympathetic nervous system from cats, destroying the nerves that regulate vascular dilation, the activity of liver enzymes, and the reaction that causes the hair standing on end. These cats were then put before a threatening aggressor. If the James-Lange theory was true, then the physiological changes should precede the emotive response. However, the cats exhibited the fear / aggression response (such as posturing, hissing, and clawing) even without an intact sympathetic nervous system. Relatedly, patients with spinal cord injuries have a similar lack of autonomic inputs to the brain, but their capacity for emotional responding is still intact.

In a second criticism, Cannon and Bard proposed that the physiological changes seen in sympathetic nervous system activity may arise for a variety of reasons, not always for emotionally salient reasons. For example, intense exercise causes strong cardiorespiratory changes; however, we do not necessarily feel a strong emotional state after this physiological perturbation. Likewise, exogenous administration of epinephrine, onset of fever, or being in cold temperatures may also trigger some physiological changes without causing a strong emotional response. Based on their evidence opposing the James-Lange theory, Cannon and Bard developed an alternative explanation for the origin of emotions. According to the Cannon-Bard theory of emotion, the perception of an emotionally charged stimulus prompts simultaneous but independent activation of both the autonomic nervous system and the emotional response. The Cannon-Bard theory also draws attention to the neuroanatomical structures that trigger the autonomic and emotional responses, with a particular focus on diencephalon structures such as hypothalamus and thalamus.
Just years later, in 1937, American neuroanatomist James Papez (pronounced payps) ascribed emotional behavior to a particular series of brain structures. These structures, collectively called the Papez circuit, consist of the hypothalamus, cingulate gyrus, thalamus, hippocampus, and more. The model that Papez developed started with a stimulus that activates the thalamus, which in turn activates a loop of activity between the hippocampus, hypothalamus, thalamus and cortex to produce both a physiological response and emotional feelings.
Papez observed unusual aggression among animals with injury to these structures, suggesting that emotional responding is distributed across many areas, rather than localized. (Notably missing from the Papez circuit structures is the amygdala, which was later added in a future revision in the 1950’s.)
Emotions are one of the most holistic functions of the brain, incorporating neural circuitry from across several different structures, ranging from the phylogenetically older to the most advanced frontal cortical areas. The structures of the Papez circuit are not a comprehensive list of brain structures involved in emotional processing but offer a good starting place for describing the anatomy of emotion.
A limbic structure called the amygdala contributes heavily to processing the valence of emotional experiences. Roughly the shape and size of an almond, the amygdala is part of the temporal lobe. Generally, the amygdala is subdivided into several nuclei, including the basolateral amygdala, central nucleus, and cortical nucleus. As a temporal lobe structure, the amygdala is strongly implicated in emotional memory formation. Emotional memories can be either positive valence (such as the happiness you may have experienced at a birthday party when younger) or negative valence (such as childhood trauma or being teased as a child).
Of the forms of declarative memory, autobiographical memories more often have emotional content compared to semantic memories. Amygdala lesions have been used as a last resort treatment for patients with temporal lobe epilepsy or psychiatric conditions with pathological and dangerous aggressiveness. These psychosurgery strategies have been variably successful, but they often have high complication rates and upwards of a 4% mortality rate. These treatments are rarely used today.
One of the major output signaling pathways of the amygdala is the hypothalamus, found at the base of the brain. The hypothalamus is often seen as the neural structure that initiates endocrine responses in the rest of the body, such as hormone production. Several different behaviors, ranging from homeostasis, hunger, and circadian regulation are modulated by hypothalamic signals.
Downstream from the hypothalamus is the pituitary gland, a pea-sized endocrine organ that protrudes from the base of the brain. It is strongly involved in the production and release of neurohormones, signaling molecules produced by nerve cells that travel throughout the bloodstream to influence the activity of several organs throughout the entire body. Recall that the pituitary gland is subdivided into two regions with distinct anatomical and functional differences. Hypothalamic magnocelluar neurons produce the neurohormones oxytocin and vasopressin. The axons of these neurons project to the posterior pituitary gland, which then releases these hormones into the bloodstream.
Oxytocin plays a significant role in the development and maintenance of prosocial behaviors, acts such as trust, compassion, and empathy—all actions that enhance interpersonal relationships. Interestingly, while oxytocin generally strengthens the social bonds between people, it promotes antisocial behaviors against those not perceived to be within one’s own social group. Disorders of the oxytocin system are believed to contribute to autism spectrum disorder and psychopathy, two complex conditions characterized partly by social impairment. Some studies have examined the therapeutic use of nasal oxytocin for a variety of psychiatric conditions, but the studies have been unable to demonstrate strong clinical effects despite success in nonhuman animal models.
The insula (or insular cortex) is the lobe of the cortex buried deep within the lateral fissure. Although not visible from a side view, the insula is often considered to be the fifth lobe of the telencephalon. Early studies by Wilder Penfield where he directly stimulated the brain during open brain surgery led researchers to suggest that the insula contributes to interoception, detecting the internal state of the body and conveying that information for processing.
In functional imaging studies, the insula is involved in the recall or many different emotional stimuli, especially those emotions that have a sensory component. Notably, the insula is strongly implicated in the emotion disgust. For example, a patient is placed in an fMRI scanner while breathing through a mask, which allows the experimenters to change the smells that are perceived. Patients are then given pleasant smells (such as passion fruit, pear, or mint), a neutral smell, or unpleasant smells (like ethyl-mercaptan or isovaleric acid, which smells like skunk or body odor, respectively). There is increased activity of the anterior insula in response to the unpleasant smells but not the pleasant smells.

The insula also responds to social cues related to disgust as well. When a patient in an fMRI sees a video of a person smelling something unpleasant and reacting with a “repulsed” face (the closing of the nostrils and curling of the upper lip), their anterior insula likewise increases in activity just as if they had smelled it themselves. In addition to sensory stimuli, feelings of social repugnance (unwarranted violence, murder) or moral disgust (incest) also increase insula activity. Atypical insula activity is implicated in behavioral disorders. For example, insensitivity to disgust can lead to squalor-dwelling conditions (sometimes seen in excessive hoarding or late cognitive decline), which puts those people at heightened health risks due to regular exposure to unsanitary conditions. Substance use disorders, PTSD, and suicide attempts have all been associated with atypical insula activity.
Nearly everyone has experienced the prototypical fear response: Imagine reading a book when you see a spider skittering along the wall. Suddenly, you’ll feel your heart racing, your breathing increase, dryness of your mouth, and your palms sweating. You probably won’t notice the dilation of your pupils or the change in liver activity and digestion. This sympathetic nervous system activity is downstream of being presented with a fearful stimulus. But upon closer inspection, it was no spider at all—just an errant piece of brown fuzz picked up by a draft. Within minutes, your body’s physiology returns back to normal.

This anecdote points out a few important features about the fear response. First, the onset of the fear response is quick, and so is the dissipation of the fear. Second, it is triggered by exposure to a perceived threat, regardless of whether the stimulus is a genuine threat or not (the overwhelming majority of spiders are clinically harmless to humans!). Third, the fear response is greatly modified by knowledge and experience—an entomologist would recognize that the spider is a harmless house spider and would, instead of fear, display curiosity, interest, boredom, or other emotions. On the other hand, someone who has been bitten by a dangerous spider and sent to the hospital when younger would have a much stronger physiological response.

Fear is likely the most evolutionarily ancient emotion, and is highly protective. When encountering a hungry mountain lion, faces displaying the traits of fear (enlarged eyes, flared nostrils, and a slightly open mouth accompanying a gasp) would signal to others nearby that a threat is nearby, which helps initiate heightened alertness and the appropriate fight-or-flight response.
In 1939, two researchers named Heinrich Klüver and Paul Bucy described a unique set of emotional deficits in monkeys with bilateral temporal lobe removal, including removal of the, further providing evidence of the neuroanatomy of emotion. Most notably, the monkeys failed to display fear, including their facial expressions and vocalizations even in the face of life-threatening stimuli such as a large snake. Further, they also had decreased anger or aggression. They also display visual agnosia (the inability to recognize faces or objects visually), psychic blindness, hypersexuality, and hyperorality (an inappropriate fixation with using the mouth to interact with surroundings, such as licking or eating nonfoods). Collectively, these sets of symptoms are called Klüver-Bucy syndrome.

Although it is primarily an experimental manipulation observed in monkeys, some human patients may develop the condition, such in after brain surgery, stroke, viral encephalitis, traumatic brain injury, and many others. In addition to the symptoms described in Klüver-Bucy Syndrome, humans also display “flattened” emotions. The lesioning of the amygdala clearly results in decreased expression of fear. Stimulation of the amygdala, however, causes in increase in anxious, fearful, and aggressive responses in humans and other animals, such as piloerection in cats. In fact, amygdala activity is increased when shown images of fearful faces, but not neutral or happy faces when measured with fMRI.
Patient SM is a notable case study of a person who does not experience the fear response. Born with an extremely rare genetic condition called Urbach-Wiethe disease, Patient SM progressively developed calcification in her amygdala bilaterally, causing destruction and cell death. Like other people with Urbach-Wiethe disease, she had no severe significant cognitive deficits, except for the inability to experience fear.

In one test, she was shown a variety of emotionally charged videos, then asked to rate the intensity of each clip with respect to different emotions. SM found clips from America’s Funniest Home Videos to be just as funny as the control patients, and she found the clips of disgusting toilets to be just as repulsive. But, when presented with clips depicting ghost hauntings or suspenseful serial killers on the loose, SM rated these stimuli as being non fearful.

Other studies challenged Patient SM with more concrete threats. Researchers brought SM to a pet store, where she asked to handle the snakes. She was stopped by an employee before she put her hand into a tarantula cage out of curiosity. The researchers also took her to the Waverly Hills Sanatorium haunted house, where she bravely led a group of strangers through the house populated by actors dressed as monsters and ghosts. Although she did not display any fearful behaviors, such as hesitation to walk through the darkened corridors, patient SM reported the sensation of exhilaration and enthusiasm, akin to riding a roller coaster. She also was asked to recall some of her past real-life, fear-provoking experiences, such as when she was attacked in a domestic violence incident or was held up by a stranger at knife point in a public park. In none of these cases did she ever report feeling fear, although she was upset and angered at the situation. The destruction of her amygdala seemed to make her resilient against PTSD: the day after being threatened with a knife to her throat, she walked past the very same park bench.
Scientists have long realized there are at least two distinct types of fear:

Innate fear in which subjects avoid certain stimuli such as snakes or spiders even though they may never have seen them before
Learned fear in which a stimulus or situation causes arousal or anxiety because it has been associated with a painful or negative experience in the past
There are two important protocols used to examine learned fear: fear conditioning and conditioned defeat.
One of the best studied laboratory models of fear comes from the work of Joseph LeDoux who studied the brain circuit that mediates learned or conditioned fear in laboratory rats. In these studies, LeDoux used a classical conditioning procedure to induce what he called “conditioned fear”. In classical conditioning (think Pavlov’s dogs), a neutral stimulus that normally would not cause any physiological response (called a conditioned stimulus, e.g., a ringing bell) is paired with a meaningful stimulus (called an unconditioned stimulus, e.g., the presence of food) that elicits a behavioral response (unconditioned response, e.g., drooling). Eventually, the behavior (drooling) occurs in response to the conditioned stimulus (bell) alone.

Instead of pairing the conditioned stimulus with a positive unconditioned stimulus like food, LeDoux paired the conditioned stimulus with an electrical shock. After pairing the shock to the stimulus multiple times, the animals responded to the conditioned stimulus alone (no shock) in the same way they did to the electrical shock alone. This is referred to as the conditioned emotional response.
In this model the experimental subject (the animal whose behavior is being examined) is placed in the home cage of a larger, resident animal. This typically results in aggressive behaviors displayed by the resident animal toward the experimental subject. The resident animal will usually win the encounter because it is larger and in its own territory. The experimental animals will show submissive and defensive posturing and does not attack or threaten its opponent.

Experiencing this defeat has major long-lasting effects on the experimental subject. Following defeat, the animal rarely shows aggression even to non-aggressive animals placed in the subject’s home cage (an intruder would typically cause aggression). Because this paradigm has parallels with the earlier fear conditioning studies that paired an acoustical tone with electrical shock to the feet, it is often referred to as “conditioned defeat;” the experimental subject has been conditioned to respond to all other animals with submissive defensive postures.
Fear and anger are two very closely related emotions. As with many other emotions, anger manifests in complex ways. The anger spectrum runs from low (irritation) to high (rage), and from quick (lashing out) to persistent (vengeful). Anger can manifest behaviorally as aggression, though clearly in humans we can feel angry without showing signs of aggression. In animal models, however, we can only judge anger through their display of aggressive behaviors.

Aggression is affected by circulating levels of androgens, as castration (removal of the testes) can reduce aggressive behavior. As with fear, amygdala activation is also related to aggressive displays, as bilateral removal of the amygdala causes animals to be less aggressive and more docile. A type of psychosurgery, amygdalectomy (bilateral surgical lesioning of the amygdala), can cause a “taming” effect in humans, and is still performed today, though rarely.

In addition to amygdala circuits, regions in the frontal cortex decrease activity during acts of aggression, suggesting that frontal circuits actively inhibit the limbic system, which drive our more “primitive” responses. Researchers in the 1920s performed a series of lesion experiments, systematically injuring different parts of the brain in cats. To their surprise, when the cortex of the cat was surgically separated from the rest of the nervous system, a procedure called the decorticate preparation, the cats would exhibit a hyper-aggressive response to stimuli. For example, an innocuous touch of the tail would trigger violent clawing, biting, and hissing, behaviors which were described as sham rage. The same sham rage behavior was observed following a decorticate preparation that also included the anterior hypothalamus. However, when the decorticate preparation included both the anterior and poster hypothalamus, sham rage was no longer observed. They concluded that rage (and other powerful emotions) is normally under inhibitory control by the cortex. Altered frontal cortical action may therefore account for one reason why two different people would react to the same anger-provoking stimulus in different ways.

In a separate set of experiments, cats had different areas of their hypothalamus electrically stimulated while being presented with a rat. These experiments indicated that stimulation of different areas of the hypothalamus elicits distinct displays of aggressive behavior. When the medial hypothalamus is electrically stimulated, the cat displays what is caused a “threat attack”. The threat attack includes threatening behaviors such as hissing, but the cat did not attack the rat. If the lateral hypothalamus was electrically stimulated, the cat displayed a “silent-biting attack”. In this case, the cats did not display exaggerated threatening behaviors, but rather the cat would quickly and viciously attack the rat’s neck.
It is likely every reader of this chapter has experienced some form of stress, perhaps due to a big exam, a looming deadline, or an unplanned interaction with a spider. The physical reactions to stress, like increased heart rate and breathing, are a result of brain activation.
Stress is often split into two categories: physical and psychological. Physical stress can be caused by trauma, illness, or injury. Blood loss, dehydration, and allergic reactions are examples of physical stressors. Psychological stress has an emotional and mental component. Fear, anxiety, and grief are examples of psychological stress. The neural circuits involved in responding to the different stressors are overlapping but separate.
The body has two main systems for responding to stress: the autonomic nervous system and the hypothalamic-pituitary-adrenal (HPA) axis. The autonomic nervous system response occurs very quickly because it is synaptic in nature and is responsible for the “fight or flight” response, which stimulates heart rate and breathing and inhibits digestion. The HPA axis is a hormonal response, so it is a slower response relative to the autonomic system. Its downstream effects also promote energy use.
The hypothalamus plays a critical role in stress, activating both the autonomic and hormonal responses. The hypothalamus is a region right above the brainstem on either side of the 3rd ventricle. The hypothalamus manages hormone release in the body and maintains homeostasis; this small structure is critical for numerous functions including hunger and thirst, temperature control, regulation of blood composition, sleep, reproduction, and stress.
Although the hypothalamus directly controls the body’s response to stress, it is influenced by activity in other regions of the brain. When information from the environment is processed, activity is seen in the prefrontal cortex, hippocampus, and amygdala. These regions have direct and indirect connections to the hypothalamus. The prefrontal cortex plays an executive decision-making role, the hippocampus places events in context with previous memories, and the amygdala assesses a wide range of stimuli for their potential ability to cause harm and places an emotional value on them.
The amygdala is located medially in the temporal lobe. The amygdala, which means “almond” in Latin, is responsible for the processing of emotions and consolidating emotional memories. It is especially active during fear learning and evaluates the salience, or importance, of a situation. For instance, when we look at frightened faces, our amygdala is more activated than when we see neutral faces. Conditions such as anxiety, depression, and post-traumatic stress disorder are all linked to amygdala dysfunction.

The amygdala regulates the HPA axis by regulating the activity of the hypothalamus. Specifically, the basolateral amygdala receives sensory information that is related to fear and processes that information within the central nucleus of the amygdala, which then influences activity of the hypothalamus and the stress response.
Just posterior to the amygdala lies the hippocampus. The hippocampus, which means “seahorse” due to the similarity between its shape and the animal, is important in the long-term consolidation of memories, spatial navigation, and associating contextual cues with events and memories. Activity within the hippocampus typically inhibits the HPA axis. When a stressor is encountered, the stressor inhibits the hippocampus, thus disinhibiting the HPA axis and allowing for a stress response.

Stress has been demonstrated to damage the hippocampus in both monkeys and humans, causing a decrease in the size of the hippocampus. This damage may be due to increased glucocorticoid levels from higher than normal activation of the HPA axis. On a cellular level, increased glucocorticoid levels alter the structure of hippocampal neurons in rodents, decreasing dendritic arborizations.
Finally, the prefrontal cortex, which is located in the front of the brain in the frontal lobe, contributes to higher level cognitive functions like planning, critical thinking, understanding the consequences of our behaviors, and is also associated with the inhibition of impulsive behaviors. The prefrontal cortex is one of the last brain regions to fully develop and may not be fully developed until an individual reaches their mid-twenties. Experts think this might explain why teens are more likely than adults to participate in risky behaviors.
When presented with a stressor, our brain activates the hypothalamic-pituitary-adrenal (HPA) axis, which initiates a hormonal response.
The hypothalamus, which sits below the thalamus, integrates information from many regions of the central nervous system and plays a critical role in maintaining homeostasis in the body. The hypothalamus regulates temperature, hunger, thirst, blood volume and pressure, sleep and wakefulness, reproductive functions, and stress and fear responses.
The hypothalamic regulation of the body’s response to stress is managed via hormone release by the pituitary gland. The pituitary gland is located inferior to the hypothalamus. The pituitary is divided into two lobes, the anterior and the posterior pituitary. These regions are responsible for the release of different hormones and are controlled by the hypothalamus in different ways.
The stress response relies on anterior pituitary function. The hypothalamus contains two types of neurons that secrete hormones into the pituitary: parvocellular neurosecretory cells and magnocellular neurosecretory cells. Parvocellular cells are smaller than the magnocellular neurons (parvus means “small” in Latin). In the HPA axis, the parvocellular neurosecretory cells release a hormone called corticotropin-releasing hormone (CRH) into a specialized capillary system that lies between the hypothalamus and the pituitary called the hypophyseal portal circulation. When CRH reaches the anterior pituitary, it causes the endocrine cells of the pituitary to release adrenocorticotropic hormone (ACTH) into the general circulation.
The ACTH travels through the circulatory system and can act on the adrenal cortex, a gland located on top of the kidney. The adrenal cortex releases cortisol, a glucocorticoid hormone, into the blood stream. Cortisol travels throughout the body and has many effects that prepare the body for either fleeing or fighting the stressor. Promotion of energy use (for a quick escape or for defense) occurs through the release of glucose, the sugar the body uses for energy.
Cortisol is a steroid hormone; steroid hormones are synthesized from cholesterol and are able to cross the phospholipid bilayer because they are lipid soluble. Glucocorticoid receptors are located in the cytoplasm of many cell types across the body. The receptors dimerize after cortisol binds, and the dimer moves to the nucleus where it can alter DNA transcription.
Once the stress response has been initiated, and cortisol enters the circulation, cortisol itself is able to act on the hypothalamus and pituitary and inhibit production of CRH and ACTH. This is called a negative feedback loop; the active hormone (cortisol) can shut off its own production. Negative feedback is possible because neurons in the hypothalamus and pituitary express glucocorticoid receptors that are activated by cortisol.
One area of the brain that regulates the HPA axis is the hippocampus. Activity within the hippocampus normally acts to inhibit activity of the HPA axis. Stressors in the environment inhibit activity of the hippocampus, which in turn disinhibits the HPA axis and allows for cortisol levels to increase. The hippocampus also expresses glucocorticoid receptors that bind to circulating cortisol and act to increase hippocampal activity. This in turn increase inhibition of the HPA axis, another example of negative feedback control within the circuit.
While this cortisol response to stress is particularly important in certain situations, like moments of danger, chronic stress is an unhealthy scenario which can put people at risk for heart disease and other illnesses. Chronic stress can cause structural and functional changes, like cell death or alterations in the dendritic arbor, within the cortical regions that play a role in control of the HPA axis and the hippocampus due to long-lasting exposure to cortisol.
The brain can be thought of as a well-oiled machine made up of hundreds of billions of moving parts, all cooperating in tandem for healthy behavior and function. There is redundancy in the way these parts are organized, allowing for occasional mishaps without any significant loss of function. But when these parts interact in unusual or atypical ways, a person may develop some psychiatric disorder. The conditions described in the next three chapters likely involve dysregulations in molecules, cells, or circuits, and are therefore complex.

As far as we know, the likelihood of developing these conditions is not exclusively determined by either genes or influence from the environment. Instead, there is probably some influence from both. That is to say, none of these conditions are 100% penetrant; none of them are dictated exclusively by genetics. Having two parents or an identical twin with the condition may indicate an elevated baseline risk over the population at large, but it is not a guarantee that the disease will manifest. Environmental triggers and other exposures may lead to a sudden onset of the condition; on the other hand, certain factors in the environment may be protective against these diseases.

One of the major challenges with understanding these brain diseases is related to the difficulty of making an accurate diagnosis—as almost everything in biology exists on a spectrum, so do these brain disorders. The symptoms of these disorders frequently overlap, adding another layer of complexity. To help establish a diagnosis, the American Psychiatric Association (APA) has put together a series of criteria for psychiatrists to diagnose these complex conditions. Recall our previous discussion of the Diagnostic and Statistical Manual of Mental Disorders (DSM-5), used for compiling symptoms and diagnostic criteria.

Many of the treatments we currently have for neuropsychiatric disorders aren’t always effective. Our ability to treat these conditions depends on our understanding of the disease. The better we understand the causes of these conditions, the wider variety of new therapies we can test. Therapeutic strategies for these conditions are often first tested using cells and non-human animal models, but these have shortcomings. Most of the time, animal models of disease incompletely mimic the symptoms of the disease. Unfortunately, we don’t have any animal models that reproduce the symptoms of the most complex human conditions—it is almost impossible to create a mouse model of dissociative identity disorder or dyslexia, and even if we could, scientists would struggle to quantify the behaviors that we use as diagnostic criteria, which are too subtle to be observed or quantified in non-humans. And for the animal models that we do have, they are often imperfect or incomplete, modeling only some of the deficits seen in humans. Furthermore, most human diseases have many symptoms, and only a few can be assessed with behavioral tests. We can only study disorders of the brain that have a clearly and easily quantifiable behavioral component.
Anxiety is something that everyone has experienced at many points in their life. An anxious person may experience cardiovascular symptoms such as elevation of blood pressure and heart rate, shortness of breath, profuse sweating, and a state of panic. In many ways, the anxiety response is similar to the fight-or-flight response observed during sympathetic nervous system activity. However, a clinical diagnosis of anxiety is different from the passing anxiety that we all experience. Anxiety disorders are characterized by fear, which is an adaptive response to an external threat or stressor.
Anxiety disorders can be very common, and lifetime prevalence estimates suggest 29% of people could develop clinically significant anxiety over their life span.

There are various anxiety disorders. Some are described below.

Generalized anxiety disorder (GAD). People with GAD experience a constant sensation of being overwhelmed, accompanied by fear and worry. Many times, this worry is not about a single concern, but rather a combination of issues all at once, such as financial issues, relationship issues, uncertainty of the future, and many others. GAD is much more severe and persists longer than the normal worries that affect everyone. In GAD, worry persists for several months and is uncontrollable. There are also associated cognitive symptoms, such as fatigue, irritability, difficulty with concentration, and changes in sleep patterns.
Specific phobias. With specific phobias, a person develops the anxiety-related symptoms (cardiovascular and psychological changes) in response to highly specific stimuli, such as snakes, enclosed spaces, deep ocean, or public speaking. The person with the phobia perceives the stimulus to be a great threat, even though it does not actually pose a genuine threat. Most people with specific phobias will go to great lengths to avoid exposure to their particular phobia trigger. These phobias are often influenced by social and cultural conditions. Developing a specific phobia has a lifetime prevalence of about 7%, but only a very small number of people with specific phobias ever seek treatment for their phobia. Like other forms of anxiety, there is a range of severity of these phobias.
Panic disorder. A person with panic disorder experiences frequent panic attacks, characterized by sudden increases in heart rate, shortness of breath, dizziness, and sudden numbness or tingling (panic attacks can also be seen in specific phobias, but are not observed in GAD.) In panic disorder, these panic attacks may occur independently of external influences.
Agoraphobia. Agoraphobia involves a fear of entrapment or of having no escape. Individuals with agoraphobia may avoid crowds of people, riding elevators or cars, and crossing bridges.
Social phobia. Social phobia is similar to more specific phobias, however, with social phobia there is a specific fear of public speaking or being in social situations.
Obsessive compulsive disorder (OCD). OCD is a common psychiatric condition affecting an estimated 3% of the population, characterized by persistent intrusive thoughts or the need to perform some ritualistic series of actions or motions. OCD exists on a spectrum, and in severe cases, can severely impair the quality of an individual’s life.
Post-traumatic stress disorder (PTSD). Anyone can be diagnosed with PTSD at any point in their lives. Some of the most common events that lead to a PTSD diagnosis include combat experience, physical, emotional, or sexual assault or abuse, accidents, and natural disasters. Women are twice as likely as men to be diagnosed with PTSD. Genetic influence appears to account for approximately 30-40% of risk. The symptoms of PTSD are usually divided into three categories: Re-experiencing, Avoidance, Hyper-arousal. Re-experiencing symptoms arise when stimuli cause PTSD patients to relive their traumatic experience in flashbacks, frightening thoughts, or nightmares. Avoidance symptoms arise when PTSD patients feel lack of emotion, lose interest in activities they once enjoyed, or withdraw from family and friends. These symptoms may be a result of trying to avoid reminders or triggers of the traumatic event. Hyper-arousal symptoms appear as increased anxiety or feeling tense in safe environments. PTSD patients can be easily frightened, may have trouble sleeping, and may have frequent angry outbursts.
The exact cause of anxiety is still unknown. One theory suggests that anxiety is a maladaptive evolutionary response to our modern living conditions. The argument is based on the observation that an anxiety response looks a lot like a mild version of the fight-or-flight, sympathetic nervous system response: both elicit cardiovascular and respiratory changes.

For the majority of the evolutionary history of Homo sapiens, we benefited from the sympathetic nervous system as a reflex to improve the odds of survival in dangerous situations. However, our modern civilized living conditions over the past few centuries have been very tame in comparison to the risks that our earlier ancestors experienced. The relative ease of living has let the main function of the sympathetic nervous system fall into disuse. The theory argues that people experience GAD because a part of them encourages sustained activity in the sympathetic nervous system. Although thought-provoking, this theory can’t be tested experimentally and offers no explanation about a biological mechanism that can help to develop a therapy.
There are various treatments for anxiety disorders.

Psychotherapy utilizes a therapist that performs exposure therapy for the individual  to practice being put in a situation that would normally cause anxiety and a fearful response to learn that the situation is not actually dangerous. This treatment has been demonstrated to be very effective but does take time and can be uncomfortable for the individual receiving the therapy.
Deep brain stimulation is a medical intervention in which a surgeon implants permanently indwelling electrodes directly into brain tissue. These electrodes are controlled by an external battery pack that delivers preprogrammed stimulation protocols. Deep brain stimulation has been approved for treating obsessive compulsive disorder and is being tested as a potential treatment for a number of other disorders.
Psychosurgery involves an operation that uses a stereotaxic frame to make very precise alterations to the brain by cutting connections between brain areas or by selectively lesioning brain areas with the goal of correcting abnormal activity within the brain. Psychosurgery is still performed today, but not very often.
Anxiolytic Drugs. Pharmacologically, there are a wide variety of drugs that can be used to treat anxiety, broadly called anxiolytics. The first-line therapies are usually selective serotonin reuptake inhibitors (SSRIs), the same class of compounds that are used in depression treatment. Other anxiolytics, such as the benzodiazepines alprazolam or clonazepam, act as positive allosteric modulators which increases the effect of the GABA system. Benzodiazepines are not always preferred since they may have abuse potential and can be addictive. Opioids and norepinephrine inhibitors can also decrease anxiety.
When treating individuals for anxiety using drugs, the placebo effect is especially strong in those with anxiety disorders. A placebo is an inactive substance that is not made to serve as a treatment, such as a sugar pill. The placebo effect is a real response (can be either negative or positive) that an individual has to receiving a placebo. Interestingly, the mechanisms underlying how the placebo effect works is still largely unknown, but is believed to be related to the mind-body relationship.

SSRIs are the most common treatment for anxiety disorders. A SSRI inhibits reuptake of serotonin by blocking the serotonin transporter (SERT) located on the presynaptic cell, effectively increasing serotonin concentration within the synapse, and increasing the likelihood that serotonin will bind to postsynaptic serotonin receptors. If increasing serotonin at the synapse is an effective treatment for anxiety disorders, to many it logically follows that anxiety disorders are caused by decreased serotonin levels. However, the cause of anxiety disorders is not so clear cut. It is possible that SSRIs might be treating symptoms of the disorders rather than the actual underlying disorder. Alternatively, these drugs may be producing compensatory changes within the brain that ultimately cause them to be effective.
There are nonhuman behavioral tests used to assess anxiety in rodents, such as the elevated plus maze. This maze is a raised platform, with four arms in the shape of a plus sign. Two of the arms have walls surrounding the sides, while the other two are open, exposed on all sides. The rodent is free to move between any of the arms as they choose. Standing in one of the open arms, where they can see the floor far below them, is an anxiety-provoking condition. Under normal circumstances, rodents choose to spend more time in the arms that are surrounded by walls. But if you give these animals an anti-anxiety drug, they increase the time spent in the open arms, indicating a decrease in the behavioral expression of anxiety.
A related behavioral test is the open field test. The test apparatus consists of a large, flat area where the rodent can move around freely, and some method to track the animal—either an aerial view camera or a series of parallel invisible infrared beams that can locate the animal in the field. In the wild, rodents, as prey animals, prefer to spend more time close to the sides of the testing arena up against the wall, avoiding the wide-open space in the middle where their instinct warns them that they may be snatched up by some predator. However, if you give the rodent an anti-anxiety drug, they will spend more time venturing into the middle of the open field.

Another non-human model of anxiety is the predator exposure paradigm. In this paradigm, an ethologically-relevant stimulus is presented to the rodent, such as one of their naturally occurring predators. In this paradigm, rodent anxiety presents itself as a freezing response, an autonomic nervous system activity spike, and a reduction in non-survival behaviors. Although the predator exposure paradigm has good predictive validity, they may struggle with poor face validity, since the anxiety measures also may appear as many of several other conditions, such as PTSD or stress.
Affective disorders are highly prevalent. Affect indicates mood, or emotional state. Therefore, affective disorders are disorders of mood. We will cover two major mood disorders: major depression and bipolar disorder.
Episodes of depression can occur throughout an individual’s life with or without an external cause and can last on the order of months or years. Depression is a highly prevalent condition with a lifetime risk of about 18%. Depression gets diagnosed more frequently in women than in men, affecting about 5% of women and 2.5% of men. Even with treatment, there is a high rate of relapse: an estimated 80% of people with depression have more than one episode in their lifetime. The prevalence of depression is similar across both high-income and low-income countries, indicating that biological factors contribute significantly to the disease. Major Depression Disorder is also called unipolar depression to differentiate it from the depression that represents a phase seen in bipolar disorder.

Clinical depression is often associated with another medical or psychiatric condition. For example, rates of depression are higher among people with terminal diagnoses, like cancer. In this case, we say that the two are comorbid. Additionally, a set of particularly challenging circumstances, like the death of a loved one, could trigger a depressive episode. Major Depression Disorder represents a severe health risk across all ages. About 18% of adolescents report at least one instance of non-suicidal self-injury, and the lifetime risk for suicide among people with Major Depression Disorder is estimated to be about 10%.
The fundamental criteria that are used to diagnose people with Major Depression Disorder is a depressed mood/self-esteem, low energy, and anhedonia, the decrease in sensitivity to pleasure. Because of the decrease in pleasure, they have a lessened desire to engage in activities that once produced happiness, thus leading them to become withdrawn from their friends and family. Short-term changes in mood are completely normal and not clinical. The main diagnostic criteria for Major Depression Disorder is the severity and duration of the symptoms. When the depression begins to affect other aspects of life, including feelings of worthlessness, changes in sleep or appetite, difficulty concentrating, or suicidal ideation that persist daily for two weeks or longer, then a person may be diagnosed as clinically depressed.

To diagnose Major Depression Disorder, a trained psychiatrist or psychologist would use a combination of interview with a self-report questionnaire such as the Hamilton Rating Scale for Depression (HAM-D scale) or the Beck Depression Index. Items that appear on these sorts of tests include: “Feels like life is not worth living”, “Experience frequent weeping”, “I blame myself all the time for my faults”, etc. To date, there is no biomarker for depression.
The monoamine hypothesis of affective disorders postulates that there is decreased signaling within monoamine neurotransmitter systems and is based on observations in depressed patients. First, treatment with different pharmacological substances has indicated that the monoamines serotonin and/or norepinephrine are involved in affective disorders. The drug reserpine blocks the vesicular monoamine transporter that is responsible for the loading of monoamine neurotransmitters into vesicles prior to release at the synapse and causes severe depression in approximately 20% of people. Monoamine oxidase inhibitors, drugs that inhibit the degradation of monoamine neurotransmitters (therefore increasing monoamine availability) have been demonstrated to improve mood. Lastly, the drug imipramine that blocks both the serotonin transporter and norepinephrine transporter is effective at relieving depression. These pieces of evidence support that affective disorders are a consequence of decreased serotonin and/or norepinephrine signaling.
Serotonin, specifically, has been a neurotransmitter of focus in depression since the 1950’s due to a number of observations in depressed patients. There are lower levels of serotonin metabolites, such as 5-H1AA in the cerebrospinal fluid and diets that are low in tryptophan (the precursor for serotonin synthesis) can cause a return of depressive symptoms. Lastly, a number of drugs that are effective at treating affective disorders act to increase serotonin signaling and/or availability. However, it is important to note that there is also evidence that opposes the theory that affective disorders are due to a deficit in serotonin signaling. Primarily, that the level of serotonin in the synapse is less important than how serotonin acts in the synapse. Plastic changes at the synapse, either presynaptically (altering serotonin synthesis) or postsynaptically (altering expression and sensitivity of serotonin receptors) affect how serotonin or serotonergic drugs act on the synapse.
There is also pharmacological data that supports a specific role for norepinephrine in affective disorders. The drug desipramine specifically blocks the reuptake of norepinephrine at adrenergic synapses and has been demonstrated to be effective at treating depression in some individuals. Recall that norepinephrine and serotonin have different synthesis mechanisms, with serotonin synthesized from tryptophan and norepinephrine synthesized from tyrosine. The drug AMPT inhibits the activity of tyrosine hydroxylase, the rate-limiting step of norepinephrine synthesis. For individuals that are successfully treated for depression with the adrenergic drug desipramine, the administration of AMPT results in worsening of depressive symptoms. However, when AMPT is administered to those on serotonergic drugs, it has no effect on depressive symptoms. This evidence indicates that there may be separate groups of individuals in which either serotonin or norepinephrine is the major neurotransmitter system affected in depression.
Diathesis is a predisposition for a disease. The diathesis-stress hypothesis of affective disorders is based on the observation that mood disorders have a tendency to be more common in families with common genetics. This leads to some individuals having a genetic predisposition for the development of mood disorders. Further, abuse and stress have both been demonstrated to be significant risk factors for the development of mood disorders and anxiety and depression are often comorbid. In the diathesis-stress hypothesis, the HPA axis (discussed in Chapter 61) is where both genetic and environmental factors converge to ultimately cause mood disorders. Specifically, the HPA axis has been shown to be hyperactive in depressed individuals, with increased levels of corticotropin releasing factor (CRF), adrenocorticotropic hormone (ACTH), and cortisol and an overall decrease in negative feedback control of the HPA axis.
The anterior cingulate cortex is a structure that is the anterior most portion of the cingulate cortex just dorsal to the corpus callosum. It is part of the limbic system and typically functions in emotions and in maintaining attention in healthy individuals. Interestingly, the anterior cingulate cortex is interconnected with the HPA axis, the amygdala, prefrontal cortex, and hippocampus. When individuals are sad or depressed there is increased activity within the anterior cingulate cortex, and successful treatment of depression results in decreased activity of the anterior cingulate cortex. It is hypothesized that dysfunction within the anterior cingulate cortex to prefrontal cortex circuit underlies difficulty in concentrating on tasks during depressive bouts.
There is currently no completely effective treatment for Major Depression Disorder that reliably works for everyone. The currently accepted strategies can be divided into behavioral treatments and chemical treatments.
Cognitive behavioral therapy (CBT) is a therapist-guided form of talk therapy that may help a person manage their depression. In CBT, a patient’s behavior, including their coping mechanisms, erroneous thoughts, and emotional responses, is analyzed through careful clinical examination and patient self-reflection. Then, the patient is taught mechanisms to counteract those maladaptive behaviors and replace them with adaptive behaviors. For example, a person undergoing CBT for Major Depressions Disorder might learn to identify the moments when they dwell on something negative in their lives, and then learn to tell themselves: “That thought does not function to make my day better. Let’s start the day by getting out of bed and see what happens next.” It should be known that CBT is not exclusively for the treatment of Major Depression Disorder; CBT can also be effective for anxiety, OCD, PTSD, insomnia, substance use disorders, behavioral addictions, and many others.
A wide variety of drugs are used for the treatment of depression. The first-generation antidepressants were developed in the 1950s and 1960s. These drugs acted to increase the action of the monoamine neurotransmitters: primarily dopamine, norepinephrine, and serotonin. Our body uses an enzyme called monoamine oxidase (MAO) which degrades these chemicals into inactive components that do not signal at receptors. These first generation antidepressants block the action of MAO; biochemically, we call them monoamine oxidase inhibitors (MAOIs).

In the presence of an MAOI, the neurotransmitter signal remains in the synapse longer, similar to how an acetylcholinesterase inhibitor increases acetylcholine signaling. Most of the MAOIs, while sometimes effective, have fallen out of fashion clinically because of the adverse side effects associated with their biochemical activity. Some of them interact dangerously with foods rich in tyramine (particularly fermented foods, such as aged cheeses or beer, as well as beans and processed meats), an amino acid that is degraded by MAO. Excess tyramine can activate the sympathetic nervous system, and body levels of tyramine can rise to dangerous levels in the presence of an MAOI, leading to adverse cardiovascular events like stroke. Many of the common MAOIs, like phenelzine and isocarboxazid, can be damaging to the liver. Some MAOIs also produce unwanted side effects, such as psychosis or nausea.

A different class of antidepressant drugs called the tricyclic antidepressants (TCAs), named for the shape of their chemical structure, was also developed around this time. They generally act as monoamine reuptake inhibitors, resulting in elevated neurotransmitter signaling. Unfortunately, these tricyclics may produce many severe side effects, such as seizures, tachycardia, and heart attacks, so prescriptions must be monitored closely. The tricyclics are still prescribed today for several other nervous system disorders, ranging from insomnia to neuropathic pain, but due to their potential cardiotoxicity, they are not often the first line of treatment in depression.

Our current, most often prescribed class of compounds for Major Depression Disorder, called the third-generation antidepressants, are focused on boosting the signaling activity of serotonin. Instead of preventing degradation, like the MAOIs, these compounds block the reuptake of serotonin out of the synapse. These chemicals are called selective serotonin reuptake inhibitors (SSRIs), of which fluoxetine (Prozac) is one of the most well-known examples. While SSRIs can be effective at reversing the side effects of depression, they are not perfect drugs. One shortcoming is that a person needs to be on the drug for 2-4 weeks before they start to experience a clinically meaningful reversal of depressive symptoms. This finding is highly unusual since the pharmacological, molecular-level effects of SSRIs take place within hours after taking the medication.

Similar to SSRIs, SNRIs (serotonin and norepinephrine reuptake inhibitors) can also be used to treat depression. One of the unsavory side effects of SSRIs is serotonin syndrome, a set of somatic changes resulting from excessive serotonergic signaling. In mild cases, a person may have an elevated body temperature, excessive sweating, rapid heart rate, and elevated blood pressure. In more severe cases, a patient may have severe fevers or seizures. Serotonin syndrome can happen in the event of an SSRI overdose, or as a consequence of some interaction between an SSRI and other drugs like MAOIs, MDMA (ecstasy), amphetamines, or cocaine.

Our newest treatment options for depression, recently approved by the FDA in March of 2019, is esketamine, a dissociative anesthetic typically used as a veterinary tranquilizer and a recreational club drug. Branded as Spravato, it can be administered rapidly via nasal spray. The strength of esketamine is the speed of its action. After taking a dose, the antidepressant effects of the substance can be observed within hours. The speed at which this drug takes effect, makes it ideal for treating severe cases of suicidal thoughts.

One future therapy that is currently making significant medical advancements in curing depression is the use of psychedelic drugs, particularly psilocybin—a substance found in some species of wild mushrooms. As a potent serotonergic agonist, a single dose of psilocybin has been shown to decrease depression scores in various self-report studies with little to no adverse side effects.
For severe or treatment-resistant depression, electroconvulsive therapy (ECT) is a treatment option. Introduced in 1938, the procedure has since been refined over the years (it is currently performed under anesthesia) and is considered to be well-tolerated and highly effective. During the procedure, electrodes are placed on the head and electrical current is passed through the electrodes. The mechanism of action that accounts for the therapeutic effects of electroconvulsive therapy are not well-known. Side effects include aches, nausea, and memory loss.
Deep brain stimulation that targets the cingulate cortex or the prefrontal cortex that may be overactive in depression, is ultimately aimed at decreasing activity. This treatment is only pursued when other less invasive treatments are unsuccessful.
Behavioral neuroscientists have developed a variety of tests to assess the effectiveness of antidepressant drugs in non-humans. They are roughly divided into two categories: despair-based tests and reward-based tests.
One symptom of depression is that a person “gives up”, a behavior that can be modeled in a variety of rodent tests. One such example is in a tail suspension test. In this test, a rodent is held by the tail upside down. While it does not cause injury to the animal, they do experience discomfort, and will generally struggle to either free themselves or to get upright again. The sooner they stop struggling (more time spent immobile), the more despair they experience, or the more depressive they are. Giving a rodent an antidepressant like fluoxetine causes them to fight for a longer duration.
A similar test to assess “giving up” is the forced swim test. Here, a rodent is put into a container with some water. While they are naturally buoyant and are not at risk of drowning, they do not like being wet and will try to swim so that they can climb out of the water-filled container. As in the tail suspension test, they are unable to escape their predicament, and will eventually become immobile. Giving them an antidepressant decreases time spent immobile.
These tests seek to measure the severity of anhedonia, one of the main symptoms of depression. For example, a rodent may be presented with a two-bottle choice task, where they are put into a cage with two different bottles to drink from: one filled with standard water, and the other filled with a more desirable sugar-water solution. A depressed rodent will not drink from the sugar-water bottle as frequently as a healthy rat but give that rat an antidepressant, and they will prefer the sweet water. An intracranial self-stimulation paradigm can also be tested here in the context of depression. When an electrical stimulator is placed in a reward area of the brain and the rodent is trained to perform some operant task to receive activation of these areas, we find that depressed rodents do not activate these areas of their brain as much as rodents on antidepressants.
A person with bipolar disorder (BD) experiences phases of clinical depression as described in the previous chapter and, at other times, they experience mania, a state of exhilarating high energy. During this state, they may sleep very little, have difficulty concentrating, and experience pressure of speech: a perceived need to speak very rapidly to get their thoughts out. They might make poor financial or life decisions.

Historically, BD has been called “manic depression.” The estimated prevalence of BD is around 2.5%, but the disease is often misdiagnosed in the clinic as Major Depression Disorder. One reason this happens is that more people are aware of the symptoms of depression, and these symptoms are generally more easily observed. Mania is more difficult to identify, since in mild cases it may be hard to distinguish from a person just “being in a really good mood”.
For a diagnosis of BD according to the DSM-V, a mood cycle has to last for a week or more. The word “bipolar” is often misused in pop culture. Frequent changes in mood from happy to sad does not characterize BD. In fact, for a person to be diagnosed with rapid-cycling bipolar disorder, they need to experience four mood transitions annually! BD is usually diagnosed in adolescence and early adulthood. As with depression, there are some genetic factors involved, since a family history of BD is a risk factor. Concordance rates for identical monozygotic twins are estimated to be between 35%-80%. But, environmental influences may be the precipitating factor in the onset of BD.

BD is diagnosed into two categories, based roughly on the severity of symptoms. Bipolar 1 disorder is the more severe of the two conditions, with a clinical diagnosis made when a patient experiences depressive or manic events that cause significant social or occupational impairment, or hospitalization to prevent serious self-harm. A diagnosis of Bipolar 2 disorder is less severe, but the behavioral changes are still noticeable by friends and family. A related diagnosis is cyclothymia, where a person has alternating mood states that shift from depression to hypomania, a less severe state of mania. Like most other disorders, BD exists on a spectrum, and these labels only exist for simplicity.
The main issue with BD therapy is bringing the patient to some “middle” state: an antidepressant may treat the depression phase, but could also swing the patient into mania. Similarly, a mania-controlling drug could initiate depression.

Currently, our most reliable therapy for BD is lithium drugs. These compounds are described as mood stabilizers since they act to move the patient’s mood to the center, rather than being at either the high end of mood (mania) or the low end (depression). The way lithium acts to reverse the symptoms is still unknown, and it probably acts on multiple pharmacological targets.

The main downside of this therapy is that lithium is very toxic. It has a very narrow therapeutic window: blood levels of lithium lower than 0.6 mEq/L produce no effect, and anything above 1.5 mEq/L causes delirium, tremor, fatigue, and deadly side effects like seizures and coma. It is also harmful to the kidneys after long exposure. Therefore, a person taking lithium drugs regularly undergo therapeutic drug monitoring, a procedure by which the concentration of lithium is assayed. Therapeutic drug monitoring requires frequent visits to a hospital. Usually, patients get multiple blood draws in the first month when they start lithium treatment, decreasing to one test every 2 months, before decreasing to about four times a year.

Bipolar disorder is very challenging to model in nonhumans. A genetically modified disruption of the circadian rhythm can induce mania-like symptoms, as can extending the length of daytime light exposure; oppositely, decreasing daily light exposure can induce depressive behaviors. Exposure to amphetamine can increase manic behaviors, while withdrawal from the drug can induce depression. Clearly, neither of these models for BD exhibit strong validity.
Schizophrenia is a psychiatric condition affecting just under 1% of people. Schizophrenia affects men slightly more often than women and affects people of all races. There is a strong association between low socioeconomic status and the risk of developing schizophrenia, indicating that stresses such as neonatal nutritional deficiency or food insecurity may be risk factors. Other risk factors that contribute to increased schizophrenia risk include prenatal drug exposure, heavy drug use during early adolescence, and childhood adversity.

A diagnosis is generally made while a person is in their late adolescent years through their thirties. During this phase of life, the brain is still undergoing subtle maturation processes, which may account for why a person is more vulnerable in these years. After this age, the risk of developing schizophrenia decreases significantly. Also, the later in life that schizophrenia symptoms appear, the better the health outcomes are. It is worth noting that people with schizophrenia have the neurotypical range of intelligence, with the occasional outliers: John Nash, the real-life Nobel prize-winning economist depicted in the movie “A Beautiful Mind”, was first diagnosed with schizophrenia in 1959.
The symptoms of schizophrenia can be roughly classified into two categories: positive symptoms and negative symptoms. These phrases are used to describe whether there is an excess of some function, (positive symptoms), or a deficit of a function, (negative symptoms). The symptoms do not appear uniformly across patients, so not all patients develop every symptom.
The most well-known positive symptom of schizophrenia is hallucinations, perceiving something that is not there (as opposed to illusions, which are misinterpretations of things that are there). Usually, patients experience auditory hallucinations, but they more rarely have visual hallucinations. The voices that people hear may be consistent or can change over time. Interestingly, the nature of these hallucinations is influenced by society. In cultures with strong ancestor reverence, they may hear the voices of their grandparents, whereas people in religious cultures may hear the voices of deities.

Relatedly, people with schizophrenia may experience a variety of delusions, untrue beliefs that cannot be changed despite overwhelming evidence. The delusions can come and go spontaneously. Delusions exist in many forms. A paranoid delusion is when a person believes that they are being spied on, maybe by the government or by aliens. A persecutory delusion is a persistent thought that the world is out to get them or to do them harm. Delusions of grandeur are when a person has a tremendously high sense of self esteem, believing that they are royalty or are the reincarnation of God.

Other positive symptoms that can present in schizophrenia are a variety of motor disturbances. Basal ganglia and cerebellar structural deficits are found in schizophrenia, two brain structures involved in motor control, which may explain why deficits are observed. One motor difficulty is catatonia, where a person can hold their body in a highly unusual position for a prolonged period of time. They may also display stereotypy, a series of repetitive, purposeless behaviors, such as the persistent rocking of the body or self-caressing.
The negative symptoms of schizophrenia may include deficits in expression. One common symptom is a flat affect, where a patient does not show or express emotion in situations where you would expect to see them. A related negative symptom is alogia, a decrease in the use of language. People with alogia often use vague language that is lacking in content or repetitive. Negative symptoms also include deficits in motivation or interest. Two closely-related negative symptoms include anhedonia, a loss of a sensation of pleasure and the inability to expect upcoming pleasure. Furthermore, patients with schizophrenia may also exhibit avolition, a decrease in goal-directed activity, which can cause a person to stop seeing their friends and cease displaying interest in social gatherings, leading to worsened interpersonal relationships. Negative symptoms may also manifest as a deficit of a patient’s cognitive abilities, particularly shortcomings in episodic memory. They may also present with difficulty in performing attention-related behavioral tasks.
Schizophrenia has a strong genetic component, with increased risk associated with having a first-degree relative that has the disease, however most individuals with schizophrenia do not have a family history. Many different genes have been identified in disease onset and progression.

One example supporting the genetic component of schizophrenia are the Genain Quadruplets. They were a set of identical quadruplet sisters that were born in 1930. All four of the sisters developed schizophrenia by the age of 24. The sisters’ paternal grandmother may have had schizophrenia and it was known that they grew up in an abusive household, making it unclear if their development of schizophrenia stemmed from their environment, genetics, or a combination of the two.
A number of structural abnormalities have been observed in the brains of individuals with schizophrenia. For one, the lateral ventricles are typically enlarged in those with schizophrenia than in those without schizophrenia. The increased size of the lateral ventricles could alter intracerebral pressure or compress the areas of the brain adjacent to the lateral ventricles.
In addition, a decrease in cortical thickness has been observed as well as wider than typical sulci between the gyri. Problems of cell migration during development may also play a part in schizophrenia, leading to abnormal cellular densities and organization. There also seems to be cell loss and disorganized cell location within the prefrontal cortex.
In a healthy person, dopamine is important for motor control and motivation, two behaviors that are changed in patients with schizophrenia. Dopamine receptors (D1 and D2-like receptors) are found throughout the mesolimbic and nigrostriatal dopamine pathways. Therefore, scientists have suggested that increased dopamine signaling may be an underlying root cause in schizophrenia. In fact, psychotic episodes are triggered by activation of dopamine receptors and increased D1 receptor binding has been observed in the prefrontal cortex in those with schizophrenia. While the dopamine hypothesis is one of the earliest theories of schizophrenia, modern genetics studies have shown that polymorphisms in the dopamine D2 receptor are risk factors.
One animal model for schizophrenia is based on the hypothesis that excess dopamine leads to the disorder. Introducing high doses of the drug amphetamine, which increases dopaminergic signaling, induces a temporary schizophrenic-like state in non-human animals. The hyperdopaminergic model of schizophrenia produces cognitive deficits with no changes in memory or other negative symptoms. Alternatively, administration of NMDA glutamate receptor antagonists, like ketamine or PCP, is also used as a behavioral model of schizophrenia.

Other non-human models of schizophrenia are neurodevelopmental models. In these models, a pregnant dam is exposed to the compound MAM, which causes the newborns to develop atypically and display behavioral deficits similar to schizophrenia. Inducing an unusually strong immune response in the pregnant mother can also cause atypical development in utero, which causes the animals to experience behavioral deficits after birth. The biggest limiting factor to developing an animal model is that many symptoms in human schizophrenia, like paranoid delusions or auditory hallucinations, are impossible to detect and quantify in nonhumans. The PCP model can cause changes in rodent social behaviors, but it is hard to tell if this model causes any of the positive symptoms that you might see in a patient with schizophrenia. Despite the limitations of these non-human models of schizophrenia, they have been helpful in testing the therapeutic efficacy of anti-schizophrenia drugs.
The dopamine theory of schizophrenia has led to a few novel therapeutic strategies, especially in the context of the dopamine D2 receptor.

Typical, or classical, antipsychotics such as thorazine or haloperidol are more effective treating positive symptoms of schizophrenia such as hallucinations and delusions in some patients. These drugs block D2 dopamine receptors (dopamine antagonists) and decrease dopaminergic signaling, however they have many undesirable motor side effects such as tremors, decreased voluntary movement, tardive dyskinesias, and a shuffling gait named the ‘Thorazine shuffle’. The effectiveness of the antagonist is correlated with the ability of that drug to block the D2 receptor.

Atypical, or nonclassical, antipsychotics such as Clozapine, antagonize a wider array of dopamine receptors in addition to some serotonin and norepinephrine receptors. These drugs more effectively treat negative symptoms of schizophrenia, but also can treat the positive symptoms with less side effects compared to the typical antipsychotics. Unfortunately, pharmacological therapies are not always effective in humans. Around a third of patients discontinue their treatment regimen, and around a fifth of them report adverse side effects such as extrapyramidal motor symptoms, sedation, and weight gain.
A potential new therapy is based on transcranial magnetic stimulation. In physics, there is a close relationship between electricity and magnetism. The movement of magnets can generate electric currents, and conversely, electricity can generate magnetic fields, a process called induction. A brain stimulation technique called transcranial magnetic stimulation (TMS) relies on induction to generate electrical currents through the skull. The TMS machine itself is a handheld coil of wires in a loop. Passing electrical current through that loop produces a magnetic field. The magnetic field generated then induces an electrical current at some distance away from the coil. By placing the coil at the surface of the scalp, we can electrically activate small areas of brain tissue.
For instance, using TMS above the motor cortex causes muscle contractions, and using TMS above the occipital lobe causes the perception of flashes of light.  A single pulse of TMS delivered to the right motor cortex will produces electrical activity in the motor nerve of the left hand, causing it to twitch. In repetitive TMS (rTMS) multiple pulses are delivered, which has been demonstrated to produce long-lasting effects that extend beyond the stimulation period. rTMS can be used to produce either inhibition in brain targets, through low frequency rTMS, or to produce excitation to the brain through high frequency rTMS.

TMS is believed to have moderate benefits for several different psychiatric conditions, potentially making it a meaningful therapeutic intervention. Single pulse TMS can be used to evaluate damage from stroke, ALS, multiple sclerosis, and a number of motor disorders. It has also been approved for the treatment of migraines. rTMS delivered to the motor cortex may help alleviate chronic pain conditions, Parkinsonian symptoms, and improve contralateral motor function following stroke injury. Further, rTMS activation of prefrontal cortex can decrease anxiety, antidepressive symptoms, cigarette craving or consumption, and schizophrenia. Stimulation of other brain regions can be antiepileptic and may also minimize auditory hallucinations or tinnitus (ringing in the ears.) In schizophrenia, some evidence suggests that targeted activation of the cortex can decrease the severity of auditory hallucinations. There may also be some mild improvements in the negative symptoms.

The technique itself is completely noninvasive. TMS can be delivered simply with placement of the electric coil on the surface of the head. TMS may have some unexpected consequences, such as temporary headaches, localized pain, changes in hearing, and bizarre changes in somatosensation. The most severe side effect so far recorded is seizures, which can be very dangerous. Use of TMS is still highly experimental. As with fMRI, the magnetic fields generated by a TMS device can cause dangerous interactions with any magnetosensitive implants, such as deep brain stimulation devices, cochlear implants, or aneurysm clips.
Think back to your favorite birthday party. Which of your friends were there? What did you do, where did you go, and did you have cake? Did you get gifts? The ability to perform this task depends on our ability to create and recall memories. According to our current best understanding of the neuroscience of learning, the underlying biology of a memory mainly consists of subtle changes among synapses distributed across several brain areas. Our ability to learn new facts, recount the events of last week, or to perform new motor skills is the result of learning-induced neural plasticity. In our discussion of learning and memory, we will consider different aspects of learning and memory, starting from the behavioral level down to the molecular changes responsible for memory formation.
First, it is important to distinguish between different types of memories.
Declarative memories, also called explicit memories, are the pieces of information that can be consciously declared or stated explicitly. Declarative memories are thought of as a “knowing what”. Declarative memories can be further subdivided into semantic memory and episodic memory. Semantic memories are pieces of factual information. Some examples include: 1. “Jupiter is the largest planet of our solar system.” 2. “Rosalind Franklin discovered the doublehelix structure of a DNA molecule.” 3. “The actor Keanu Reeves played the protagonist of the movie The Matrix.”

An episodic memory, sometimes also called an autobiographical memory, is the recollection of a discrete moment in a person’s life. It can be thought of as “mental-time travel”—what was it like when. The following memories are examples of episodic memories: “When I got home, I put my wallet and phone on the table.”, “I ordered pizza last night.”, “In 2019, I went to see my favorite musicians perform live.”.

Declarative memories can either be a short-term memory or a long-term memory, which are distinct from each other. The process of memory consolidation takes facts and events and converts them from short-term memory into a long-term memory, which is supported by structural and functional change within the neurons that hold the long-term memory.
Nondeclarative memory encompasses all other types of memory outside of semantic and episodic memory including procedural memories, skeletal muscle memory, and emotional response memory.

Procedural memories, (or implicit memories) are unconscious memories, and can’t be explicitly stated. These can be thought of as “knowing how”. Some examples of procedural memories include, for example, performance of a series of motor actions without conscious thought such as an experienced musician playing a simple scale (sometimes commonly called “muscle memory”, even though the muscles do not store any actual memory!), or a priming effect (such as when a person sees pictures of bananas, they are more likely to answer the fill-in-the-blank prompt “b _ _ _ _ _” with “banana”, whereas other people might guess “bubble” or “badger”.

There are two different types of procedural learning: non-associative learning and associative learning.
Non-associative learning involves a change in behavioral response over time in response to a single type of stimulus and includes habituation and sensitization. In habituation, responses decrease after repeated presentation of a stimulus as the individual learns that the stimulus lacks meaning. For example, if someone poked you in the back, you will initially jump in surprise. However, if someone repeatedly pokes you in the back over and over again, your response will decrease and you realize that the stimulus is meaningless.

In sensitization, responses increase following presentation of a strong stimulus. For example, a sound of a door opening in your house typically will not cause a strong response. However, if you are home alone and hear a loud bang followed by a door opening, you will likely be on high alert.
Associative memories are the types of information that we learn through traditional Pavlovian conditioning. For example, recall the classic Nobel prize-winning experiment in physiology conducted by Ivan Pavlov in the late 1800s. Normally, the presentation of dog food, an unconditioned stimulus (US), causes a dog to salivate, a naturally occurring behavior, called the unconditioned response (UR). Dogs are not particularly interested in the sound of a bell: this neutral stimulus will produce a minor response, such as a head turn and attentional shift towards the origin of the sound, but not much more than that. However, when this stimulus is repeatedly paired with the presentation of food, dogs quickly learn to associate that the bell signals food. After multiple pairings, upon hearing the bell, a conditioned stimulus (CS), the dogs begin to salivate, a conditioned response (CR), independent of any food being presented.
Associative learning can also be measured with instrumental conditioning where a rodent, for example, learns to associate a response with a meaningful stimulus. For example, a rodent will learn to press a lever for access to food.
Separate from declarative or procedural memories, a different form of memory called working memory involves processes of storing information temporarily while simultaneously manipulating those pieces of information. This type of memory can be thought of as a “short-term memory on overdrive.” For example, a test of working memory is the digit span test, where a person is given a series of numbers to remember, then they are asked to repeat the numbers in reverse order. After successfully completing this task, a different series of numbers, this time one digit longer, is presented to the patient until they first start making errors in recall. A related task is called the Corsi block tapping test, where an experimenter sets up several blocks on a table. The experimenter then taps a series of blocks in a specific order, then the subject is asked to tap on the blocks in reverse order. As with the digit-span test, the experimenter then makes the series of blocks longer until they make mistakes in the tapping.
In the 1950’s, the scientist Karl Lashley was interested in finding a location in the brain where memories were stored. His experiments searched for the location within the cortex of what he called an “engram” or memory trace. He trained rats to run in a complex maze to reach a food reward, which took the animals time to learn. After the animals had learned how to successfully run the maze, Lashley would lesion different areas of the rat cortex and then test the rats in the maze again. He found that regardless of the location of the lesion, which was done at different areas of the cortex for each rat, that cortical lesions resulted in decreased ability to remember the location of the food reward and run the maze. Instead of finding a specific location where the memories were being stored, Lashley discovered that the size of the lesion corresponded to the amount of memory deficit in the animal, but that the location of the lesion did not have an effect, demonstrating that the engram was widely spread across the cortex.
The main structures of the medial temporal lobes include the hippocampus, the entorhinal cortex, the perirhinal cortex, and parahippocampal cortex. Together, these structures are important in both consolidation and storage of declarative memories.

The hippocampus, meaning “seahorse” in Greek, was named based on its morphology and resemblance to a seahorse. The hippocampus is located along the ventral and medial surface of the brain. The hippocampus is one of the critical structures of the limbic system, a series of subcortical brain structures that are involved in several different complex behaviors, such as emotions and memory. The limbic system is an evolutionarily ancient brain network.

The hippocampus is involved in spatial memories, memories involved in navigation of our surroundings, and the creation of a mental map of our world. Spatial memories are developed when we enter a new building for the first time and we search for a new classroom. We also use our spatial memory whenever we are walking around campus, making our way from one building to another, thinking about the streets you’d need to cross or the buildings you can cut through. While the volume of the hippocampus is not a reliable indicator of the strength of a healthy person’s spatial memory, injury to the hippocampus causes deficits in spatial memory.
One of the most influential case studies in the neuroscience of memory is the story of Patient HM. Since his death in 2008, we now know that Patient HM’s name was Henry Molaison. HM was born in 1926 in a small Connecticut town. In his childhood, HM began having severe seizures, possibly the result of a head injury. In his teenage years, he started having tonic-clonic seizures, the most severe form of seizures that produces a loss of consciousness and convulsions (extreme muscle contraction or extension). In his early adulthood, he was having a tonic-clonic seizure monthly and several minor seizures daily, preventing him from working a normal job or living a normal life, despite taking a cocktail of anti-epileptic medications.

Neurosurgeon William Scoville proposed a “frankly experimental operation” to treat HM. It was known that most epilepsy originates in patches of neurons of the medial temporal lobe, and HM’s epilepsy was typical in this respect. Scoville suggested to surgically resect, or remove, the medial temporal lobe. In 1953, Scoville removed about 8 cm of the medial temporal lobe bilaterally, including part of the amygdala, and notably the hippocampus, the seahorse-shaped structure of the brain. The surgery succeeded at its primary goal: HM’s seizures were less frequent and less severe. However, HM was left with a highly unusual and life-altering side effect: He was unable to create new declarative memories, a memory deficit called anterograde amnesia. For example, he could not remember what he had eaten for lunch just minutes after finishing the last bite. Despite being an avid fan of watching the news, HM couldn’t remember the names or the faces of different celebrities or public figures. It was as if he was permanently living in the present. (In contrast, retrograde amnesia affects the ability to successfully retrieve memory from one’s past.)

However, despite his pervasive memory deficits, HM did not display any deficits in intelligence. His language and speech were unaffected, and word recall was excellent, as he loved completing crossword puzzles and often did so successfully late in life, with only the occasional spelling errors. He could learn to acquire new skills, such as keeping a pen still on a moving circular platform, or a tapping task (these skills are a different form of memory called procedural memory). He was also capable of recalling things from his early childhood, such as geography facts he had learned in elementary school.

The fact that HM’s medial temporal lobe surgery disrupted some types of memories (e.g., memory for facts) while others were still intact (e.g., motor skills) inspired neuropsychiatrists to try to define the different forms of memory. Much of the research was led by Dr. Brenda Milner, who carried out several behavioral tests on HM to figure out what types of memories are dependent on the intact medial temporal lobe and which ones can function without the medial temporal lobe.

Several tests concluded that HM had lost his ability to create new semantic memories. In one such study, HM was asked to determine if a word was made up or real. He was shown words with very old origins, such as “shepherd” or “butcher.” On these words, he performed as well as the control group. When he was shown words that are made up, such as “phlage” or “thweise”, he likewise performed as well as the controls. However, when shown words that were added into the dictionary after his 1953-surgery, such as “granola” or “jacuzzi,” he scored about 50% correct—consistent with guessing at random, as if he never acquired the knowledge that these words have a meaning.

HM was also unable to create autobiographical memories. When asked to recall one of his birthday celebrations as an adult, he wouldn’t be able to give any significant details about the event. Instead, his answers were often vague and generic. One interesting observation was that HM’s memory about details from his childhood were still intact. The inability to recall memories from the past, in this case, from before HM´s surgery, is called retrograde amnesia. Patient HM’s retrograde amnesia was temporally graded, meaning that the farther back you examine, the more complete his memories were. Many of his memories for the two years before his surgery were completely lost, but memories from his youth and teenage years were intact as much as healthy individuals (there is contention about this observation, because HM was taking several anti-epileptic drugs, which may have impacted memory formation.)

From this observation, memory researchers concluded that the medial temporal lobe functions as short-term storage site for memories, but after some years, those memories get relocated to other brain areas outside of the medial temporal lobe. Currently, the scientific evidence suggests that memories are distributed across several networks of cortical and subcortical brain areas.

While HM lost the ability to create new declarative memories, he was still able to maintain a different class of memories, called procedural memories (or implicit memories). The original test of procedural memory conducted by Dr. Brenda Milner was called the mirror tracing task. In this test, the patient is told to draw a third star in between the two stars as quickly as possible without making any mistakes. The challenge is that the tracing is to be done while watching their hand and the star in their reflection in a mirror. Because of these unusual circumstances, completing this task is difficult. But over multiple days of practice, people become better at this mirror tracing task, completing it faster with fewer errors. Improvement on this task indicates that a person is learning or gaining some memory about how to better perform the task. After practicing this mirror tracing task, HM was able to finish drawing the star about ten times faster than when he first began. He improved his performance within each day’s worth of training, and he also improved day-to-day. There is evidence that he maintained these skills up to one year later, despite not having regular training on this task.

Surprisingly, each day Milner examined HM, she would need to reintroduce herself since he forgot who she was. She also had to re-explain what HM was supposed to do in the mirror tracing task. Hence, while HM was unable to form declarative memory about the experiment or the people involved, learning of the procedural memories and motor actions involved in this task remained intact.

Based on the deficits seen in Patient HM and other experimental manipulations of the hippocampus, we conclude that the hippocampus is strongly implicated in the process of declarative memories and spatial navigation. Since some of HM’s memory functions were still intact, such as procedural memories and working memory, it is believed that these functions are independent of hippocampus function.
To test spatial memory behaviorally in nonhuman animals, one test that is regularly used in rodents is called the Morris water maze. In this test, a shallow pool is filled with an opaque liquid, making it difficult to see through. Hidden somewhere in this pool is a clear plexiglass platform, and surrounding the pool are different environmental cues that can be seen from the surface of the water, such as different shapes or colors. The water is deep enough that when a rodent is put into the Morris water maze, they have to swim to stay afloat. The rodents swim around aimlessly until they find the platform, the time it takes for this to happen is recorded, and the trial ends. Over time, the animals learn that the platform is located near certain navigational cues, and on future trials, the animals spend more time near those cues, and the latency to find the platform decreases. When the hippocampus is surgically removed from rodents or inactivated, they perform poorly in the Morris water maze.
Another non-human behavioral test used to assess the capacity for learning navigational cues is the radial arm maze. In this test, a rodent is placed on a circular platform. Extending from this platform are eight or more “arms”, at the end of each is a small dish. In one of the dishes is a morsel of food (“rewarded arm”), while the other dishes contain nothing (“non-rewarded arms”). The maze is designed so that the food cannot be seen from the end of each arm, so the animal must return to the starting platform before exploring another arm. The number of entries into a non-rewarded arms is counted as an error. Over time, the animals make fewer errors as they learn which arm is rewarded and which ones are not. Alzheimer’s disease model organisms perform poorly on this task.
An individual memory is likely distributed widely across several different parts of the brain. However, there are a few special populations of neurons mainly in the medial temporal lobe that contribute to highly specific types of memories.
Place cells are a special population of pyramidal cells of the hippocampus. These neurons increase their firing activity when the animal is in a particular location in an environment, indicating that they contribute strongly to location and navigational memory. There is no apparent topographical arrangement of these place cells, meaning that adjacent areas of an environment do not necessarily activate adjacent hippocampal place cells. The place cells, when firing at the right times, help the animal create a spatial map of their surroundings.
Grid cells are located in the entorhinal cortex, the main input structure to the hippocampus. Closely related to the place cells described above, grid cells increase their firing properties periodically when an animal is at an intersection of a “grid” in a wide-open, previously-explored environment. The grid itself is roughly hexagonal, and spans the whole environment an animal is in. The overlap of multiple grids gives the animal an idea of the surroundings. The scientific description of grid cells earned three scientists, Edvard Moser, May-Britt Moser, and John O’Keefe, a Nobel Prize in Physiology or Medicine in 2014.
Concept cells are a series of cortical neurons in the temporal lobe that increase their firing exclusively in response to highly-specific stimuli, such as the idea of Jennifer Aniston, Halle Berry, or the Tower of Pisa. These concept cells respond to much more than just pictures: for example, a Luke Skywalker neuron that responded to a picture of young Mark Hamill (the actor who played Luke Skywalker) will also respond to text that reads “LUKE SKYWALKER” and the sound of a person saying “Luke Skywalker”. Although this particular neuron probably won’t fire in response to pictures of athlete Manu Ginobili or actress Marilyn Monroe, the neuron might fire in response to pictures of Yoda or Darth Vader, indicating that the neuron may encode an even broader concept, such as “Star Wars characters” or “Jedi”, or is a part of a network that encodes concepts related to the Star Wars franchise.
As part of the frontal lobe, the prefrontal cortex is involved in higher order decision making and personality. In the context of memory, neural circuits in the prefrontal cortex are important for short-term and working memory.

A delayed-response task relies on prefrontal cortex activity. In this task, a monkey is shown a cue of food placed into a randomly selected compartment outside their cage. A screen is then lowered and the compartments are covered for a standard period of time. The screen is then raised again and the monkey is tasked with correctly uncovering the compartment that contains the food. Animals with a lesion to the prefrontal cortex perform worse than animals with an intact prefrontal cortex in this task.

Patients with injuries to their prefrontal cortex after stroke, tumors or aneurysm, performed worse on a variety of working memory tasks such as the digit span test. Additionally, people with frontotemporal dementia, a neurodegenerative disorder characterized by a degradation of the frontal lobe, often have difficulty with working memory. The prefrontal cortex also has strong projections with the hippocampus, and these circuits are likely also involved in the formation of hippocampal-dependent memories.
The striatum, made up of the caudate nucleus and putamen, is important for habit or procedural memory and reward in learning. A T-maze is used to test procedural learning. In this task, a rodent is placed at the area of the maze that corresponds to the bottom of the T. The animal is trained to turn either left (with a high frequency tone) or right (with a low frequency tone) once they reach the cross of the T. If the animal completes the task successfully, they are rewarded with a treat. The ability of the animal to learn this task is dependent on activity within the striatum. Animals that have striatal lesions have impaired performance on the T-maze, but not on tasks that rely on other types of memory.
In the late 1800s, around the time when Golgi and Ramon y Cajal were engaged in intense debate about the organization of the nervous system, many neuroscientists came to a strange observation: the weight of the brain increases dramatically over the first 10 years of life, but not much more after that. Even though we learn lots of new facts and make lots of new memories in adulthood, the brain itself doesn’t grow in size. So how is it possible to store new knowledge if the brain is not making many new neurons? Most likely, new pieces of information are held in the connections between cells, not just in the cells themselves. If our estimate of 150 trillion synapses per adult brain is correct, then it is possible that we could store all the knowledge and memories that we collect over our lifetime through some combination of activity across certain connections.

The activity at the cellular level is believed to take place on at least three different levels enabling us to build, store, and retrieve memories.
Encoding refers to the ability for brain circuits to store some piece of information. In real life, you are presented with countless stimuli simultaneously. Imagine walking down a busy street, and think of the number of different sights, smells, and tactile stimuli you experience. Storing memories is an energetically costly process, and we are limited in the fact that all of our sensory inputs cannot possibly get encoded. Instead, evolution has preferred to encode stimuli that are the most salient pieces of information, such as perceptual cues associated with predators. Alternatively, information that we pay strong attention to can get encoded more strongly, like when we repeat a phone number to ourselves until we have a chance to write it down. It is also easier to encode novel information that “builds” on previous bits of knowledge, or information that is closely related to other well-established information, which is why analogies are such an effective way to learn new facts.
The process that enables memory storing is called consolidation, which makes the memory more permanent. In 1949, a student of Karl Lashley, the neuropsychologist Donald O. Hebb, offered an explanation for how changes in synapses could possibly lead to a phenomenon as complex as learning. His theory, published in his text The Organization of Behavior, can be summed up in the phrase: “Cells that fire together, wire together.” In Hebb’s framework, repeated activity at a synapse within a circuit of neurons acts as a reinforcer signal that strengthens this synapse for future communication, making the next incoming signal more robust. Hebb also implies the inverse is true: when cells do not fire together, they weaken their connection. Through fine tuning of synaptic connections, some strengthening and others weakening, a lifetime of memories can be stored across a wide distribution of neurons. After a memory has been created, the specific circuit of neurons that represent that piece of information is called a memory trace or an engram. A cellular process called reverberation is thought to be the mechanism that allows for consolidation.
Reverberation is the process by which networks of neurons fire repeatedly. Each time that circuit is activated, the strength of the network is increased, meaning that it becomes easier for that circuit to be activated in the future. Throughout the process of consolidation, memory traces are thought to become more represented in the neocortex and less in the subcortical structures like the hippocampus or amygdala.

Recall Patient HM’s temporally graded retrograde amnesia, where he had lost declarative memories in the two years leading up to this surgery, and yet his memories from the long past were maintained. This finding suggests that some aspects of declarative memory consolidation depends at least partially on medial temporal lobe and hippocampus for a period of time, maybe up to two years, before those memories get stored in the cortex more permanently. However, we cannot conclude how long consolidation takes in healthy humans based on findings from HM, who had pervasive and frequent seizures, which might have negatively impacted memory consolidation before the surgery.

Consolidation seems to occur predominantly during sleep. Specifically, declarative memory is enhanced during non-REM sleep, while procedural memory is enhanced during REM sleep. Studies investigating sleep consolidation are often done by letting participants learn or perform behavioral tasks, after which they are deprived of a specific phase of sleep. To wake participants at the right moment, researchers commonly use EEG signatures, which are unique for different phases of sleep: sleep deprivation early in the night denies non-REM slow wave sleep, while late-sleep deprivation decreases time spent in REM sleep. Some speculate that the hallucinations we sometimes experience during dreaming are a consequence of consolidation processes, but it is inconclusive as to what role dreaming plays in memory formation.
Finally, for the stored memories to be recalled, a cellular process called retrieval happens which brings back the specific engram. Retrieval happens for both declarative and procedural memories. The writing of memories can be differentiated from the retrieval of memories using specific priming-related behavioral tests. One example is a vocabulary recall test. Consider if you were given a list of 50 words to memorize, words that belong to a handful of different conceptual categories (such as cinnamon, pepper, or curry, which fall under the category “food flavors”). When asked to write down as many words as possible from the list using your memory, a test called free-recall, you may be able to successfully remember about a third of them. However, if you were prompted with the category titles, a related test called cued-recall, you would perform much better at retrieving those memories, possibly recalling up to 75% of the words. The fact that cued-recall scores are often higher than free-recall scores indicate that there is a distinction between the encoding / consolidation of memories and the retrieval of memories.

Retrieval is not a passive function. When an engram is retrieved, it is reconsolidated, which is an act similar to replaying the activity of the circuit. During this reconsolidation, it is possible that some aspects of the memory are emphasized, while others are lost. This is likely the main reason why we experience false memories, memories that are not true to reality—one reason why eyewitness testimonies are notoriously unreliable. We may imagine our good memories as better than they actually were, while simultaneously dampening the negative aspects of those memories. A dysregulation of this reconsolidation process could lead to the symptoms seen in post-traumatic stress disorder, where the negative emotional components of a particular memory are exaggerated rather than being blunted.
Through the 1960s, psychiatrist Eric Kandel and his colleagues Arvid Carlsson and Paul Greengard worked with the marine mollusk Aplysia californica. Their work uncovering the neural mechanisms of learning and memory earned them the Nobel Prize in Physiology or Medicine in 2000.

With a nervous system of only 20,000 cells, Aplysia is orders of magnitude simpler than the other model organisms used at the time. Additionally, some Aplysia neurons are huge, up to a millimeter in diameter, which took away the need for highly precise equipment.
Aplysia also has a relatively simple anatomy. It breathes using a half-circle of delicate tissue called the gill, which is guarded by the mantle shelf. They also have an organ called the siphon, a small tube that is used for moving water through the animal.
Kandel and his colleagues began their exploration of memory by studying the gill-withdrawal reflex, a defensive motor response behavior. When a stimulus, such as a hungry predator (or an experimenter’s paintbrush), grazed the siphon, the Aplysia would reflexively withdraw their gill, as if to protect this vital organ by shrinking away from the threat. However, after repeated brush strokes to the siphon, the sea slugs figured out that the stimulus was completely innocuous and decreased the strength of gill withdrawal. Kandel and team suggested that this change in behavior was a form of learning. Kandel and colleagues used Aplysia to learn about the processes of habituation and sensitization.
The gill-withdrawal reflex circuit relies heavily on two different populations of neurons: the glutamatergic sensory neurons that receive somatosensory information from the skin of the siphon, and the motor neurons that control the muscles of the gill. By using two different tiny glass pipettes, they could impale these neurons, inducing action potential firing in the sensory neuron, and observe changes in membrane potential of the motor neurons. Activation of the sensory neuron causes release of glutamate onto the motor neuron that controls the gill, binding to glutamatergic receptors and causing an EPSP response in the motor neuron.
Although there was a strong gill withdrawal reflex following the one poke, Kandel and colleagues observed that after repeated pokes to the siphon, the gill withdrawal reflex got weaker. They found that the activity of the siphon neuron remained unchanged, however, the activity of the motor neuron supplying the gill decreased. The reflex had been habituated. This habituation was due to a decreased release of glutamate from the siphon sensory neuron onto the gill motor neuron.
The group went about seeing if they could modify this habituated response, curious if a stored memory can be modified by stimuli from the outside world. When they paired the mild siphon touch with a painful electric shock to the tail, the Aplysia began responding with a strong motor reaction, withdrawing the gill very intensely, indicating that the inhibited response disappeared. They called this observation sensitization. In electrophysiological studies, they observed that the EPSP at the motor neuron was much larger following the tail shock.

On a molecular level, presentation of sensitization is downstream of the action of a third population of neurons, serotonergic interneurons that synapse onto the siphon sensory neurons. The noxious stimulus triggers these interneurons to release the neurotransmitter serotonin, which binds to receptors on the terminals of the siphon sensory neurons, increasing adenylyl cyclase activity and cAMP production. cAMP activates protein kinase A, which in turn increases the release of glutamate from the sensory neuron and strengthening the gill withdrawal reflex.
Repeating the sensitization protocol multiple times results in plastic changes at the synapse between the sensory siphon neuron and the motor neuron. These plastic changes are long-lasting and dependent on new gene expression. The activated protein kinase A can translocate to the siphon sensory neuron nucleus to activate gene expression and the production of proteins that can remodel the anatomy of the synapse through the growth of additional sensory neuron axons, increasing synaptic connections.
Zooming in beyond the level of anatomy, the substrates of learning can be found at the level of synapses. Synapses change in a phenomenon called plasticity. The word “plasticity” refers to a change in synaptic strength, which may be an increase or a decrease. This change may persist for minutes, hours, days, or in some cases, even a whole lifetime.

When synaptic strength is increased and remains elevated, we call this long-term potentiation (LTP). A prolonged weakness of a synapse is called long-term depression (LTD). In our current limited understanding of plasticity, both phenomena are important for a healthy brain, and neither one is always good or always bad. It is also important to clarify that both excitatory synapses and inhibitory synapses can be subject to either LTP or LTD.
The hippocampus, meaning “seahorse” in Greek, was named based on its morphology. It is located along the ventral and medial surface of the brain. The hippocampus serves as one of the critical structures of the limbic system, a series of subcortical brain structures that are involved in several different complex behaviors, such as emotions and memory. The synaptic connectivity of the hippocampus is very well characterized. Hippocampal synaptic connectivity was first described by Ramon y Cajal, and is made up of three main synaptic connections; sometimes called the trisynaptic circuit.

First, the entorhinal cortex serves as the major input to the hippocampus. This white matter signaling tract is called the perforant pathway, and the neurons synapse onto the granule cells within an area of the hippocampus called the dentate gyrus. The dentate gyrus neurons send their axons, called mossy fibers, to the pyramidal cells of the CA3 region of the hippocampus. The CA3 neurons have axonal projections called Schaffer collaterals that project out of the hippocampus via the fornix and also to neurons within an area of the hippocampus called CA1, which are also neurons that serve as an output of the hippocampus.
Long-term potentiation (LTP) is a long-lasting increase in synaptic strength, measured by the amplitude of the post-synaptic potential. Plasticity can be measured throughout these connections, but for our purposes we will examine how to create LTP within the Schaffer collateral.

To create LTP within the Schaffer collateral, a brief electrical stimulus must be provided to the presynaptic axons coming from the CA3 cells via a stimulating electrode. The EPSP generated in the postsynaptic CA1 neurons is then measured with a recording electrode to establish a baseline.
Using Hebb’s theory about plasticity, if “cells that fire together, wire together,” then it stands that repeated stimulation of that synapse would induce a rewiring of the connection, resulting in LTP. To induce LTP within these cells, a tetanus, or a very intense electrical stimulation consisting of 100 stimulations a second (100 Hz) is delivered to the presynaptic CA3 cells for 3 seconds. Following the delivery of tetanus, a single stimulus is provided again and the EPSP is then measured in the postsynaptic CA1 neuron. The delivery of the high frequency stimulation results in an increased amplitude of the postsynaptic EPSP in response to a single stimulus, demonstrating that LTP is a measurable phenomenon.
In many cases, LTP is shown graphically by measuring the EPSP amplitude as a percent of the control EPSP amplitude. Prior to tetanus delivery, the amplitude will be measured as 100%, or the same as control. Following tetanus, the amplitude of the EPSP will be larger than it was baseline, for instance 130% indicating a 30% increase in amplitude. Increasing the amplitude of the postsynaptic EPSP increases the likelihood of a neuron firing an action potential by increasing the neuron membrane potential such that it is closer to the threshold potential for the cell.

It has been demonstrated in rodents that the elevated postsynaptic EPSP response is long-lasting and can remain elevated for upwards of one year. In humans, we theorize that some synaptic connections may remain potentiated for our entire lifetime, however investigating this is in humans is ethically constrained.
Long-lasting changes in synaptic strength, such as the LTP, are made possible through a series of molecular and cellular level changes. One form of LTP results from a change in the types of glutamatergic receptors. Of the three classes of ionotropic glutamate receptors, two are important for this form of LTP: the AMPA and the NMDA receptors (Chapter 16).

When a molecule of glutamate binds to the active site of the AMPA (α-amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid) receptor, the ligand-gated ion channel changes to the open conformation and allows the cations, sodium and potassium, to cross the cell membrane. Sodium moves into the cells more than potassium leaves the cell, leading to depolarization. The NMDA (N-methyl-D-aspartate) receptor requires the binding of glutamate to open, but it is also dependent on voltage. The pore of the NMDA ligand-gated ion channel is blocked by a molecule of magnesium when the membrane potential is below or near resting membrane potential, preventing ions from moving through the channel. Once the cell depolarizes, the magnesium block is expelled from the receptor, which allows sodium, potassium, and calcium to cross the membrane.

The voltage change needed to open the NMDA receptor is usually a result of AMPA receptor activation. Released glutamate binds to both AMPA and NMDA receptors, and sodium influx occurs through open AMPA channels, which depolarizes the cell enough to expel the magnesium ion and allow ion flow through the NMDA receptors.
The calcium that enters the cell through the open NMDA receptors activates various kinases including, protein kinase A (PKA), protein kinase C (PKC), and calcium-calmodulin-dependent kinase II (CAMKII). Kinases phosphorylate target proteins within the cell, including AMPA receptors. Phosphorylation of AMPA receptors increases their conductance, allowing more ions to pass through the receptors and leading to a greater degree of depolarization. Further, increased intracellular calcium can lead to the insertion of additional AMPA receptors into the postsynaptic cell membrane, which will also allow more sodium to move into the cell and lead to increased depolarization.
Long-term potentiation increases the strength of synapses. Changes in activity can also cause synapses to be weakened through the process of long-term depression (LTD). Again, using the Schaffer collateral as an example, long-term depression can be induced at the synapses between the CA3 and CA1 neurons by replacing the tetanus stimulation with low-frequency stimulation for longer periods of time. For instance, a 15 min exposure to 1 Hz stimulation will lead to a decreased EPSP amplitude.

Through LTP and LTD, synapses demonstrate bidirectional plasticity that is dependent on the type of stimulation that the synapse receives.
Even with low-frequency stimulation of the synapse, glutamate will bind to post-synaptic NMDA receptors and allow for the influx of calcium into the cell. Weak depolarization of the membrane leads to a low amount of calcium entering the cell, which activates a separate class of enzymes call protein phosphatases, specifically protein phosphatase 1 and protein phosphatase 2, that remove phosphate groups from target proteins. Further, LTD causes AMPA receptors to be internalized, or removed from the postsynaptic membrane. Removal of AMPA receptors will decrease excitability.
To test how LTP And LTD are directly related to memory, a robust model of learning is used called Inhibitory Avoidance. In an inhibitory avoidance task, a rat learns to associate an environment with an aversive experience. Typically, a two-chamber compartment is used with one light side and one dark side. The animal is permitted to move from the light chamber to the dark chamber, where it receives an electric foot shock. After just one trial with this protocol, the animal will learn to avoid the dark chamber where it received the foot shock.

One trial of inhibitory avoidance led to measurable LTP within the Schaffer collaterals, demonstrating that the behavioral learning corresponded to LTP during this task. Administration of an NMDA receptor blocker to the hippocampus prior to inhibitory avoidance training results in the animals being unable to learn that the dark chamber leads to a foot shock and inhibition of the corresponding LTP.
The neuron is composed of a number of specialized structures that are critical for proper functioning. Dendrites branch out from the cell body or soma like a tree. The word dendrite comes from the word for tree in Greek. The dendrites are the primary input zone for the cell and receive information from other cells. The number of inputs a neuron receives depends on the complexity of the dendritic branching. The soma houses the nucleus and most organelles and is the location of gene transcription, protein synthesis, vesicle packaging, and other cellular machinery mechanisms. The axon hillock is located at the transition of the soma and axon. It is the location where action potential propagation begins. The axon transmits electrical signals, called action potentials, from the cell body to the presynaptic terminal. Some axons are covered by myelin sheath, which is an insulating material that allows the action potential to travel down the axon faster. Between the myelin segments are the Nodes of Ranvier where the axonal cell membrane is open to the extracellular space. Ions can flow across the membrane at the Nodes, which allows for regeneration of the action potential. Finally, the presynaptic terminal is the output zone. After the action potential reaches the terminal, neurotransmitters are released into the synapse to send messages onto the next cell.
Myelin increases the speed at which action potentials flow down the axon. If myelin was lost, action potentials would propagate down the axon at a slower rate or possibly not at all. Normal sensory, motor, and cognitive functions would be dysfunctional, depending on the location of the demyelination.
Ions move from regions of high concentrations to regions of low concentrations by a process called diffusion. The concentration gradient will cause ions to diffuse across an impermeable membrane if there are open ion channels. Ions are also attracted to regions of opposite charge, so the electrical gradient will move cations toward a negative charge and anions toward a positive charge.
When an ion is at equilibrium, there will be no net ion flow in either direction. The ions will still move however, there will simply be an equal number of ions moving into the cell than are moving out.
The membrane potential is the difference in electrical charge between the inside and outside of a cell. The extracellular solution is the reference point, so you should think of that as having no charge. If a cell has a membrane potential of -70 mV, that means the inside of the cell is more negative than the outside. Active neurons can have drastic changes in their membrane potentials, but the resting membrane potential is the difference in charge when the cell is not active.
The membrane potential is the difference in charge inside the cell relative to the outside, so it takes into account permeability and concentration of all charged molecules when the cell is at rest. It is calculated by the Goldman equation. Equilibrium potential is the membrane potential at which one specific ion is at equilibrium, meaning there is no net movement of that ion in either direction. A cell would reach the equilibrium potential of an ion if the membrane were permeable to only that ion. It is calculated by the Nernst equation.
A change in potassium’s extracellular concentration had a much larger effect on the resting membrane potential compared to changed sodium’s extracellular concentration.
The reason for this is because the membrane is significantly more permeable to potassium compared to sodium at rest. Since there are open channels, potassium can diffuse across the membrane and alter the resting membrane potential. Sodium may increase in concentration outside the cell, but without a way to cross the membrane, the membrane potential does not change.
At rest, the neuronal membrane includes open non-gated potassium channels, fewer open chloride channels, very few open sodium channels, and sodium-potassium pumps.
The rising phase is a depolarization. The voltage-gated sodium channels are open. The voltage-gated potassium channels are closed.

The falling phase is a repolarization. The voltage-gated sodium channels are inactivated. The voltage-gated potassium channels are open.

The undershoot is a hyperpolarization. The voltage-gated sodium channels are closed. The voltage-gated potassium channels close during the undershoot.
The absolute refractory period occurs when the voltage-gated sodium channels are either open during the rising phase or inactivated during the falling phase.
The cell cannot fire a second action potential during the absolute refractory period. The voltage-gated sodium channels cannot reopen in response to a stimulus, regardless of the strength.

The cell can fire a second action potential during the relative refractory period, but the strength of the stimulus must be stronger than when the cell is at rest since the membrane potential is hyperpolarized. The cell will require more stimulus to reach threshold.
In this voltage-clamp experiment, the neuron is clamped at a membrane potential of 0 mV starting a the 1 msec time point. This depolarization is past threshold, so the voltage-gated sodium channels open transiently, increasing sodium permeability and allowing sodium ions to rush into the cell, shown by the inward ion flow on the graph. Briefly after opening, the voltage-gated sodium channels inactivate, preventing any further inward current. The delayed-rectifier voltage-gated potassium channels then open, increasing potassium permeability and allowing potassium ions to rush out of the cell, shown by the outward ion flow on the graph.
An action potential arrives in the terminal
The depolarization opens voltage-gated calcium channels
Calcium interacts with synaptotagmin, a protein bound do synaptic vesicles
Synaptotagmin interacts with the SNARE proteins, causing the synaptic vesicle membrane to fuse with the cellular membrane
Neurotransmitters are released into the synaptic cleft via exocytosis.
With this repetitive firing comes a summation of individual EPSPs, which leads to an increase in depolarization. Once the depolarization reaches threshold, the cell will fire an action potential, but the recording electrode in this example is located in the cell body, not the axon, so action potentials will not be measured.
Neurotransmitters can activate both ionotropic and metabotropic receptors.

Ionotropic receptors are themselves an ion channel, allowing direct ion flow after neurotransmitter binding. Action is immediate and rapid.

Metabotropic receptors do not form an ion channel, and if they affect ion flow it is done indirectly via G-proteins. The effects are slower than ionotropic receptors and have broader actions. Metabotropic receptors can open ion channels, but they can also send second messengers into the cell, which have downstream cellular effect and can even alter gene transcription and protein translation.
Rods and cones play specialized roles in the perception of sight.

Physical appearance: Rods have an elongated, cylindrical outer segment; cones have a shorter, conical outer segment.

Light sensitivity: Rods are highly sensitive to light and therefore are specialized for low light levels. Cones, on the other hand, have lower sensitivity to light, so they are specialized for bright light conditions.

Location: Rods are almost completely excluded from fovea, but the fovea is the location of the majority of cones.

Convergence: Rods have high convergence on bipolar cells; cones have low convergence and can have a 1 to 1 pairing of photoreceptor to bipolar
The fovea is the region of greatest vision acuity. It consists mainly of cone photoreceptors.

The optic disc is the region where the ganglion cell axons leave the retina as the optic nerve. It is responsible for our blindspot because of the absence of photoreceptors in the region.
Different areas of the body have different two-point discrimination thresholds. The more receptors that innervate an area, the smaller the receptive fields of those receptors, which leads to a smaller two-point discrimination threshold.
The primary somatosensory cortex is located in the postcentral gyrus – named because it is the gyrus just posterior to the central sulcus.
Neurons traveling from brainstem will synapse in the ventral posterior nucleus of the thalamus before traveling to the primary somatosensory cortex.