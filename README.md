# <img src="figure/languages_icon.png" alt="Icon" style="vertical-align: middle; width: 1.4em; height: 1.2em;"> *LIvE*: *L*inguistic *I*ntermediary *v*ia *E*nglish for Information Distribution in Low-Resource Languages



Translating low-resource languages remains a significant challenge, particularly in scientific fields where accurate communication is critical. To address this, we introduce **Linguistic Intermediary via English (LIvE)**, a novel framework that leverages English as a pivot language within a Multilingual Neural Machine Translation (MNMT) system. By facilitating knowledge transfer between low-resource languages, LIvE aims to bridge linguistic gaps efficiently. Built on Googleâ€™s **GEMMA 2-9B** model, our approach integrates supervised fine-tuning (SFT) with the parameter-efficient technique LoRA, enabling scalable and effective translation. The framework follows a three-stage process: translating from a source low-resource language to English, refining translations from English to a target low-resource language, and developing a direct MNMT model for source-to-target translation.
To ensure domain-specific accuracy, we curate a Neurobiology-focused dataset, addressing the challenges of limited natural parallel corpora. The framework is evaluated using BLEU, COMET, METEOR, and chrF metrics, alongside human assessments to validate semantic and contextual precision. 
Remarkably, LIvE outperforms state-of-the-art large language models with hundreds of billions of parameters in low-resource language translation, particularly in specialized domains. By optimizing translation quality with reduced computational demands, LIvE demonstrates the potential to democratize access to scientific knowledge while offering scalability to other language pairs and domains.
